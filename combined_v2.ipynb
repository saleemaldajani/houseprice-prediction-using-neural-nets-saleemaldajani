{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# House Price Prediction Comparison\n",
    "\n",
    "This notebook implements three versions of a neural network to predict house prices using Keras/TensorFlow, PyTorch, and JAX (Flax/Optax). In all cases:\n",
    "\n",
    "- The target (`SalePrice`) is log-transformed during training to stabilize the dynamic range. Predictions are exponentiated before RMSE is computed.\n",
    "- Feature selection is applied based on the correlation matrix (keeping the top five features most correlated with `SalePrice`).\n",
    "- Data is split (80% train, 20% validation) and scaled via `StandardScaler`.\n",
    "- The loss is a combined loss: Mean Squared Error (MSE) on the log targets plus a KL divergence penalty computed from differentiable soft histograms. (The KL weight is kept low to avoid numerical issues.)\n",
    "\n",
    "Predictions are saved to:\n",
    "  - `predictions_keras_KL.csv`\n",
    "  - `predictions_pytorch_KL.csv`\n",
    "  - `predictions_jax_KL.csv`\n",
    "\n",
    "Summary plots compare loss curves and the predicted vs. actual price distributions (after exponentiation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d644d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: jax in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: flax in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.10.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: jaxlib<=0.5.0,>=0.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from jax) (0.5.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /home/codespace/.local/lib/python3.12/site-packages (from jax) (1.14.1)\n",
      "Requirement already satisfied: msgpack in /usr/local/python/3.12.1/lib/python3.12/site-packages (from flax) (1.1.0)\n",
      "Requirement already satisfied: optax in /usr/local/python/3.12.1/lib/python3.12/site-packages (from flax) (0.2.4)\n",
      "Requirement already satisfied: orbax-checkpoint in /usr/local/python/3.12.1/lib/python3.12/site-packages (from flax) (0.11.6)\n",
      "Requirement already satisfied: tensorstore in /usr/local/python/3.12.1/lib/python3.12/site-packages (from flax) (0.1.72)\n",
      "Requirement already satisfied: rich>=11.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from flax) (13.9.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from flax) (6.0.2)\n",
      "Requirement already satisfied: treescope>=0.1.7 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from flax) (0.1.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: namex in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=11.1->flax) (2.18.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: chex>=0.1.87 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from optax->flax) (0.1.88)\n",
      "Requirement already satisfied: etils[epy] in /usr/local/python/3.12.1/lib/python3.12/site-packages (from optax->flax) (1.12.0)\n",
      "Requirement already satisfied: nest_asyncio in /home/codespace/.local/lib/python3.12/site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Requirement already satisfied: humanize in /usr/local/python/3.12.1/lib/python3.12/site-packages (from orbax-checkpoint->flax) (4.12.1)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from orbax-checkpoint->flax) (3.20.1)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from chex>=0.1.87->optax->flax) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2024.2.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/python/3.12.1/lib/python3.12/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.5.2)\n",
      "Requirement already satisfied: zipp in /usr/local/python/3.12.1/lib/python3.12/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.21.0)\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-hqjfqu13/pytorch_efea1aa9e37644ab9c923b5474a78ae7/setup.py\", line 15, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch tensorflow jax flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:23:28.045342: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-25 10:23:28.382788: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-25 10:23:28.538917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740479008.799351    2507 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740479008.908212    2507 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-25 10:23:30.271390: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Torch version: 2.5.1+cpu\n",
      "JAX version: 0.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# JAX / Flax / Optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn_flax\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Torch version:', torch.__version__)\n",
    "print('JAX version:', jax.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-load",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "Update the file paths below to point to your `train.csv` and `test.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "data-load-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1000, 81)\n",
      "Test shape: (460, 80)\n"
     ]
    }
   ],
   "source": [
    "# Update these paths as needed\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Test shape:', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-preprocess",
   "metadata": {},
   "source": [
    "### 1.1 Preprocessing & Target Transformation\n",
    "\n",
    "Fill missing values (numeric with median, categorical with mode), drop the `Id` column, one-hot encode categorical features, and apply a log transformation to the target (`SalePrice`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "data-preprocess-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training features shape: (1000, 230)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGJCAYAAADBveoRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf80lEQVR4nO3dd3xT5f4H8M9JmqQj3SNtoYtSKHtPmVIEBZUrLi4q4AAVRMQryL0CigNBr6KI4gS9wvWKPwUEAVmyQSiUvWkZhaalK90jeX5/hERCB6U0PUn6eb9eedGc58k530NC8+WZkhBCgIiIiMiOFHIHQERERK6PCQcRERHZHRMOIiIisjsmHERERGR3TDiIiIjI7phwEBERkd0x4SAiIiK7Y8JBREREdseEg4iIiOyOCQfRNa+//jokSarVaxcvXgxJkpCSklK3QV0nJSUFkiRh8eLFdrtGVUaPHo3o6Oh6v66FJEl4/fXXZbt+TUVHR2P06NF2v05ln4XRo0dDq9Xa/doWzvKekONgwkFO7+jRo3jsscfQqFEjaDQahIeHY+TIkTh69KjcockmJSUFY8aMQWxsLNzd3REaGoo+ffpg5syZ9R5Lv379IEmS9REQEIAuXbrgm2++gclkqvd4aur6uBUKBXx8fNC8eXM8/vjjWL9+fZ1d57fffnPYL25Hjo2cj8S9VMiZ/fzzzxgxYgQCAgLw1FNPISYmBikpKfj666+RmZmJH374AX/7299qdK7y8nKUl5fD3d39luMwGo0oKyuDRqOpdSvJzaSkpCAmJgaLFi2q9n/RZ86cQZcuXeDh4YEnn3wS0dHRuHLlCvbv3481a9aguLj4lq89evRo/PHHH7VqwenXrx/Onj2L2bNnAwAyMjLw3XffISkpCVOnTsW7775703MUFxfDzc0Nbm5ut3z92rox7oKCApw5cwY///wzzp07h4cffhjff/89VCqV9TUlJSVQKBQ2x25mwoQJWLBgAW7lV7EQAiUlJVCpVFAqlQDM79FPP/2E/Pz8Gp/ndmKT4z0h58ZPCjmts2fP4vHHH0eTJk2wdetWBAcHW8tefPFF9O7dG48//jgOHTqEJk2aVHmegoICeHl53dYvT6VSaf3FL7cPP/wQ+fn5SEpKQlRUlE1Zenq6LDH5+vrisccesz4fN24cmjdvjk8++QRvvvlmpV/QJpMJpaWlcHd3r1USWBdujBsA3n33XUycOBGffvopoqOjMWfOHGuZRqOxazzl5eUwmUxQq9Wy/Z1YyH19cj7sUiGn9d5776GwsBBffPGFTbIBAEFBQfj8889RUFCAuXPnWo9bxmkcO3YMf//73+Hv749evXrZlF2vqKgIEydORFBQELy9vXHfffchNTW1Qv91ZWM4oqOjMXToUGzfvh1du3aFu7s7mjRpgu+++87mGllZWfjHP/6BNm3aQKvVwsfHB3fffTcOHjxYq7+Xs2fPonHjxhWSDQAICQmxeb5ixQoMGTIE4eHh0Gg0iI2NxZtvvgmj0XjT65hMJsybNw+tWrWCu7s7dDodxo0bh+zs7Ju+1tPTE927d0dBQQEyMjIAmMcETJgwAUuWLEGrVq2g0Wiwdu1aa9mNTfupqal46qmnrLHHxMTgueeeQ2lpqbVOTk4OJk2ahIiICGg0GjRt2hRz5sy5ra4cpVKJjz/+GC1btsQnn3yC3Nxca9mNYzjKysrwxhtvIC4uDu7u7ggMDESvXr2sXTKjR4/GggULrPdoeQB/jdN4//33MW/ePMTGxkKj0eDYsWPVjuc5d+4cBg0aBC8vL4SHh2PWrFk2LRR//PEHJEnCH3/8YfO6G89ZXWyWYze+JwcOHMDdd98NHx8faLVaDBgwALt377apY/m3smPHDkyePBnBwcHw8vLC3/72N+tngVwTWzjIaf3666+Ijo5G7969Ky3v06cPoqOjsXr16gplDz30EOLi4vDOO+9U25Q9evRo/Pjjj3j88cfRvXt3bNmyBUOGDKlxjGfOnMGDDz6Ip556CqNGjcI333yD0aNHo1OnTmjVqhUA8xfE8uXL8dBDDyEmJgZ6vR6ff/45+vbti2PHjiE8PLzG1wOAqKgobNiwAZs2bcKdd95Zbd3FixdDq9Vi8uTJ0Gq12LRpE2bMmAGDwYD33nuv2teOGzcOixcvxpgxYzBx4kQkJyfjk08+wYEDB7Bjx46bdiucO3cOSqUSfn5+1mObNm3Cjz/+iAkTJiAoKKjKgaqXL19G165dkZOTg7FjxyI+Ph6pqan46aefUFhYCLVajcLCQvTt2xepqakYN24cIiMjsXPnTkybNg1XrlzBvHnzqo2vOkqlEiNGjMD06dOxffv2Kj8Tr7/+OmbPno2nn34aXbt2hcFgwL59+7B//34MHDgQ48aNw+XLl7F+/Xr85z//qfQcixYtQnFxMcaOHQuNRoOAgIAqEyaj0YjBgweje/fumDt3LtauXYuZM2eivLwcs2bNuqV7rEls1zt69Ch69+4NHx8fTJkyBSqVCp9//jn69euHLVu2oFu3bjb1X3jhBfj7+2PmzJlISUnBvHnzMGHCBPzvf/+7pTjJiQgiJ5STkyMAiPvvv7/aevfdd58AIAwGgxBCiJkzZwoAYsSIERXqWsosEhMTBQAxadIkm3qjR48WAMTMmTOtxxYtWiQAiOTkZOuxqKgoAUBs3brVeiw9PV1oNBrx8ssvW48VFxcLo9Foc43k5GSh0WjErFmzbI4BEIsWLar2no8cOSI8PDwEANG+fXvx4osviuXLl4uCgoIKdQsLCyscGzdunPD09BTFxcXWY6NGjRJRUVHW59u2bRMAxJIlS2xeu3bt2grH+/btK+Lj40VGRobIyMgQx48fFxMnThQAxL333mutB0AoFApx9OjRCjHd+Pf9xBNPCIVCIfbu3VuhrslkEkII8eabbwovLy9x6tQpm/JXX31VKJVKceHChQqvvV7fvn1Fq1atqiz/5ZdfBADx0UcfWY9FRUWJUaNGWZ+3a9dODBkypNrrjB8/XlT2q9jyfvv4+Ij09PRKy67/LIwaNUoAEC+88IL1mMlkEkOGDBFqtVpkZGQIIYTYvHmzACA2b95803NWFZsQFd+TYcOGCbVaLc6ePWs9dvnyZeHt7S369OljPWb5t5KQkGB9r4QQ4qWXXhJKpVLk5ORUej1yfuxSIaeUl5cHAPD29q62nqXcYDDYHH/22Wdveg1Lc/7zzz9vc/yFF16ocZwtW7a0aYEJDg5G8+bNce7cOesxjUYDhcL8T9FoNCIzMxNarRbNmzfH/v37a3wti1atWiEpKQmPPfYYUlJS8NFHH2HYsGHQ6XT48ssvbep6eHhYf87Ly8PVq1fRu3dvFBYW4sSJE1VeY9myZfD19cXAgQNx9epV66NTp07QarXYvHmzTf0TJ04gODgYwcHBaNGiBebPn48hQ4bgm2++sanXt29ftGzZstr7M5lMWL58Oe6991507ty5Qrml2X/ZsmXo3bs3/P39bWJMSEiA0WjE1q1bq73OzVimoFo+i5Xx8/PD0aNHcfr06VpfZ/jw4RW6DKszYcIE68+WbqrS0lJs2LCh1jHcjNFoxO+//45hw4bZjJcKCwvD3//+d2zfvr3Cv8GxY8fadNH07t0bRqMR58+ft1ucJC92qZBTsiQS1f2yv778xsQkJibmptc4f/48FApFhbpNmzatcZyRkZEVjvn7+9uMczCZTPjoo4/w6aefIjk52Wb8RGBgYI2vdb1mzZrhP//5D4xGI44dO4ZVq1Zh7ty5GDt2LGJiYpCQkADA3Az+2muvYdOmTRW+EK4fm3Cj06dPIzc3t8KYEIsbB6dGR0fjyy+/hCRJcHd3R1xcXKWvrcn7kpGRAYPBgNatW1db7/Tp0zh06FCVX9a3O4DWMhukuqR31qxZuP/++9GsWTO0bt0agwcPxuOPP462bdvW+Do1+TuxUCgUFQZIN2vWDADsukZMRkYGCgsL0bx58wplLVq0gMlkwsWLF63diEDFfxv+/v4AUKMxQOScmHCQU/L19UVYWBgOHTpUbb1Dhw6hUaNG8PHxsTl+/f/s7amqmSviunEj77zzDqZPn44nn3wSb775JgICAqBQKDBp0qTbXqdCqVSiTZs2aNOmDXr06IH+/ftjyZIlSEhIQE5ODvr27QsfHx/MmjXLumbH/v37MXXq1GqvbTKZEBISgiVLllRafuOXvJeXlzXJqU5dvi8mkwkDBw7ElClTKi23fBHX1pEjRwBUn4D26dMHZ8+exYoVK/D777/jq6++wocffoiFCxfi6aefrtF16vqzWtW07ZoMFK5LNfm3Qa6FCQc5raFDh+LLL7/E9u3brTNNrrdt2zakpKRg3LhxtTp/VFQUTCYTkpOTERcXZz1+5syZWsdcmZ9++gn9+/fH119/bXM8JycHQUFBdXYdS/fDlStXAJhnK2RmZuLnn39Gnz59rPWSk5Nveq7Y2Fhs2LABd9xxR70lbxbBwcHw8fGxfuFXJTY2Fvn5+TVKdG6V0WjE0qVL4enpWeln73oBAQEYM2YMxowZg/z8fPTp0wevv/66NeGoy3VbTCYTzp07Z5NMnTp1CgCsA3AtLQk5OTk2r62sK6OmsQUHB8PT0xMnT56sUHbixAkoFApERETU6FzkujiGg5zWK6+8Ag8PD4wbNw6ZmZk2ZVlZWXj22Wfh6emJV155pVbnHzRoEADg008/tTk+f/782gVcBaVSWeF/dcuWLUNqamqtzrdt2zaUlZVVOP7bb78BgLXZ2/I/zOuvXVpaWuF+K/Pwww/DaDTizTffrFBWXl5e4cusLikUCgwbNgy//vor9u3bV6Hccj8PP/wwdu3ahXXr1lWok5OTg/Ly8lpd32g0YuLEiTh+/DgmTpxYofXsejd+LrVaLZo2bYqSkhLrMS8vL2tMdeGTTz6x/iyEwCeffAKVSoUBAwYAMCfSSqWywhiWyt73msamVCpx1113YcWKFTZdN3q9HkuXLkWvXr2q/XuihoEtHOS04uLi8O2332LkyJFo06ZNhZVGr169iv/+97+IjY2t1fk7deqE4cOHY968ecjMzLROi7X8j7Gu/mc6dOhQzJo1C2PGjEHPnj1x+PBhLFmypNrFyqozZ84cJCYm4oEHHrCOFdi/fz++++47BAQEYNKkSQCAnj17wt/fH6NGjcLEiRMhSRL+85//1KhJu2/fvhg3bhxmz56NpKQk3HXXXVCpVDh9+jSWLVuGjz76CA8++GCt4q+Jd955B7///jv69u2LsWPHokWLFrhy5QqWLVuG7du3w8/PD6+88gpWrlyJoUOHWqciFxQU4PDhw/jpp5+QkpJy0xak3NxcfP/99wCAwsJC60qjZ8+exaOPPlppwnW9li1bol+/fujUqRMCAgKwb98+/PTTTzYDOzt16gQAmDhxIgYNGgSlUolHH320Vn8v7u7uWLt2LUaNGoVu3bphzZo1WL16Nf75z39au7l8fX3x0EMPYf78+ZAkCbGxsVi1alWlY1puJba33noL69evR69evfD888/Dzc0Nn3/+OUpKSmzWwqEGTMYZMkR14tChQ2LEiBEiLCxMqFQqERoaKkaMGCEOHz5coa5l6qtlimBlZdcrKCgQ48ePFwEBAUKr1Yphw4aJkydPCgDi3XfftdaralpsZVMi+/btK/r27Wt9XlxcLF5++WURFhYmPDw8xB133CF27dpVoV5Np8Xu2LFDjB8/XrRu3Vr4+voKlUolIiMjxejRo22mLFrqdu/eXXh4eIjw8HAxZcoUsW7dugrTJm+cFmvxxRdfiE6dOgkPDw/h7e0t2rRpI6ZMmSIuX75sc7/VTS+1ACDGjx9fZdn1UzCFEOL8+fPiiSeeEMHBwUKj0YgmTZqI8ePHi5KSEmudvLw8MW3aNNG0aVOhVqtFUFCQ6Nmzp3j//fdFaWlptfH07dtXALA+tFqtiIuLE4899pj4/fffK33NjdNi33rrLdG1a1fh5+cnPDw8RHx8vHj77bdtrl1eXi5eeOEFERwcLCRJsn4GLe/3e++9V+E6VU2L9fLyEmfPnhV33XWX8PT0FDqdTsycObPCtOuMjAwxfPhw4enpKfz9/cW4cePEkSNHKpyzqtiEqPw92b9/vxg0aJDQarXC09NT9O/fX+zcudOmjuXfyo1Tmquarkuug3upEN2ipKQkdOjQAd9//z1GjhwpdzhERE6BYziIqlFUVFTh2Lx586BQKGwGWhIRUfU4hoOoGnPnzkViYiL69+8PNzc3rFmzBmvWrMHYsWM56p6I6BawS4WoGuvXr8cbb7yBY8eOIT8/H5GRkXj88cfxr3/9i9tyExHdAiYcREREZHccw0FERER2x4SDiIiI7I6d0DAvB3z58mV4e3vX6TLDRERErk4Igby8PISHh1t3vq4MEw4Aly9f5owDIiKi23Dx4kU0bty4ynImHPhre+mLFy9yvX8iIqJbYDAYEBERYf0urQoTDvy1J4aPjw8TDiIiolq42ZAEDholIiIiu2PCQURERHbHhIOIiIjsjgkHERER2R0TDiIiIrI7JhxERERkd0w4iIiIyO5kTTi2bt2Ke++9F+Hh4ZAkCcuXL7eWlZWVYerUqWjTpg28vLwQHh6OJ554ApcvX7Y5R1ZWFkaOHAkfHx/4+fnhqaeeQn5+fj3fCREREVVH1oSjoKAA7dq1w4IFCyqUFRYWYv/+/Zg+fTr279+Pn3/+GSdPnsR9991nU2/kyJE4evQo1q9fj1WrVmHr1q0YO3Zsfd0CERER1YAkhBByBwGYVyj75ZdfMGzYsCrr7N27F127dsX58+cRGRmJ48ePo2XLlti7dy86d+4MAFi7di3uueceXLp0CeHh4TW6tsFggK+vL3Jzc7nSKBER0S2o6XeoU43hyM3NhSRJ8PPzAwDs2rULfn5+1mQDABISEqBQKLBnz54qz1NSUgKDwWDzICIiIvtxmr1UiouLMXXqVIwYMcKaQaWlpSEkJMSmnpubGwICApCWllbluWbPno033njDrvE2NN169kKaXl9leahOhz07t9djRERE5EicIuEoKyvDww8/DCEEPvvss9s+37Rp0zB58mTrc8tOd1R7aXo9Ji1cXWX5vGeH1GM0RETkaBw+4bAkG+fPn8emTZts+odCQ0ORnp5uU7+8vBxZWVkIDQ2t8pwajQYajcZuMRMREZEthx7DYUk2Tp8+jQ0bNiAwMNCmvEePHsjJyUFiYqL12KZNm2AymdCtW7f6DpeIiIiqIGsLR35+Ps6cOWN9npycjKSkJAQEBCAsLAwPPvgg9u/fj1WrVsFoNFrHZQQEBECtVqNFixYYPHgwnnnmGSxcuBBlZWWYMGECHn300RrPUCEiIiL7kzXh2LdvH/r37299bhlXMWrUKLz++utYuXIlAKB9+/Y2r9u8eTP69esHAFiyZAkmTJiAAQMGQKFQYPjw4fj444/rJX4iIiKqGVkTjn79+qG6ZUBqskRIQEAAli5dWpdhERERUR1z6DEcRERE5BqYcBAREZHdMeEgIiIiu2PCQURERHbHhIOIiIjsjgkHERER2Z3DL21OjuFmm7PpqykjIiJiwkE1crPN2abc17EeoyEiImfDLhUiIiKyOyYcREREZHdMOIiIiMjumHAQERGR3THhICIiIrtjwkFERER2x4SDiIiI7I4JBxEREdkdEw4iIiKyOyYcREREZHdMOIiIiMjumHAQERGR3THhICIiIrtjwkFERER2x4SDiIiI7I4JBxEREdkdEw4iIiKyOyYcREREZHdMOIiIiMjumHAQERGR3THhICIiIrtjwkFERER2x4SDiIiI7I4JBxEREdkdEw4iIiKyOyYcREREZHdMOIiIiMjumHAQERGR3THhICIiIrtjwkFERER2J2vCsXXrVtx7770IDw+HJElYvny5TbkQAjNmzEBYWBg8PDyQkJCA06dP29TJysrCyJEj4ePjAz8/Pzz11FPIz8+vx7sgIiKim5E14SgoKEC7du2wYMGCSsvnzp2Ljz/+GAsXLsSePXvg5eWFQYMGobi42Fpn5MiROHr0KNavX49Vq1Zh69atGDt2bH3dAhEREdWAm5wXv/vuu3H33XdXWiaEwLx58/Daa6/h/vvvBwB899130Ol0WL58OR599FEcP34ca9euxd69e9G5c2cAwPz583HPPffg/fffR3h4eL3dC5kVlJTjUnYRcopKERusRZBWI3dIRETkABx2DEdycjLS0tKQkJBgPebr64tu3bph165dAIBdu3bBz8/PmmwAQEJCAhQKBfbs2VPluUtKSmAwGGwedPt2nc3EV9uTsfZoGnafy8LSPRew+WQ6SsqMcodGREQyc9iEIy0tDQCg0+lsjut0OmtZWloaQkJCbMrd3NwQEBBgrVOZ2bNnw9fX1/qIiIio4+gbHs82CfgzJQsAEOytQWSAJwSAQ5dyseLgZUBy2I8aERHVgwb5LTBt2jTk5uZaHxcvXpQ7JKd2PrMAfv2eBAB0bxKAv3eNxN86NMIDHRpB7abAldxioO19MkdJRERyctiEIzQ0FACg1+ttjuv1emtZaGgo0tPTbcrLy8uRlZVlrVMZjUYDHx8fmwfVjtEksPFEOiSFEi3CvNE1OsBaFhHgiUEtzS1UUrN++O3wFbnCJCIimTlswhETE4PQ0FBs3LjResxgMGDPnj3o0aMHAKBHjx7IyclBYmKitc6mTZtgMpnQrVu3eo+5ITqlz0NecTmMhTm4s3kIJEmyKW8SrEWnSH8AwIwVR1BYWi5HmEREJDNZE478/HwkJSUhKSkJgHmgaFJSEi5cuABJkjBp0iS89dZbWLlyJQ4fPownnngC4eHhGDZsGACgRYsWGDx4MJ555hn8+eef2LFjByZMmIBHH32UM1TqgRAC+1KyAQD5B36Dm7Lyj1OP2ECI/Ku4ml+KRTtS6jFCIiJyFLImHPv27UOHDh3QoUMHAMDkyZPRoUMHzJgxAwAwZcoUvPDCCxg7diy6dOmC/Px8rF27Fu7u7tZzLFmyBPHx8RgwYADuuece9OrVC1988YUs99PQnLtagKzCUqjdFCg49HuV9ZQKCTi6BgDw+ZazyC0sq68QiYjIQci6Dke/fv0ghKiyXJIkzJo1C7NmzaqyTkBAAJYuXWqP8OgmEs+bWzfaNfZFcmlR9ZUv7Efz+57HSX0ePt96FlMGx9dDhERE5CgcdgwHObbcojJcyS2GBKBdY78avELg5buaAQAW70yBoZitHEREDQkTDqqVM+nm/Woa+XvAS1OzhrKBLXVoGqJFYakRPydesmd4RETkYJhwUK1YEo64EG2NXyNJEp7oEQUA+G73+Wq704iIyLUw4aBbZiguQ5rBvIFebHDNEw4AeKBjY2g1bjiXUYAdZzLtER4RETkgJhx0y85aulP8at6dYqHVuOGBjo0AAN/tSqnr0IiIyEEx4aBbdvpawtH0FrpTrmfpVtlwXA/9tZYSIiJybUw46JYUlRrNe6MAiA32qtU5moZ4o3OUP0wCWJGUWpfhERGRg2LCQbfkUk4hACDQSw1vd1Wtz/O3a90qP+9nwkFE1BAw4aBbcinbvMBXY3+P2zrP0DbhUCsVOJGWh2OXDXURGhEROTAmHHRL/ko4PG/rPL6eKtwZHwIA+OUA1+QgInJ1TDioxgpKypFVUArg9ls4gL+6VVYkXYbRxDU5iIhcGRMOqjFL60awVgN3lfK2z9e/eQj8PFVIzyvB7nNck4OIyJUx4aAau5RtHjBaF60bAKB2U2Bwq1AAwOrDV+rknERE5JiYcFCN1dWA0evd0yYMALDuSBq7VYiIXBgTDqoZdx/kFJVBgnnDtrrSIzYQfp4qZBaUYk8yu1WIiFwVEw6qmcBo8x9aNTRutz9+w0KlVOCuljoAwG/sViEicllMOKhmAszLkYf6uNf5qS3dKmuP6NmtQkTkophwUM0ERAIAQn3rPuG4o2kQfD1UuJpfgr0pWXV+fiIikh8TDropo0kA/hEAAJ0dWjhUSgUSWpi7VTYc09f5+YmISH5MOOimzqTnQ1K5Q6WUEOCltss1ElqYVx1df1wPIditQkTkaphw0E0lXcwGAOi83aGQJLtco3ezYKiVCpzPLMTZjHy7XIOIiOTDhINuKuliLgBAZ4fxGxZajRt6xAYCADYcT7fbdYiISB5MOOimki7mALDPDJXrWbpVOI6DiMj1uMkdADm2wtJynNLnAQB0Phq7Xuujfz4HdJuAvSmZiGrRHigtsCkP1emwZ+d2u8ZARET2wYSDqnX0sgFGk4AoyoW3u8qu18q4cAYhAzTIyC/BwGlfoWWYj035vGeH2PX6RERkP+xSoWodTTWP30D2xXq5XkywFwDgHAeOEhG5FCYcVK1jVwzmH3JS6+V6TYLMCceFrEKUG031ck0iIrI/JhxUrfpOOEK8NfDSKFFmFLiUU1Qv1yQiIvvjGA6qUpnRhFNp17o2bjPh0KfpERUbV30dvR6SJCEmyAtHUg1IzihAdKDXbV2XiIgcAxMOqtLZjHyUGk3w1rjBUHB7e5wYTSZMWri62jpT7usIAGgSpMWRVAPOXS1APyEg2WmxMSIiqj/sUqEqHbts7k5pEeYDoP6WG4/w94CbQkJ+STky8kvq7bpERGQ/TDioSpaEo2W4z01q1i03pQJRgZ4AgOSMgpvUJiIiZ8AuFUK3nr2Qpq9kdc8+z0PSNcOij2ZDX1m5HUUHeuFsRgHOZxWiW5PAer02ERHVPSYchDS9vsL4CiEEvth2DsVlJvz9+Sl4f+fyeo3J0sKRlluM4jIj3FXKer0+ERHVLXapUKXyS8pRXGaCQoLdtqSvjre7CoFeagiY1+QgIiLnxoSDKmUZrOnvpYabUp6PiaWV43wmEw4iImfHhIMqdTW/FAAQpLXvhm3Vibq2Bsf5zAIIUX+zZIiIqO4x4aBKZV5r4QiSoTvFItzXHW4KCQWlRmsCREREzsmhEw6j0Yjp06cjJiYGHh4eiI2NxZtvvmnzv10hBGbMmIGwsDB4eHggISEBp0+fljFq15BZYP6CD5SxhcNNqUBjfw8AwPksTo8lInJmDp1wzJkzB5999hk++eQTHD9+HHPmzMHcuXMxf/58a525c+fi448/xsKFC7Fnzx54eXlh0KBBKC4uljFy52Y0CWRbEg4ZWzgAWJc25zgOIiLn5tDTYnfu3In7778fQ4YMAQBER0fjv//9L/78808A5taNefPm4bXXXsP9998PAPjuu++g0+mwfPlyPProo7LF7sxyCkthEoBKKcHbXd6PiGXg6OWcIsBNvtYWIiK6PQ7dwtGzZ09s3LgRp06dAgAcPHgQ27dvx9133w0ASE5ORlpaGhISEqyv8fX1Rbdu3bBr164qz1tSUgKDwWDzoL9Yu1O8NLLvY+LnqYavhwomASC4qayxEBFR7Tl0C8err74Kg8GA+Ph4KJVKGI1GvP322xg5ciQAIC0tDQCg0+lsXqfT6axllZk9ezbeeOMN+wXu5DLzLeM35O1OsYgK9MShS7ko8om+6Y6zoTod9uzcXk+RERFRTTl0wvHjjz9iyZIlWLp0KVq1aoWkpCRMmjQJ4eHhGDVqVK3PO23aNEyePNn63GAwICIioi5CdgmZBeYZKnKP37CwJBzqqLZ4cdJz1ba6zHt2SD1GRkRENeXQCccrr7yCV1991ToWo02bNjh//jxmz56NUaNGITQ0FACg1+sRFhZmfZ1er0f79u2rPK9Go4FGw/EAVXGEGSrXa+znCYUEuPnqkFNUBn9Px0iEiIio5hx6DEdhYSEUCtsQlUolTCYTACAmJgahoaHYuHGjtdxgMGDPnj3o0aNHvcbqKsqNJuQWlgFwnBYOtZsC4X7XpsdytgoRkVNy6BaOe++9F2+//TYiIyPRqlUrHDhwAB988AGefPJJAIAkSZg0aRLeeustxMXFISYmBtOnT0d4eDiGDRsmb/BOKquwFAKAu0oBT7XjbJgWHeiFS9lFSMksQPsIP7nDISKiW+TQCcf8+fMxffp0PP/880hPT0d4eDjGjRuHGTNmWOtMmTIFBQUFGDt2LHJyctCrVy+sXbsW7u7uMkbuvKwDRh1ghsr1ogI9sf0MkJpdhHKTCW4Kh26cIyKiGzh0wuHt7Y158+Zh3rx5VdaRJAmzZs3CrFmz6i8wF5bpIAt+3SjQSw1jQTbg5Y8rOcWICPCUOyQiIroF/G8i2ci6lnDIsSV9dSRJQsmFwwC4XT0RkTNiwkE2sh004QCA4vMHATDhICJyRkw4yKrcZEJukXmGiiMmHCUXzS0c6XklKCwtlzkaIiK6FUw4yCqnsAwCgFrpWDNULEyFuQi6tvrpxawimaMhIqJbwYSDrK7vTnGkGSrXi7w2WJTdKkREzoUJB1lZBoz6e6lkjqRq1yccQgiZoyEioppiwkFWWYWOO2DUopGfB5QKCfkl5ci+tiIqERE5PiYcZJVdcG3AqAPvVeKmVKCRdZnzApmjISKimmLCQQAAIQSyCy1dKo6bcAAcx0FE5IyYcBAAwFBcjnKTgFKS4OvuuGM4gL8SjkvXljknIiLHx4SDAPw1YNTPUwWFwjFnqFgEadXwVCtRbhJIyy2WOxwiIqoBJhwEANbuFEceMGohSZJ1LxV2qxAROQcmHATguimxDjxg9HpR1xKO85lMOIiInAETDgLguJu2VcUyjiM9rwRFZUaZoyEiopthwkEAHHvTtsp4adwQ6GVZ5pytHEREjo4JBwEaLYrLzbM9/Dwde4bK9SIDOY6DiMhZMOEgwDsEAODj7gaV0nk+EteP4+Ay50REjq1W3y5NmjRBZmZmheM5OTlo0qTJbQdF9cwnFIDjL/h1o3Auc05E5DRqlXCkpKTAaKw4UK+kpASpqam3HRTVM28dAOcZv2GhUioQ7usOgN0qRESOzu1WKq9cudL687p16+Dr62t9bjQasXHjRkRHR9dZcFRPfK4lHE4yJfZ6kYGeuJhdhAtZhWgf4Sd3OEREVIVbSjiGDRsGwLzw0qhRo2zKVCoVoqOj8e9//7vOgqN6cm0Mh7O1cABAVIAXdiATl7ILYTRxHAcRkaO6pYTDdG3fipiYGOzduxdBQUF2CYrqT0FJOSSvAADON4YDMC9z7qFSoqjMyGXOiYgcWK3GcCQnJzPZcBHnMsxbvHuolPBQKWWO5tZJkmRdBOx8FrerJyJyVLfUwnG9jRs3YuPGjUhPT7e2fFh88803tx0Y1Y8zGXkAnLM7xSIy0BMn9XkcOEpE5MBqlXC88cYbmDVrFjp37oywsDBIkmPvLkpVO5OeDwDw93KeBb9uFOlvbuHQG0oAlafM0RARUWVqlXAsXLgQixcvxuOPP17X8VA9O5tu7oZwxhkqFlp38zLnmQWlgC5O7nCIiKgStRrDUVpaip49e9Z1LCSDMxnmFg5n7lIB/trMDbp4eQMhIqJK1SrhePrpp7F06dK6joXqWZnRhJSr5hYOZ5yhcr2/Eo7mXOaciMgB1apLpbi4GF988QU2bNiAtm3bQqWy7f//4IMP6iQ4sq/zmYUoNwmI8hJ4a2o9ftghNPL3gFKSYPQKQPLVAjQJ1sodEhERXadW3zKHDh1C+/btAQBHjhyxKeMAUudhGTAKgx6S1FreYG6TSqlAmJ87LmUXYdvpq0w4iIgcTK0Sjs2bN9d1HCSDs9fGbyAvXd5A6khkgKc14RjVM1rucIiI6DrOsxc51bmz17VwuALLdvW7zl5FmdF0k9pERFSfatXC0b9//2q7TjZt2lTrgKj+nLG2cLhGwhHsrYEoyUcBtDhwIQddYwLkDomIiK6pVcJhGb9hUVZWhqSkJBw5cqTCpm7kmIQQLtfCIUkSoD8FRHbE9tMZTDiIiBxIrRKODz/8sNLjr7/+OvLz828rIKofaYZiFJQaoVRIKM+/Knc4dUd/AojsiK2nr2LyXc3ljoaIiK6p0zEcjz32GPdRcRKWGSpRgZ6AMMocTR3SnwQAHLqUg5zCUpmDISIiizpNOHbt2gV3d/e6PCXZiSXhaOpq00eLctE0RAuTAHacyZQ7GiIiuqZWXSoPPPCAzXMhBK5cuYJ9+/Zh+vTpdRIY2Zc14QjRYp3MsdS1vs2CcSY9H5tPpmNI2zC5wyEiItSyhcPX19fmERAQgH79+uG3337DzJkz6zTA1NRUPPbYYwgMDISHhwfatGmDffv2WcuFEJgxYwbCwsLg4eGBhIQEnD59uk5jcEWWhCPW1Vo4AAyIDwEAbD6RDqOJy5wTETmCWrVwLFq0qK7jqFR2djbuuOMO9O/fH2vWrEFwcDBOnz4Nf39/a525c+fi448/xrfffouYmBhMnz4dgwYNwrFjx9i9Uw3Lol9NQ1wv4egSEwBvdzdkFpTi4KUcdIz0v/mLiIjIrm5rA43ExEQcP34cANCqVSt06NChToKymDNnDiIiImwSnJiYGOvPQgjMmzcPr732Gu6//34AwHfffQedTofly5fj0UcfrdN4XEVOYSmu5psHVMa6YMKhUirQt1kwVh26go3H9Uw4iIgcQK26VNLT03HnnXeiS5cumDhxIiZOnIhOnTphwIAByMjIqLPgVq5cic6dO+Ohhx5CSEgIOnTogC+//NJanpycjLS0NCQkJFiP+fr6olu3bti1a1eV5y0pKYHBYLB5NCSW7pRwX3donXzTtqoMaGHuVtl43DWWbScicna1SjheeOEF5OXl4ejRo8jKykJWVhaOHDkCg8GAiRMn1llw586dw2effYa4uDisW7cOzz33HCZOnIhvv/0WAJCWlgYA0Ol0Nq/T6XTWssrMnj3bZgxKREREncXsDKzjN1ywdcOiX7MQKCTgRFoeLmUXyh0OEVGDV6uEY+3atfj000/RokUL67GWLVtiwYIFWLNmTZ0FZzKZ0LFjR7zzzjvo0KEDxo4di2eeeQYLFy68rfNOmzYNubm51sfFixfrKGLncPpawhEX4i1zJPbj76VG5yjzSqObTrCVg4hIbrVKOEwmE1QqVYXjKpUKJlPdbZoVFhaGli1b2hxr0aIFLly4AAAIDQ0FAOj1tktz6/V6a1llNBoNfHx8bB4NyfVTYl3Znde6VTawW4WISHa1SjjuvPNOvPjii7h8+bL1WGpqKl566SUMGDCgzoK74447cPLkSZtjp06dQlRUFADzANLQ0FBs3LjRWm4wGLBnzx706NGjzuJwNQ0l4Ui4lnDsPpuJgpJymaMhImrYapVwfPLJJzAYDIiOjkZsbCxiY2MRExMDg8GA+fPn11lwL730Enbv3o133nkHZ86cwdKlS/HFF19g/PjxAMybdU2aNAlvvfUWVq5cicOHD+OJJ55AeHg4hg0bVmdxuJKCknKk5hQBAOJcPOGIDdYiKtATpUYTtp12of1iiIicUK2mKERERGD//v3YsGEDTpw4AcDc1XH9bJG60KVLF/zyyy+YNm0aZs2ahZiYGMybNw8jR4601pkyZQoKCgowduxY5OTkoFevXli7di3X4KjCuYwCAECglxr+XmqZo7EvSZJwZ3wIFu1IwcbjegxuXXU3GxER2dctJRybNm3ChAkTsHv3bvj4+GDgwIEYOHAgACA3NxetWrXCwoUL0bt37zoLcOjQoRg6dGiV5ZIkYdasWZg1a1adXdOVncnIA+DaM1Sul9BCh0U7UrD5ZDpMJgGFQpI7JCKiBumWulTmzZuHZ555ptJBlr6+vhg3bhw++OCDOguO6t5pvWWGSsNIOLpEB8Bb44ar+eZVR4mISB63lHAcPHgQgwcPrrL8rrvuQmJi4m0HRfbTUAaMWqjdFOjTLBgAFwEjIpLTLSUcer2+0umwFm5ubnW60ijVvTMuvIdKVRJammerrDta9WJwRERkX7eUcDRq1AhHjhypsvzQoUMIC+N24I6qtNyE85nmVTddedGvG90Zr4NKKeF0ej7OpOfJHQ4RUYN0SwnHPffcg+nTp6O4uLhCWVFREWbOnFntAE+SV0pmAYwmAa3GDTofjdzh1BtfDxV6NQ0CAKw5zFYOIiI53FLC8dprryErKwvNmjXD3LlzsWLFCqxYsQJz5sxB8+bNkZWVhX/961/2ipVu0/V7qEhSw5qtcXcbc8vbb0eYcBARyeGWpsXqdDrs3LkTzz33HKZNmwYhBADz1NRBgwZhwYIFFTZSI8fR0GaoXG9gCx2UCgnHrxiQcrUA0UFecodERNSg3PLCX1FRUfjtt9+QnZ2NM2fOQAiBuLg4+Pv72yM+qkMNccCohb+XGj1jA7Ht9FWsOZKG5/rFyh0SEVGDUqulzQHA398fXbp0QdeuXZlsOIkz6Q23hQMA7m5t7lZZffjyTWoSEVFdq3XCQc7FaBI424BbOABgcOtQuCkkHEk1WP8uiIiofjDhaCAuZReitNwEtZsCjf095Q5HFgFeavSOM89WWZnEVg4iovrEhKOBsAwYjQ3WQtmA9xO5v30jAMDKg5etg56JiMj+mHA0EA15wOj1BrbUwV2lQPLVAhxJNcgdDhFRg1Gr7enJ+Vj3UAl27YRDn6ZHVGxcleWhOh0SJnyMVYeuYEVSKto09q3H6IiIGi4mHA3EacsMFZ1rJxxGkwmTFq6usnzes0Nwf/tGWHXoClYevIxX746Hm5INfURE9sbftA2AEAJnG9gusdXp2ywY/p4qpOeVYNuZq3KHQ0TUIDDhaAD0hhLkl5RDqZAQHcgVNtVuCuvg0Z8SL8kcDRFRw8CEowE4kWYeHBkd6Am1G99yAHiwU2MAwPqjeuQUlsocDRGR6+O3TwNwSm/ekj0+1EfmSBxH60a+aBHmg1KjCb8e5JocRET2xoSjATiRZk44mod6yxyJY7G0cixjtwoRkd0x4WgATjLhqNSw9uFwU0g4dCkXxy5zTQ4iIntiwuHiyo0m65TY5jomHNcL1GpwVysdAGDpn+dljoaIyLUx4XBx57PMe6h4qJSIDGiYe6hU5+9dowAAyw9cRkFJuczREBG5LiYcLs7SndJMp4WiAe+hUpWesYGICvREfkk5B48SEdkREw4XxwGj1VMoJIzoGgkAWPrnBZmjISJyXUw4XNzJa2twNOP4jSo92KkxVErz4NGDF3PkDoeIyCUx4XBxp65tS881OKoWpNVgaNtwAMCiHckyR0NE5Jq4eZsLKyo1IiWzAAC7VCyq3E3WrzGkgf/AL/svYvvCadj3x9r6D46IyIUx4XBhp9PzIAQQ6KVGsLdG7nAcQnW7yS5LvIjLOcXI8G1ez1EREbk+dqm4sBPWGSps3aiJDhH+5h+a9ERRqVHeYIiIXAwTDhd2ijNUbkmTYC/4uLtB0mjxy4FUucMhInIpTDhc2Enrpm1MOGpCIUloH+EHAPhmRzKEEPIGRETkQphwuDCuwXHrWob7QJQV40x6Pradvip3OERELoMJh4vKKihFRl4JACCOYzhqTOOmBJJ3AwC+3s4pskREdYUJh4uyLGkeEeABrYaTkW7JmW2QJGDLqQycSc+TOxoiIpfAhMNFWVYYba7jgl+3rCATd7U07yL7+ZZzMgdDROQamHC4KMuA0eahWpkjcU7P9o0FAPxyIBWpOUUyR0NE5PyYcLiovwaMsoXjVunT9BjWvyuE/iTKTQI9n3odUbFx1ke3nr3kDpGIyOk4VcLx7rvvQpIkTJo0yXqsuLgY48ePR2BgILRaLYYPHw69Xi9fkA5ACGFdg4NTYm+dZTXS4YPvBAC4Ne+LZz5agUkLV2PSwtVIa+CfLyKi2nCahGPv3r34/PPP0bZtW5vjL730En799VcsW7YMW7ZsweXLl/HAAw/IFKVjuJRdhIJSI1RKCTFBXnKH47Qa+3sg1McdRpPAAe4iS0R0W5wi4cjPz8fIkSPx5Zdfwt/f33o8NzcXX3/9NT744APceeed6NSpExYtWoSdO3di9+7dMkYsL8sMldhgLVRKp3iLHZIkSegSbf68Hb6Ui+IyLndORFRbTvFtNH78eAwZMgQJCQk2xxMTE1FWVmZzPD4+HpGRkdi1a1eV5yspKYHBYLB5uJLjV8z3w+6U2xcT5IUgrRqlRhMOXsqROxwiIqfl8AnHDz/8gP3792P27NkVytLS0qBWq+Hn52dzXKfTIS0trcpzzp49G76+vtZHREREXYctq6OXzQlHq3BfmSNxfpIkoXNUAAAg6UIOSstNMkdEROScHDrhuHjxIl588UUsWbIE7u7udXbeadOmITc31/q4ePFinZ3bERy9kgsAaBXOGSp1IU6nha+HCsXlJhxJzZU7HCIip+TQS1AmJiYiPT0dHTt2tB4zGo3YunUrPvnkE6xbtw6lpaXIycmxaeXQ6/UIDQ2t8rwajQYajcaeocsmt6gMF7PM60a0vJZwdOvZq9qZFQ19Vs/NKCQJnaP9sfF4OvadzwaUarlDIiJyOg6dcAwYMACHDx+2OTZmzBjEx8dj6tSpiIiIgEqlwsaNGzF8+HAAwMmTJ3HhwgX06NFDjpBlZxm/0cjPA36e5i/GNL0ekxaurvI1U+7rWGUZmbUI9cHe5CwYisuB2DvkDoeIyOk4dMLh7e2N1q1b2xzz8vJCYGCg9fhTTz2FyZMnIyAgAD4+PnjhhRfQo0cPdO/eXY6QZWcZv9GS3Sl1SqmQ0C0mEOuP64H4ASgoKYcX96ghIqoxp/+N+eGHH0KhUGD48OEoKSnBoEGD8Omnn8odVr2p0F3S5e+Qorvi92WLEfXGCADsMqkr8aHe+DMlC7nQ4ttdKXi+X1O5QyIichpOl3D88ccfNs/d3d2xYMECLFiwQJ6AZHZjd8mSPedxNb8U9414Ek2CJwJgl0ldUSgkdI8JwLpjenyx9Rwe7x4Fb3eV3GERETkFh56lQrem3GRCVkEpACDI2zUHxcqtWag3hEGPnMIyLN6RInc4REROgwmHC8nML4VJAO5uCnhzfIFdKCQJOLYOAPDltnPILSqTOSIiIufAhMOFZOSXAACCvTWQJEnmaFzYxQOIC9HCUFyORTuS5Y6GiMgpMOFwIRmGvxIOsieBSQnNAABfbUu2dmMREVHVmHC4EH1eMQBA51N3q7JS5e5uHYqWYT7ILynHp5vPyB0OEZHDY8LhIowmgat55v9pM+GwP4VCwpTBzQEA3+06j9ScIpkjIiJybEw4XERmfgmMQkDjpoCPOweM1oe+zYLRvUkASo0mfLj+lNzhEBE5NCYcLkKfZx6/ofNx54DReiJJEqYOjgcA/Lz/Ek7p82SOiIjIcfG/wi4i3WAevxHCAaN2p0/TIyo27q8DPcbA1LgdBv5jAbDzawBAqE6HPTu3yxQhEZHjYcLhIq5v4SD7MppMNqu7ZhWU4vvd54FGbfDQuz8h3M8D854dImOERESOh10qLqDcaEJmviXhYAtHfQvwUls3y9tx9iqEEDJHRETkeJhwuICr11YY9VApoeUKo7LoFhMApULC5ZxipGQWyh0OEZHDYcLhAvQGy/obXGFULt7uKrRv7AfA3MoB8H0gIroeEw4XYFnwK4TjN2TVOdofajcFMvNLgUju0EtEdD0mHC4gLdeccIQy4ZCVu0qJzlH+5iet70FJuVHegIiIHAgTDmen8kR2oXnH0lBfJhxyax/hBy+1EpJXIP6z67zc4RAROQwmHM4uIBIA4OehgodKKXMwpFIq0D02EADw8cbTyObGbkREAJhwOL/AaABAGFs3HEbLMB+InFQYisvx8abTcodDROQQmHA4u2sJB7tTHIdCkoCDKwAA/9l1Hucy8mWOiIhIfkw4nJjJJICAKABMOBxO+incGR+CcpPA7DUn5I6GiEh2TDic2NmMfEhqD7gpJAR5cYVRR/PPe+KhVEhYf0yPXWcz5Q6HiEhWTDic2IELOQDM+6coFFxoytE0DfHG37uaB/W+tfqYuUWKiKiBYsLhxA5czAbA7hRHNikhDt4aNxy9bMDPB1LlDoeISDZMOJzYvhRzwsEZKo4rUKvBhDubAgDeX3cShaXlMkdERCQPJhxOKqugFKfTzbMfwn09ZI6GqjOqZzQa+3sgzVCML7cmyx0OEZEsmHA4qb0pWQAAYUiDh5oLfjkyd5USr94dDwBYuOWsdbM9IqKGhAmHk9qbbE44kHFW3kCoRoa0CUPHSD8UlRnx3rqTcodDRFTv3OQOgGrH0sKBq+fkDYQqpU/TIyo2zvZgQBSkAS/hp8RL2PTV29i/7kd5giMikgETDidUUFKOI5cN5ids4XBIRpMJkxaurnD892NpOH4lD5lR/WAyCU5nJqIGg10qTmj/hWwYTQKN/DyAohy5w6FbcEdsENRKBaSAKPy0/5Lc4RAR1Ru2cDihP6+N3+gaEwB+ZTkXL40busUEYNuZq3jl+x14ZeTbQHnlg0hDdTrs2bm9niMkIrIPJhxOyJJwdIkOwM8yx0K3rl2EHzb9eRCqgEboMHEh+jQLrrTevGeH1HNkRET2wy4VJ1NcZsSBizkAzC0c5HyUCgm5W78FABy8lIPM/BKZIyIisj8mHE5mX0o2SstN0PloEBvsJXc4VEsl5w+iSZAXTALYcioDQnCfFSJybUw4nMz2M1cBAHc0DYIkcYaDM+sdFwSlQsLF7CKc1OfJHQ4RkV0x4XAyO89eSzhig2SOhG6Xn6caXaPN3WJbT11FcZlR5oiIiOyHCYcTyS0sw+HUXADmFg5yfp2i/BHopUZRmRHbTl+VOxwiIrthwuFEdp27CiGA2GAvbknvIpQKCXfGhwAAjl0x4FJ2ocwRERHZh0MnHLNnz0aXLl3g7e2NkJAQDBs2DCdP2u5DUVxcjPHjxyMwMBBarRbDhw+HXq+XKWL72nEmEwDQi60bLiXczwOtG/kAADadSEe5ySRzREREdc+hE44tW7Zg/Pjx2L17N9avX4+ysjLcddddKCgosNZ56aWX8Ouvv2LZsmXYsmULLl++jAceeEDGqO1nx7UBoz2ZcLicXrFB8FQrkV1Yhn0p2XKHQ0RU5xx64a+1a9faPF+8eDFCQkKQmJiIPn36IDc3F19//TWWLl2KO++8EwCwaNEitGjRArt370b37t3lCNsuLmYV4tzVAigVEro3CZQ7HKpjGpUSfZsFY82RNOxLyUbTEK3cIRER1SmHbuG4UW6uecBkQIB5ZH9iYiLKysqQkJBgrRMfH4/IyEjs2rWryvOUlJTAYDDYPBzd5pPpAIBOkf7w9VDJHA3ZQ1yIFjFBXjAKgXVH0wCFUu6QiIjqjEO3cFzPZDJh0qRJuOOOO9C6dWsAQFpaGtRqNfz8/Gzq6nQ6pKWlVXmu2bNn44033rBnuHVu0wlzwtH/2gBDcj2SJGFAfAiW7LmAq/mlQKu7b+t83Xr2QtpNxjNxvxYiqi9Ok3CMHz8eR44cwfbtt//Lcdq0aZg8ebL1ucFgQERExG2f116KSo3YddY8YPROJhwuzUvjhgEtQrDq0BWg+Z3YeeZqrcfspOn1mLRwdbV1uF8LEdUXp+hSmTBhAlatWoXNmzejcePG1uOhoaEoLS1FTk6OTX29Xo/Q0NAqz6fRaODj42PzcGQ7z15FSbkJjfw80EzHvn1XFxusRatwH0iSAhN/OAC9ofLdZImInIlDJxxCCEyYMAG//PILNm3ahJiYGJvyTp06QaVSYePGjdZjJ0+exIULF9CjR4/6Dtdu/upOCeZy5g1E32bBEDmpuJpfiheWHkC5kVNlici5OXTCMX78eHz//fdYunQpvL29kZaWhrS0NBQVFQEAfH198dRTT2Hy5MnYvHkzEhMTMWbMGPTo0cNlZqgIIfDHyQwA7E5pSFRKBbBrEbw1bvgzJQszVh7lBm9E5NQcOuH47LPPkJubi379+iEsLMz6+N///met8+GHH2Lo0KEYPnw4+vTpg9DQUPz8888yRl23jl/JQ2pOETRuCvRowvU3GpT8q/jgkfaQJGDpngtYuOWc3BEREdWaQw8arcn/6Nzd3bFgwQIsWLCgHiKqf2uOXAEA9GseDA81p0k2NANb6jBzaEu8/usxzFl7AoFaNR7u7LgDnImIquLQLRwNnRACqw+bE4572oTJHA3JZfQdMXi6l3n80pSfDmHpngsyR0REdOuYcDiwU/p8nMsogNpNwfEbDdy/hrTA6J7RAIB//nIYCzaf4ZgOInIqTDgc2G/XWjf6xAXD252rizZkkiRh5r0t8WzfWADAe+tO4rnv9yOvuEzmyIiIaoYJhwP7zdqdUvWaItRwSJKEqYOb452/tYFKKWHt0TQMnrcNm69NmyYicmRMOBzUaX0eTqfnQ6WUMKCFTu5wyEFIkoS/d4vEj+N6oJGfB1JzijBm8V48/e1eHLqUI3d4RERVYsLhoH4+kArAvAAUN2ujG3WI9Mf6yX0wtk8TKBUSNhxPx32f7MDfv9yN/0u8hIKScrlDJCKywYTDARlNAj/vvwQAeLBT45vUpobKU+2Gf97TAusm9cEDHRpBqZCw82wmXl52EJ3f2gB0fQwpmQUwmji4lIjk59DrcDRU289chd5QAn9PFe6MZ3cKVa9piBYfPNIeLw1shp/3p2J5UiqSrxZAiuqMFUmX4aFSommIFs10WoT7eUDB5fGJSAZMOBzQT4nm1o372zeC2o2NUFQzEQGeeDEhDhMHNEXSxRwMmzwHni36oajMiMOpuTicmgsvjRKtwnzRppEvtO78509E9Ye/cRxMblEZ1h1NA8DuFKodSZLQIdIfOPB/ePqZMbiYXYhT+nyczchHQYkRf6ZkYe/5LMTrvAEtl8snovrB/z47mOUHUlFabkJ8qDdahfvIHQ45OYVCQlSgFwa21OHp3jG4p3UoGvl5QAjgeFoeMPifmPrTIaTnFcsdKhG5OLZwOBCTSeDbnSkAgBFdI7kVPdUpN4UCcTpvxOm8oTcUY09yFpKvFuB/+y5i9eErmJQQhzF3xECp4OeOiOoeWzgcyNbTGTh3tQDeGjcMZ3dKg6dP0yMqNq7KR7eevWp9bp2PO+5rFw6xcR7aNfZFfkk53lp9HA9/vgtnM/Lr8C6IiMzYwuFAFu1IAQA81DkCWg3fmobOaDJh0sLVVZbPe3bI7V8kKwW/PH8H/rfvIt5ZfRyJ57Nxz0fb8I+7muPJXmztIKK6wxYOB3EmPR9bTmVAkoBRPaPkDocaEIVCwoiukVj3Uh/0aRaMknIT3v7tOB5auBMpVwvkDo+IXAQTDgfx1bZzAIAB8SGICvSSORpqiML9PPDtmC6YM7wNvDVu2H8hB3d/tA3f7z7PnWmJ6LYx4XAAF7MKrWtvWHYDJZKDJEl4pEsk1r7UBz1jA1FUZsRry49g9KK90Bs4k4WIao8DBRzA/E2nUW4S6B0XhM7RATZl3Xr2QppeX+Vr9dWUkWuzDCqtsrwGn43qzyGhMLwjPLs/gi2nMtD19ZVA4k/ApQM2tUJ1OuzZuf1WQieiBogJh8wuZBbi//abN2qblNCsQnmaXl/twMEp93W0W2zk2G42qLQmn42anOPZl1/DuqNpSM8D0GMUmunGo1/zEHiolADqaPAqEbk8dqnI7IP1J2E0CfRpFoxOUf5yh0NUQYCXGg93jkDXmABIEnBKn4/vdqbgSGoux3YQUY2xhUNGe1OysDzpMiQJ+MddFVs3iByFUiGhR5NAxAR6YcMJPTLzS7HxRDoOpeYCungIIbhQHRFViy0cMjGaBGauOAoAeKRzBNo29pM3IKIaCPV1x4gukegdFwS1UoGMvBJIfZ7Fgwt3Yd3RNJhMbPEgosqxhUMmS/ecx7ErBvi4u+GVQc3lDoeoxpQKCR0j/dEi1Ad7z2dhf3IGEs9nY9x/EtHY3wMPdmqMBzo0RmSgJ4CbD3wGOPCUqCFgwiGDC5mFeHfNCQDAy3c1R6BWI3NERLfOQ61En7hg7F8wEc//ewm+330el7KLMG/DaczbcBrxod64Mz4EaVIAnvvkS2jclFWeiwNPiVwfE456ZjQJTP4xCQWlRnSNDsBj3bmqKDm5YgOmDI7HC3fGYd3RNPyUeAm7zmXiRFoeTqTlQeo9Dgu3nEOQVo1wXw/ofN0R4q1BgKcaCi6dTtRgMOGoZ5/9cQb7zmdDq3HDuf+9hSbvnaq2PtfZIGfhoVZiWIdGGNahEXIKS7HpRDp2ns3Esi0HIGmDcTW/FFfzS4HUXACAm0JCsLcGOm93ILIzTuvz0CRYy/1biFwUE456tPlkOj5Yb04wXr+vFV7+/lS1ayAAXGeDnJOfpxoPdGyMBzo2xrJXH8TTH63A5ZwiXMktRnpeCdLzilFmFLiSW4wrucWQuj2GgR9uhadaiQ6RfugZG4QesYFo28gXbkqObSdyBUw46smZ9DxMXHoAJgE83LkxhndshJflDoqonnhp3BCn80aczhsAIIRAdmEZ0g3F0OeV4M89u6EKiUEhNNhxJhM7zmSa65UVAxln4FNwCWu+moPG/p5y3gYR3QYmHPXgSm4Rnly8D3kl5egaHYC3hrXhmgXUoEmShAAvNQK81IgPA1b/YybeXZGIrIJSpGYX4WJ2IS5lF6EE7kB4a+ShNXrN2Yy4EC36x4egf/MQdI72h4qtH0ROgwmHnekNxfj7l3twIasQkQGe+OyxjlC78Zck0Y0UkoQgrQZBWg3aRfjBJAQy8kpwIasQO3b/CWVILE6n5+N0ej6+2HoOWo0bescFoX/zEPRtHgydj7vct0BE1WDCYUed7xyCjBYPQvIOgSjIwvnVb6Dj59nWcg4IJaqaQpKg83GHzscdP096DbqIGEDXHAhrAYS2QD68seZIGtYcSQMAuOWl4dn7eqF/fDDaR/hz8CmRg2HCYScHLmQjo+3jkNy9odW44cGeHeF73/c2dTgglKhmjCYTJs1fZn0uhIA+rwQpVwuQklkAvaEE5d6h+GTzGXyy+Qz8PFXoExeMXk2D0CHSD7HBWk7BJZIZEw472HBMj/FL90Ny90awVoN724XB210ld1hEdlH9Fvf2acmTJAmhPu4I9XFH9yaBKCwtxxfvv4n7xk7B1lMZyCksw8qDl7Hy4GUAgLfGDe0i/NA+wg8dIs1/Vrbg3s1WReWKqES1x4TDDiICPKFWKlB84TAeHHEfx2yQS6vJFvf25ql2Ay7sw/wRHVBuNOHgpRxsPpGBvSlZOHQpF3kl5dh+5iq2n7lqfU1jfw9zEtLYD+0i/NC6kQ/S9Ppq74UrohLVHhMOO2ge6o3/e74nBt4xEerHh8kdDlGDUGVLi6QAfEJRoAmCV2QrIDAKkk8oLmUX4VJ2EVYfugIAEMKE8v6TseG4Hjpvd+h8NQj00nAsCFEdYcJhJ8103oAwyR0GUYNRk5aWf82aDQAoKTci3VCCNEMx9IZi6A0lyC8phyooEkcvG3AUBgDmjepCvDXXBq9qAK8gCCE4rZ2oFphwEFGDo3FTIiLAExEBfy0kVlBSjjlTnsPgibOhN5RAbyhGSbnJuhoqAEj3vIYOb65H28Z+aNfYF/GhPmge6o3oQE+uiEp0E0w4iIhgXg21ODkRPWODAJhnwuQUlZlbQHLNrSFXsvOQUwhsPZWBracyrK9VuynQNFiL6CBPRPh7onGAJyIDPBHq444ALzX8PVVMSKjBc5mEY8GCBXjvvfeQlpaGdu3aYf78+ejatavcYRGRk5IkCf6eavh7qhEfaj4277n78Osfe5B0MRuHU3NxUp+P0/o8FJYaceyKAceuGKo4F+DvqUaglxqBWvMKq94aFXw83ODtroKP+7U/PVTwdneDj/u1Pz1U0GrcOI6EXIJLJBz/+9//MHnyZCxcuBDdunXDvHnzMGjQIJw8eRIhISFyh0dErkIY0aaxL9o09rUeMpkELmUX4ZQ+Dy/NmA2DSQ1oAwGvAMDdB1B7AlAgq6AUWQWlOJ1ei8uWFQFlJYCxDDCWQq0AunRoCw+VEhqVApIkQSFJkAAoJGDtut9RVFQIQDJnO5LC/Kf1uQR3jTt69eoFoxAwCXOLjkkImEyASQjsT0pCaVm5+bWQAAjAZDSPTbv2p0atQv8+veCmUECpkOCmkMx/Ks1//t///R8K8/PNrxFGwGS69vNf5/DRemHqPybf8FqF9fnUKa8gO0MPGEuB8msPy8/CyKnKN6h6ave1pFWSoAsJwZ87t9VrXICLJBwffPABnnnmGYwZMwYAsHDhQqxevRrffPMNXn31VZmjIyJXplBIiAz0RGSgJwwHVlcYuGoyCRSVGc2PUiO+emcKHnjxLZSUm1BSbkRpuenaz+bnl1LOwTc0EiXlJhhNAgAgqTwAlYf1nGUAdp7NrDooXWvcrE2kBMDGE9VkP76RNz1HKYB1R6tZZ6VRl5ueIw/Aa8uPVF2hzaNVnkMhAWklRej69gZ4qpXwULvBQ6WAp9oN7iolNG4KqN0UUCuv/XnDc0u5m0JhzsNgXuEW1342J3LXcjRI13I16VqZua4QgIC49qc5cQMAIcyJ2/XHBQBcV990w2txrU65UaDUaEJp+bXHtZ9LbJ4bbcos5WkdnoJPcDiMJvHX41ocFvpTf9zkXbEPp084SktLkZiYiGnTplmPKRQKJCQkYNeuXZW+pqSkBCUlJdbnubm5AACDofLm0NoymUwoLsivslwIUW15Teo4yzmcJU5XOoezxOlM5zCZTNX+nqjq37wSgFYCtBqg8OQONA+o+lfv9Fn3Y8IP5v99lpv++kIpKzeh3CRQZjRh1ZdzMPe991FcZkSp0QSTyfxFZWmpmPvvD9DzvlHmE1q/PGH9UpUkCVv+txBvzpxp/eJUKMx/Wr5kX/7HKxg85h/W15jPf31rCLDph88wY/p0GE0C5SYBo8kco9EIGE0Cn37+BToMHG6uf63lxATza3HtHKcO7MDAhIHXvd6cpFnu9eDR4/DVRaLcZEKZ0fx3YvnytMwDTLuaDbpGrUVubvXfZaKspE6/7yznsiRbVV/YyaWmpgoAYufOnTbHX3nlFdG1a9dKXzNz5kyBa0knH3zwwQcffPBx+4+LFy9W+33t9C0ctTFt2jRMnjzZ+jwnJwdRUVG4cOECfH19ZYzM/gwGAyIiInDx4kX4+PjIHY5dNZR7bSj3CfBeXVVDuVdXvU8hBPLy8hAeHl5tPadPOIKCgqBUKivs16DX6xEaGlrpazQaDTSaivso+Pr6utSHoDo+Pj68VxfTUO4T4L26qoZyr654nzX5z7rTTwxXq9Xo1KkTNm7caD1mMpmwceNG9OjRQ8bIiIiIyMLpWzgAYPLkyRg1ahQ6d+6Mrl27Yt68eSgoKLDOWiEiIiJ5uUTC8cgjjyAjIwMzZsxAWloa2rdvj7Vr10Kn09Xo9RqNBjNnzqy0m8XV8F5dT0O5T4D36qoayr02lPusiiTEzeaxEBEREd0epx/DQURERI6PCQcRERHZHRMOIiIisjsmHERERGR3TDhg3to+Ojoa7u7u6NatG/7880/ZYtm6dSvuvfdehIeHQ5IkLF++3KZcCIEZM2YgLCwMHh4eSEhIwOnTp23qZGVlYeTIkfDx8YGfnx+eeuop5Ofb7u9w6NAh9O7dG+7u7oiIiMDcuXMrxLJs2TLEx8fD3d0dbdq0wW+//XbLsVRl9uzZ6NKlC7y9vRESEoJhw4bh5MmTNnWKi4sxfvx4BAYGQqvVYvjw4RUWeLtw4QKGDBkCT09PhISE4JVXXkF5eblNnT/++AMdO3aERqNB06ZNsXjx4grx3OwzUJNYqvLZZ5+hbdu21sV+evTogTVr1rjcfVbm3XffhSRJmDRpksvd7+uvv27eyOu6R3x8vMvdJwCkpqbiscceQ2BgIDw8PNCmTRvs27fPWu4qv5eio6MrvKeSJGH8+PEAXOs9lcXt72bi3H744QehVqvFN998I44ePSqeeeYZ4efnJ/R6vSzx/Pbbb+Jf//qX+PnnnwUA8csvv9iUv/vuu8LX11csX75cHDx4UNx3330iJiZGFBUVWesMHjxYtGvXTuzevVts27ZNNG3aVIwYMcJanpubK3Q6nRg5cqQ4cuSI+O9//ys8PDzE559/bq2zY8cOoVQqxdy5c8WxY8fEa6+9JlQqlTh8+PAtxVKVQYMGiUWLFokjR46IpKQkcc8994jIyEiRn59vrfPss8+KiIgIsXHjRrFv3z7RvXt30bNnT2t5eXm5aN26tUhISBAHDhwQv/32mwgKChLTpk2z1jl37pzw9PQUkydPFseOHRPz588XSqVSrF271lqnJp+Bm8VSnZUrV4rVq1eLU6dOiZMnT4p//vOfQqVSiSNHjrjUfd7ozz//FNHR0aJt27bixRdfrPE1nOV+Z86cKVq1aiWuXLlifWRkZLjcfWZlZYmoqCgxevRosWfPHnHu3Dmxbt06cebMGWsdV/m9lJ6ebvN+rl+/XgAQmzdvrtHfo7O8p3Jp8AlH165dxfjx463PjUajCA8PF7Nnz5YxKrMbEw6TySRCQ0PFe++9Zz2Wk5MjNBqN+O9//yuEEOLYsWMCgNi7d6+1zpo1a4QkSSI1NVUIIcSnn34q/P39RUlJibXO1KlTRfPmza3PH374YTFkyBCbeLp16ybGjRtX41huRXp6ugAgtmzZYj2XSqUSy5Yts9Y5fvy4ACB27dolhDAnZwqFQqSlpVnrfPbZZ8LHx8d6b1OmTBGtWrWyudYjjzwiBg0aZH1+s89ATWK5Vf7+/uKrr75y2fvMy8sTcXFxYv369aJv377WhMOV7nfmzJmiXbt2lZa50n1OnTpV9OrVq8pyV/699OKLL4rY2FhhMplc6j2VS4PuUrFsbZ+QkGA9drOt7eWUnJyMtLQ0m3h9fX3RrVs3a7y7du2Cn58fOnfubK2TkJAAhUKBPXv2WOv06dMHarXaWmfQoEE4efIksrOzrXWuv46ljuU6NYnlVuTm5gIAAgICAACJiYkoKyuzOX98fDwiIyNt7rVNmzY2C7wNGjQIBoMBR48erdF91OQzUJNYaspoNOKHH35AQUEBevTo4bL3OX78eAwZMqRCTK52v6dPn0Z4eDiaNGmCkSNH4sKFCy53nytXrkTnzp3x0EMPISQkBB06dMCXX35pLXfV30ulpaX4/vvv8eSTT0KSJJd6T+XSoBOOq1evwmg0VliRVKfTIS0tTaaoqmaJqbp409LSEBISYlPu5uaGgIAAmzqVneP6a1RV5/rym8VSUyaTCZMmTcIdd9yB1q1bW8+vVqvh5+dXbQy1vQ+DwYCioqIafQZqEsvNHD58GFqtFhqNBs8++yx++eUXtGzZ0uXuEwB++OEH7N+/H7Nnz65Q5kr3261bNyxevBhr167FZ599huTkZPTu3Rt5eXkudZ/nzp3DZ599hri4OKxbtw7PPfccJk6ciG+//dYmVlf7vbR8+XLk5ORg9OjR1nO7ynsqF5dY2pyc2/jx43HkyBFs375d7lDspnnz5khKSkJubi5++uknjBo1Clu2bJE7rDp38eJFvPjii1i/fj3c3d3lDseu7r77buvPbdu2Rbdu3RAVFYUff/wRHh4eMkZWt0wmEzp37ox33nkHANChQwccOXIECxcuxKhRo2SOzn6+/vpr3H333Tfdcp1qrkG3cNRma3s5WWKqLt7Q0FCkp6fblJeXlyMrK8umTmXnuP4aVdW5vvxmsdTEhAkTsGrVKmzevBmNGze2udfS0lLk5ORUG0Nt78PHxwceHh41+gzUJJabUavVaNq0KTp16oTZs2ejXbt2+Oijj1zuPhMTE5Geno6OHTvCzc0Nbm5u2LJlCz7++GO4ublBp9O51P1ez8/PD82aNcOZM2dc6n0NCwtDy5YtbY61aNHC2n3kir+Xzp8/jw0bNuDpp5+2HnOl91QuDTrhcLat7WNiYhAaGmoTr8FgwJ49e6zx9ujRAzk5OUhMTLTW2bRpE0wmE7p162ats3XrVpSVlVnrrF+/Hs2bN4e/v7+1zvXXsdSxXKcmsVRHCIEJEybgl19+waZNmxATE2NT3qlTJ6hUKpvznzx5EhcuXLC518OHD9v8Ilu/fj18fHysvyBvdh81+QzUJJZbZTKZUFJS4nL3OWDAABw+fBhJSUnWR+fOnTFy5Ejrz650v9fLz8/H2bNnERYW5lLv6x133FFhyvqpU6cQFRUFwLV+L1ksWrQIISEhGDJkiPWYK72nspF71KrcfvjhB6HRaMTixYvFsWPHxNixY4Wfn5/NKOP6lJeXJw4cOCAOHDggAIgPPvhAHDhwQJw/f14IYZ7y5efnJ1asWCEOHTok7r///kqnn3Xo0EHs2bNHbN++XcTFxdlMP8vJyRE6nU48/vjj4siRI+KHH34Qnp6eFaafubm5iffff18cP35czJw5s9LpZzeLpSrPPfec8PX1FX/88YfNNLTCwkJrnWeffVZERkaKTZs2iX379okePXqIHj16WMstU9DuuusukZSUJNauXSuCg4MrnYL2yiuviOPHj4sFCxZUOgXtZp+Bm8VSnVdffVVs2bJFJCcni0OHDolXX31VSJIkfv/9d5e6z6pcP0vFle735ZdfFn/88YdITk4WO3bsEAkJCSIoKEikp6e71H3++eefws3NTbz99tvi9OnTYsmSJcLT01N8//331jqu8ntJCPOMkMjISDF16tQKZa7ynsqlwSccQggxf/58ERkZKdRqtejatavYvXu3bLFs3rxZAKjwGDVqlBDCPO1r+vTpQqfTCY1GIwYMGCBOnjxpc47MzEwxYsQIodVqhY+PjxgzZozIy8uzqXPw4EHRq1cvodFoRKNGjcS7775bIZYff/xRNGvWTKjVatGqVSuxevVqm/KaxFKVyu4RgFi0aJG1TlFRkXj++eeFv7+/8PT0FH/729/ElStXbM6TkpIi7r77buHh4SGCgoLEyy+/LMrKyir8nbZv316o1WrRpEkTm2tY3OwzUJNYqvLkk0+KqKgooVarRXBwsBgwYIA12XCl+6zKjQmHq9zvI488IsLCwoRarRaNGjUSjzzyiM3aFK5yn0II8euvv4rWrVsLjUYj4uPjxRdffGFT7iq/l4QQYt26dQJApa9xpfdUDtyenoiIiOyuQY/hICIiovrBhIOIiIjsjgkHERER2R0TDiIiIrI7JhxERERkd0w4iIiIyO6YcBAREZHdMeEgIiIiu2PCQUT1ZvHixRW21LaHlJQUSJKEpKQku1+LiGqGCQcR1VhGRgaee+45REZGQqPRIDQ0FIMGDcKOHTvsds3o6GhIkgRJkuDl5YWOHTti2bJl1b4mIiICV65cQevWre0WFxHdGiYcRFRjw4cPx4EDB/Dtt9/i1KlTWLlyJfr164fMzEy7XnfWrFm4cuUKDhw4gC5duuCRRx7Bzp07K61bWloKpVKJ0NBQuLm52TUuIqo5JhxEVCM5OTnYtm0b5syZg/79+yMqKgpdu3bFtGnTcN999wEAPvjgA7Rp0wZeXl6IiIjA888/j/z8/GrPu2LFCnTs2BHu7u5o0qQJ3njjDZSXl9vU8fb2RmhoKJo1a4YFCxbAw8MDv/76KwBzC8ibb76JJ554Aj4+Phg7dmylXSpHjx7F0KFD4ePjA29vb/Tu3Rtnz561ln/11Vdo0aIF3N3dER8fj08//bSO/uaICGDCQUQ1pNVqodVqsXz5cpSUlFRaR6FQ4OOPP8bRo0fx7bffYtOmTZgyZUqV59y2bRueeOIJvPjiizh27Bg+//xzLF68GG+//XaVr3Fzc4NKpUJpaan12Pvvv4927drhwIEDmD59eoXXpKamok+fPtBoNNi0aRMSExPx5JNPWhObJUuWYMaMGXj77bdx/PhxvPPOO5g+fTq+/fbbmv71ENHNyL1dLRE5j59++kn4+/sLd3d30bNnTzFt2jRx8ODBKusvW7ZMBAYGWp8vWrRI+Pr6Wp8PGDBAvPPOOzav+c9//iPCwsKsz6OiosSHH34ohBCipKREvPPOOwKAWLVqlbV82LBhNudITk4WAMSBAweEEEJMmzZNxMTEiNLS0krjjI2NFUuXLrU59uabb4oePXpUeW9EdGu4PT0R3ZLi4mJs27YNu3fvxpo1a/Dnn3/iq6++wujRo7FhwwbMnj0bJ06cgMFgQHl5OYqLi1FQUABPT08sXrwYkyZNQk5ODgAgODgY+fn5UCqV1vMbjUab10RHR+PKlStQqVQoLi6GVqvFtGnTMHXqVADmLpVnnnkG//rXv6znSElJQUxMDA4cOID27dvjnnvuQXBwcKUtFgUFBdBqtfDw8IBC8Vejb3l5OXx9faHX6+30N0nUsHBEFRHdEnd3dwwcOBADBw7E9OnT8fTTT2PmzJno168fhg4diueeew5vv/02AgICsH37djz11FMoLS2Fp6dnhXPl5+fjjTfewAMPPFDpdSxeeeUVjB49GlqtFjqdDpIk2dT18vKqNmYPD48qyyxjTL788kt069bNpuz6RIiIbg8TDiK6LS1btsTy5cuRmJgIk8mEf//739aWgh9//LHa13bs2BEnT55E06ZNq60XFBR00zrVadu2Lb799luUlZVBpVLZlOl0OoSHh+PcuXMYOXJkra9BRNVjwkFENZKZmYmHHnoITz75JNq2bQtvb2/s27cPc+fOxf3334+mTZuirKwM8+fPx7333osdO3Zg4cKF1Z5zxowZGDp0KCIjI/Hggw9CoVDg4MGDOHLkCN566606i33ChAmYP38+Hn30UUybNg2+vr7YvXs3unbtiubNm+ONN97AxIkT4evri8GDB6OkpAT79u1DdnY2Jk+eXGdxEDVknKVCRDWi1WrRrVs3fPjhh+jTpw9at26N6dOn45lnnsEnn3yCdu3a4YMPPsCcOXPQunVrLFmyBLNnz672nIMGDcKqVavw+++/o0uXLujevTs+/PBDREVF1WnsgYGB2LRpE/Lz89G3b1906tQJX375pbW14+mnn8ZXX32FRYsWoU2bNujbty8WL16MmJiYOo2DqCHjoFEiIiKyO7ZwEBERkd0x4SAiIiK7Y8JBREREdseEg4iIiOyOCQcRERHZHRMOIiIisjsmHERERGR3TDiIiIjI7phwEBERkd0x4SAiIiK7Y8JBREREdvf/PTtIecIEVmUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fill_missing_values(df):\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in num_cols:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Process training data\n",
    "train_df = fill_missing_values(train_df.copy())\n",
    "\n",
    "# Save and drop Id column\n",
    "train_ids = train_df['Id']\n",
    "train_df.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "# Log-transform the target SalePrice\n",
    "y = np.log(train_df['SalePrice'])\n",
    "X = train_df.drop('SalePrice', axis=1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print('Processed training features shape:', X.shape)\n",
    "\n",
    "# Plot original SalePrice distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(np.exp(y), bins=50, kde=True)\n",
    "plt.title('Original SalePrice Distribution')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-selection",
   "metadata": {},
   "source": [
    "### 1.2 Feature Selection\n",
    "\n",
    "Compute the correlation matrix (using numeric columns) and select the top five features most correlated with `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feature-selection-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 features selected: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF']\n",
      "X shape after feature selection: (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "numeric_df = train_df.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_df.corr()\n",
    "top_features = corr_matrix['SalePrice'].abs().sort_values(ascending=False).iloc[1:6].index.tolist()\n",
    "print('Top 5 features selected:', top_features)\n",
    "\n",
    "# Restrict X to these features\n",
    "X = X[top_features]\n",
    "print('X shape after feature selection:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-scale",
   "metadata": {},
   "source": [
    "### 1.3 Train-Validation Split and Scaling\n",
    "\n",
    "Split the data (80% train, 20% validation) and scale features using `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "split-scale-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (800, 5)\n",
      "X_val_scaled shape: (200, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print('X_train_scaled shape:', X_train_scaled.shape)\n",
    "print('X_val_scaled shape:', X_val_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "keras-section",
   "metadata": {},
   "source": [
    "## 2. Keras/TensorFlow Implementation\n",
    "\n",
    "Build a Keras model using a combined loss of MSE and a KL divergence penalty on the log-transformed targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "keras-kl-loss",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-02-25 10:23:47.956797: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,089</span> (35.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,089\u001b[0m (35.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,089</span> (35.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,089\u001b[0m (35.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def soft_histogram_tf(x, bin_centers, sigma):\n",
    "    x = tf.reshape(x, [-1, 1])\n",
    "    diff = x - bin_centers\n",
    "    soft_counts = tf.exp(-tf.square(diff) / (2.0 * sigma**2))\n",
    "    hist = tf.reduce_sum(soft_counts, axis=0)\n",
    "    hist = hist / tf.reduce_sum(hist)\n",
    "    return hist\n",
    "\n",
    "def kl_divergence_loss_tf(y_true, y_pred, num_bins=50, sigma=1.0):\n",
    "    min_val = tf.reduce_min(y_true)\n",
    "    max_val = tf.reduce_max(y_true)\n",
    "    bin_centers = tf.linspace(min_val, max_val, num_bins)\n",
    "    hist_true = soft_histogram_tf(y_true, bin_centers, sigma)\n",
    "    hist_pred = soft_histogram_tf(y_pred, bin_centers, sigma)\n",
    "    epsilon = 1e-6\n",
    "    hist_true = tf.clip_by_value(hist_true, epsilon, 1.0)\n",
    "    hist_pred = tf.clip_by_value(hist_pred, epsilon, 1.0)\n",
    "    kl_loss = tf.reduce_sum(hist_true * tf.math.log(hist_true / hist_pred))\n",
    "    tf.print(\"KL loss:\", kl_loss, \"hist_true:\", hist_true, \"hist_pred:\", hist_pred)\n",
    "    tf.debugging.check_numerics(kl_loss, message=\"KL divergence loss produced NaN\")\n",
    "    return kl_loss\n",
    "\n",
    "def combined_loss_tf(y_true, y_pred, alpha=0.001):\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    kl_loss = kl_divergence_loss_tf(y_true, y_pred, num_bins=50, sigma=1.0)\n",
    "    total_loss = mse_loss + alpha * kl_loss\n",
    "    tf.debugging.check_numerics(total_loss, message=\"Combined loss produced NaN\")\n",
    "    return total_loss\n",
    "\n",
    "# Build the Keras model\n",
    "model_keras = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile with the combined loss\n",
    "model_keras.compile(optimizer='adam', loss=lambda y_true, y_pred: combined_loss_tf(y_true, y_pred, alpha=0.001))\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "keras-train",
   "metadata": {},
   "source": [
    "### Train the Keras Model\n",
    "\n",
    "Train for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "keras-train-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "KL loss: 5.39482212 hist_true: [0.017519189 0.0178813208 0.0182333346 ... 0.0164428614 0.0160577521 0.01566731] hist_pred: [0.300949037 0.210892424 0.147629216 ... 1e-06 1e-06 1e-06]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 6s/step - loss: 141.6672KL loss: 4.39620829 hist_true: [0.0188708175 0.0191021524 0.0193243269 ... 0.017136801 0.0168500841 0.016557958] hist_pred: [0.249592081 0.187670916 0.141017199 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 4.91314697 hist_true: [0.0183321927 0.0186111312 0.0188804436 ... 0.0169785395 0.0166595876 0.0163348764] hist_pred: [0.274528027 0.199590981 0.144990921 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 4.53845167 hist_true: [0.0185265522 0.0187956672 0.0190550704 ... 0.0168787371 0.01656 0.016235739] hist_pred: [0.25575912 0.190768 0.142182708 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 6.097579 hist_true: [0.0150503581 0.0155044859 0.0159538146 ... 0.0176297091 0.0172109473 0.01678285] hist_pred: [0.329254776 0.22147426 0.148767 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 4.91021252 hist_true: [0.0166319 0.0169658754 0.0172931273 ... 0.0182247553 0.0179202668 0.0176070202] hist_pred: [0.262918949 0.194256097 0.143400252 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 7.64990902 hist_true: [0.00839662459 0.00904951617 0.00973045733 ... 0.0169236585 0.016102327 0.0152803818] hist_pred: [0.402038068 0.241529837 0.144640639 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 4.74781275 hist_true: [0.0214479957 0.0217716638 0.0220739525 ... 0.0123447739 0.0118756434 0.0114120916] hist_pred: [0.294032276 0.208206534 0.147245884 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 5.16163635 hist_true: [0.0167843085 0.0171891749 0.017585177 ... 0.0164686404 0.0160529427 0.015631428] hist_pred: [0.28162235 0.20293349 0.146053076 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 6.26016617 hist_true: [0.0128485514 0.013469 0.0140934158 ... 0.0158054214 0.0151811736 0.0145545322] hist_pred: [0.329300314 0.221841082 0.149119228 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 4.07367802 hist_true: [0.0190921184 0.0193280075 0.0195539333 ... 0.0167286266 0.0164219085 0.0161103178] hist_pred: [0.235803902 0.180617109 0.138245359 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 4.18865061 hist_true: [0.0146707976 0.0151497377 0.0156250577 ... 0.0174572188 0.0170090012 0.0165517908] hist_pred: [0.220078662 0.172485247 0.134993285 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 4.67949581 hist_true: [0.0180900693 0.0184559505 0.0188099053 ... 0.0156425256 0.0152321588 0.0148184821] hist_pred: [0.263439238 0.194654837 0.143663466 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 6.28735876 hist_true: [0.00934393 0.00990829524 0.0104895243 ... 0.0199697111 0.0193491913 0.0187092312] hist_pred: [0.286517739 0.205608174 0.147196293 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 2.55924892 hist_true: [0.0159991086 0.0164230987 0.0168401413 ... 0.0170692652 0.0166578479 0.01623898] hist_pred: [0.160908103 0.135879055 0.114597663 ... 1.44412979e-05 1.14886216e-05 9.12804717e-06]\n",
      "KL loss: 4.87841654 hist_true: [0.0147197554 0.0151952729 0.0156670753 ... 0.0174687244 0.0170228723 0.0165679716] hist_pred: [0.252458304 0.189486519 0.142023981 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 3.48378325 hist_true: [0.0224398803 0.0227920022 0.0231171809 ... 0.0110440683 0.0105577903 0.0100813033] hist_pred: [0.229645163 0.177840978 0.137501195 ... 1e-06 1e-06 1e-06]\n",
      "KL loss: 3.84947133 hist_true: [0.0150076514 0.0154424328 0.0158728939 ... 0.0181208011 0.0177324116 0.0173337422] hist_pred: [0.207214102 0.165026292 0.131267801 ... 1.24803239e-06 1e-06 1e-06]\n",
      "KL loss: 3.14516497 hist_true: [0.0163111109 0.0166274626 0.0169383138 ... 0.0191275273 0.0188771077 0.0186170284] hist_pred: [0.185663268 0.15170595 0.123862028 ... 5.96358677e-06 4.69543465e-06 3.69409599e-06]\n",
      "KL loss: 3.55928612 hist_true: [0.0174944792 0.0178654343 0.0182261784 ... 0.0162822139 0.0158856325 0.015484021] hist_pred: [0.207491368 0.165120944 0.13125667 ... 1.36006838e-06 1.02722493e-06 1e-06]\n",
      "KL loss: 2.31218743 hist_true: [0.0175867043 0.0178958643 0.0181964692 ... 0.0173990354 0.0170776751 0.0167493895] hist_pred: [0.156959891 0.132925034 0.112472326 ... 2.49011482e-05 2.02460014e-05 1.6446962e-05]\n",
      "KL loss: 2.5449903 hist_true: [0.0173900332 0.0178760868 0.0183499958 ... 0.0141030522 0.0135842646 0.0130669391] hist_pred: [0.167283252 0.140314296 0.117515206 ... 8.23751543e-06 6.42780878e-06 5.00791475e-06]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.1273 KL loss: 3.41716218 hist_true: [0.01815884 0.0185879096 0.0190032758 ... 0.01431535 0.0138322469 0.0133493235] hist_pred: [0.205267251 0.164031059 0.130887717 ... 1.11902057e-06 1e-06 1e-06]\n",
      "KL loss: 2.28723788 hist_true: [0.0100162402 0.0105781052 0.0111533385 ... 0.0198543519 0.0192820411 0.0186909735] hist_pred: [0.123069622 0.109426543 0.0970881283 ... 4.85479468e-05 3.90302557e-05 3.13112541e-05]\n",
      "KL loss: 1.45596957 hist_true: [0.0107375989 0.0114214029 0.012121358 ... 0.0154308286 0.0146892397 0.0139506031] hist_pred: [0.0925568566 0.0857940316 0.0793260112 ... 0.000148265171 0.000120902077 9.83024e-05]\n",
      "KL loss: 0.690735042 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0685681 0.0651019 0.0617072769 ... 0.00097729417 0.000857565552 0.000751246524]\n",
      "KL loss: 4.34909916 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.205945954 0.164463013 0.131137848 ... 1.02029435e-06 1e-06 1e-06]\n",
      "KL loss: 1.14493966 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.100713931 0.0912449732 0.0825948566 ... 0.00038317556 0.000333376782 0.000289801479]\n",
      "KL loss: 1.40225899 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.117063761 0.104037844 0.0923782289 ... 0.000172816101 0.000147214436 0.000125292965]\n",
      "KL loss: 3.92894125 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.206589684 0.164688095 0.131118774 ... 1.24178678e-06 1e-06 1e-06]\n",
      "KL loss: 1.33354867 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.114697926 0.102149144 0.0909009203 ... 0.000209138656 0.000179394294 0.000153757515]\n",
      "KL loss: 0.478152484 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0681735 0.0638316721 0.0597528294 ... 0.00243028 0.00225175545 0.00208589]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 129.6594 - val_loss: 81.9014\n",
      "Epoch 2/50\n",
      "KL loss: 1.96051967 hist_true: [0.0161016658 0.0165565237 0.0170036405 ... 0.016245611 0.015786754 0.0153223565] hist_pred: [0.134977937 0.117798805 0.102655232 ... 4.58688155e-05 3.73581606e-05 3.03820125e-05]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 76.7226KL loss: 0.0169188306 hist_true: [0.0106068319 0.0111910747 0.0117870616 ... 0.0187567677 0.0181646887 0.0175586827] hist_pred: [0.0140301716 0.0146823451 0.0153416581 ... 0.0132325562 0.0125496574 0.0118761556]\n",
      "KL loss: 0.534146547 hist_true: [0.0191364381 0.0193298217 0.0195149872 ... 0.0174956508 0.0172460768 0.0169912521] hist_pred: [0.00179261738 0.00195135328 0.00212397659 ... 0.0592589788 0.0630152896 0.0669726357]\n",
      "KL loss: 2.75759792 hist_true: [0.0090500731 0.00970292091 0.0103793684 ... 0.0170854256 0.0163209904 0.0155535452] hist_pred: [0.1353347 0.11900951 0.104351372 ... 1.24667013e-05 9.50347385e-06 7.22210052e-06]\n",
      "KL loss: 0.554047465 hist_true: [0.015618436 0.0160756838 0.0165265836 ... 0.0168236643 0.0163813662 0.0159321297] hist_pred: [0.0631058 0.0601674281 0.0572883971 ... 0.00152175617 0.0013599213 0.00121361401]\n",
      "KL loss: 0.849560738 hist_true: [0.0178067926 0.018327307 0.0188337248 ... 0.0130357137 0.0124866841 0.0119431457] hist_pred: [0.086704351 0.0803883448 0.0744141042 ... 0.000417900592 0.000358208956 0.000306513655]\n",
      "KL loss: 1.71087718 hist_true: [0.0161867458 0.0165714547 0.0169494282 ... 0.0176920164 0.017328728 0.016956795] hist_pred: [0.125166312 0.110283926 0.0970673785 ... 0.00010236926 8.57560881e-05 7.17615403e-05]\n",
      "KL loss: 0.38330844 hist_true: [0.0148153119 0.0152731873 0.0157271437 ... 0.0177932139 0.0173733514 0.0169437435] hist_pred: [0.00228661555 0.00240477477 0.00254757865 ... 0.0521847196 0.0543810874 0.0565955564]\n",
      "KL loss: 0.0302614942 hist_true: [0.0180868041 0.0184610933 0.0188233405 ... 0.0154429786 0.0150184324 0.0145908818] hist_pred: [0.0274240412 0.0273501128 0.0272648949 ... 0.00985981245 0.00940642692 0.00896351319]\n",
      "KL loss: 0.112953216 hist_true: [0.0178338867 0.0181515794 0.0184595697 ... 0.0169158876 0.0165729783 0.0162239764] hist_pred: [0.0374749489 0.0366870202 0.0358995423 ... 0.00692023803 0.00654976256 0.00619348884]\n",
      "KL loss: 0.00655274279 hist_true: [0.0189432111 0.0195563976 0.0201498419 ... 0.010548126 0.009965064 0.00939816888] hist_pred: [0.0232266132 0.0237018503 0.0241432786 ... 0.00852728635 0.00799168646 0.00747759687]\n",
      "KL loss: 0.0266315211 hist_true: [0.018375583 0.018715227 0.0190429688 ... 0.0157513078 0.0153564289 0.0149579551] hist_pred: [0.0273674745 0.0265928432 0.0258372836 ... 0.0235638283 0.0241241828 0.0246949121]\n",
      "KL loss: 0.427233338 hist_true: [0.0161539819 0.0165803228 0.0169991367 ... 0.0168454275 0.0164280403 0.0160038527] hist_pred: [0.0582289323 0.055659689 0.053155411 ... 0.00227128807 0.00206293399 0.00187145802]\n",
      "KL loss: 0.0798050612 hist_true: [0.017574627 0.0180379953 0.0184887107 ... 0.0143831493 0.0138845192 0.0133861145] hist_pred: [0.0326762162 0.0324790515 0.0322542153 ... 0.00650205091 0.00607574778 0.00566919707]\n",
      "KL loss: 0.0184011329 hist_true: [0.0180823375 0.0184709076 0.0188470222 ... 0.0151837524 0.01474493 0.0143038006] hist_pred: [0.0290231463 0.0285327137 0.0280469842 ... 0.0139076114 0.0136816567 0.0134539828]\n",
      "KL loss: 0.0144088892 hist_true: [0.00925288908 0.00979538821 0.0103532504 ... 0.0212856121 0.020758301 0.0202070083] hist_pred: [0.0176942497 0.0174828246 0.0173131302 ... 0.0216840208 0.0215207972 0.0213441234]\n",
      "KL loss: 0.0363769867 hist_true: [0.014797017 0.0152866868 0.0157722142 ... 0.0170755256 0.0166110806 0.0161387641] hist_pred: [0.0288500562 0.028333718 0.0278285872 ... 0.0141427675 0.0139801195 0.0138264475]\n",
      "KL loss: 0.167486101 hist_true: [0.00928145461 0.00994647387 0.0106347008 ... 0.0165219158 0.0157430191 0.0149638318] hist_pred: [0.0402342044 0.0388682224 0.0375043377 ... 0.0139752617 0.0139816189 0.0139844744]\n",
      "KL loss: 0.0268599838 hist_true: [0.0190074295 0.019339243 0.0196576696 ... 0.0150371362 0.0146210566 0.014202971] hist_pred: [0.0285547823 0.0283775833 0.028188223 ... 0.0101003675 0.00967976544 0.00926779769]\n",
      "KL loss: 0.379312783 hist_true: [0.0132698938 0.0137194674 0.0141694257 ... 0.020046398 0.0197027512 0.0193436202] hist_pred: [0.0496197268 0.0479186624 0.0462363511 ... 0.00363064348 0.0033548018 0.00309664197]\n",
      "KL loss: 0.0306315571 hist_true: [0.0135477632 0.0140473163 0.0145466682 ... 0.0182794407 0.0178268496 0.0173625611] hist_pred: [0.0224431641 0.022626536 0.0227959435 ... 0.0127956886 0.0123593789 0.0119261071]\n",
      "KL loss: 0.00354911573 hist_true: [0.0196426846 0.0198448244 0.0200368389 ... 0.016608851 0.016316317 0.0160195846] hist_pred: [0.0241101123 0.0238408819 0.0235791318 ... 0.0182267595 0.0182561688 0.0182930231]\n",
      "KL loss: 0.00976283662 hist_true: [0.0141983349 0.0146898776 0.0151792336 ... 0.0177041162 0.0172474924 0.0167809688] hist_pred: [0.0214023385 0.0213323645 0.0212653466 ... 0.0182266328 0.0180870593 0.0179431699]\n",
      "KL loss: 0.0379871 hist_true: [0.0139409211 0.0144735835 0.015004972 ... 0.0169775207 0.0164661929 0.0159472264] hist_pred: [0.0271158982 0.0268973913 0.0266660154 ... 0.0144820567 0.0143495705 0.014220899]\n",
      "KL loss: 0.00813580304 hist_true: [0.015635306 0.0160518382 0.0164624918 ... 0.0177297816 0.0173445772 0.0169502571] hist_pred: [0.0219113976 0.0219113585 0.0219055358 ... 0.0173713397 0.0172613878 0.0171542577]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.3849  KL loss: 0.0226398613 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0256291423 0.0254282933 0.0252238754 ... 0.0151269846 0.015005148 0.0148955043]\n",
      "KL loss: 0.0538997352 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0246832632 0.0245519839 0.0244139 ... 0.0151573094 0.0149351982 0.0147131588]\n",
      "KL loss: 0.00293817231 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0207235161 0.0208044741 0.0208805744 ... 0.0169421174 0.0167131219 0.0164819956]\n",
      "KL loss: 0.0146379527 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0264756829 0.0262478366 0.0260149762 ... 0.014306928 0.0141212726 0.0139422156]\n",
      "KL loss: 0.00397841865 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0186120309 0.0186365638 0.018668877 ... 0.0199185722 0.0197606124 0.0195918903]\n",
      "KL loss: 0.00300950976 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.02199688 0.0218229126 0.0216574986 ... 0.0190247968 0.0189709608 0.0189145692]\n",
      "KL loss: 0.00191146228 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.017420223 0.0175505932 0.0176798366 ... 0.0217712969 0.0218188986 0.0218647234]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 64.8480 - val_loss: 28.3072\n",
      "Epoch 3/50\n",
      "KL loss: 0.00640201708 hist_true: [0.0152654536 0.0156986024 0.0161266867 ... 0.0178347323 0.0174400378 0.0170358494] hist_pred: [0.0204417054 0.020379018 0.0203207154 ... 0.020493716 0.020579081 0.0206695665]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 22.1243KL loss: 0.005650579 hist_true: [0.0178131238 0.0182132367 0.0186014604 ... 0.0152658941 0.0148195177 0.0143704405] hist_pred: [0.0214589741 0.0213442836 0.0212332439 ... 0.0189208779 0.0188169125 0.0187070519]\n",
      "KL loss: 0.00233054068 hist_true: [0.0173015129 0.017542908 0.0177788027 ... 0.019326305 0.0191403385 0.0189466495] hist_pred: [0.0206237342 0.0206294097 0.0206354987 ... 0.018379271 0.0182507243 0.0181194488]\n",
      "KL loss: 0.00236674957 hist_true: [0.0184361208 0.0187499411 0.0190524664 ... 0.016187286 0.0158222429 0.0154528012] hist_pred: [0.0198584646 0.0198937021 0.019929057 ... 0.018898258 0.0187629629 0.0186224096]\n",
      "KL loss: 0.0664050132 hist_true: [0.0105456058 0.0111265248 0.0117202727 ... 0.0184926111 0.0178670939 0.0172284301] hist_pred: [0.024149172 0.0242610574 0.0243605897 ... 0.0122951288 0.0119845867 0.0116864452]\n",
      "KL loss: 0.00666071754 hist_true: [0.0209901631 0.0212450586 0.0214829221 ... 0.013979475 0.0135752205 0.0131717958] hist_pred: [0.027571125 0.0271962211 0.0268226694 ... 0.0153164482 0.0152713694 0.0152385365]\n",
      "KL loss: 0.0359644964 hist_true: [0.0145122288 0.0151396561 0.0157647226 ... 0.0141653642 0.0135442745 0.0129268561] hist_pred: [0.0283929575 0.0279533248 0.0275033358 ... 0.0171285905 0.0172110125 0.017291354]\n",
      "KL loss: 0.0156367458 hist_true: [0.0142065017 0.0146347564 0.0150609352 ... 0.0193701852 0.0190295279 0.0186757352] hist_pred: [0.0145186363 0.0145277251 0.0145554915 ... 0.0274036974 0.0277273878 0.0280439164]\n",
      "KL loss: 0.0154263917 hist_true: [0.0142140687 0.0146576893 0.0150990561 ... 0.0189732909 0.0186048616 0.0182239246] hist_pred: [0.0226189531 0.0225163419 0.0224168953 ... 0.0176132843 0.0175651424 0.0175249558]\n",
      "KL loss: 0.0481991544 hist_true: [0.0145319691 0.0149533898 0.0153719047 ... 0.0191051494 0.0187619627 0.0184063781] hist_pred: [0.0290398747 0.0285947751 0.0281492844 ... 0.0139194056 0.0137512349 0.0135870911]\n",
      "KL loss: 0.0112291118 hist_true: [0.0203754958 0.02075826 0.0211209692 ... 0.0126784276 0.0121956728 0.0117179779] hist_pred: [0.0290004741 0.0286820717 0.02835867 ... 0.0116634052 0.0113626551 0.0110706165]\n",
      "KL loss: 0.0727297142 hist_true: [0.0126962941 0.0132385725 0.0137837538 ... 0.0180916339 0.0175828859 0.0170627329] hist_pred: [0.0289693754 0.0287684817 0.0285459775 ... 0.012050597 0.0118323602 0.011621478]\n",
      "KL loss: 0.00426589279 hist_true: [0.0179733485 0.0182818454 0.0185807496 ... 0.0168634504 0.0165212452 0.0161730889] hist_pred: [0.0228672605 0.0228013359 0.0227312837 ... 0.0167264193 0.0165836494 0.0164439827]\n",
      "KL loss: 0.00237169629 hist_true: [0.0182111282 0.0185203459 0.0188190397 ... 0.0165877622 0.0162395462 0.0158861168] hist_pred: [0.0185040236 0.01863016 0.0187547337 ... 0.019435551 0.0193040334 0.0191678777]\n",
      "KL loss: 0.056603387 hist_true: [0.0125848651 0.0130901653 0.0135982018 ... 0.0192759112 0.0188361164 0.0183813777] hist_pred: [0.0285184216 0.0280823112 0.0276481 ... 0.0161940735 0.0163279977 0.0164809357]\n",
      "KL loss: 0.00134355482 hist_true: [0.016292775 0.0166137554 0.0169291794 ... 0.0190411415 0.0187830292 0.0185152553] hist_pred: [0.0184994414 0.0185733959 0.0186488256 ... 0.020554753 0.0205149315 0.0204702131]\n",
      "KL loss: 0.0231405348 hist_true: [0.00934353564 0.0101065803 0.0109014958 ... 0.0129794842 0.0121150864 0.0112748537] hist_pred: [0.0182051118 0.0185455 0.0189074967 ... 0.0136547247 0.0132425493 0.012837234]\n",
      "KL loss: 0.0170941092 hist_true: [0.0104770688 0.0111302789 0.011799139 ... 0.0165757593 0.0158669241 0.0151549028] hist_pred: [0.0189399533 0.0189486295 0.0189698525 ... 0.0191870853 0.0190261211 0.0188653488]\n",
      "KL loss: 0.00898834318 hist_true: [0.0192592796 0.0195494834 0.0198269691 ... 0.0154887121 0.0151082668 0.0147248432] hist_pred: [0.0180285629 0.0181339625 0.0182396546 ... 0.0208610781 0.0208293833 0.0207920671]\n",
      "KL loss: 0.0078321863 hist_true: [0.0171938166 0.0174998064 0.0177983325 ... 0.0180462226 0.0177545901 0.0174550209] hist_pred: [0.0235034656 0.0233717877 0.0232376885 ... 0.0173118 0.0172679275 0.0172313508]\n",
      "KL loss: 0.00970819 hist_true: [0.0176143032 0.0179403126 0.0182571579 ... 0.0170057938 0.0166584868 0.0163047519] hist_pred: [0.0188835654 0.0189142972 0.0189386681 ... 0.0234420802 0.02378764 0.0241443422]\n",
      "KL loss: 0.147327721 hist_true: [0.0181199983 0.0185074285 0.0188824721 ... 0.0151216295 0.0146793388 0.0142348735] hist_pred: [0.0436626971 0.0424037352 0.041153755 ... 0.00621619448 0.00603982434 0.00588885881]\n",
      "KL loss: 0.0378830917 hist_true: [0.0173609443 0.0177522413 0.0181331132 ... 0.0160714146 0.0156584475 0.0152409961] hist_pred: [0.0309692658 0.0305050034 0.0300331395 ... 0.0124064535 0.0122425966 0.0120870387]\n",
      "KL loss: 0.00268328842 hist_true: [0.0170384441 0.0173898134 0.0177328475 ... 0.0172779635 0.0169255752 0.0165659934] hist_pred: [0.0209459048 0.020918861 0.0208945069 ... 0.018247515 0.0181089379 0.0179665182]\n",
      "KL loss: 0.0436011516 hist_true: [0.0169985611 0.0174880475 0.017966602 ... 0.014471503 0.0139551936 0.0134390937] hist_pred: [0.0326704197 0.0317811333 0.0309006777 ... 0.0188757982 0.0193563551 0.0198571496]\n",
      "KL loss: 0.0271321442 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0270842984 0.0264891274 0.025908798 ... 0.0195723064 0.0197338574 0.0198936369]\n",
      "KL loss: 0.047604803 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0245995559 0.0243671853 0.0241396073 ... 0.0161055736 0.0159301981 0.0157540962]\n",
      "KL loss: 0.00401274348 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0219875854 0.0218819957 0.021780584 ... 0.0181857254 0.0181046966 0.0180254299]\n",
      "KL loss: 0.00350160105 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.022711901 0.02262046 0.0225276221 ... 0.0171904769 0.0170554463 0.0169202052]\n",
      "KL loss: 0.0460927077 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.027873259 0.0275348127 0.0271994378 ... 0.013420552 0.0132085579 0.0130048459]\n",
      "KL loss: 0.00181284593 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0214427374 0.0214962792 0.0215457249 ... 0.0160615277 0.015781315 0.0154988449]\n",
      "KL loss: 0.0229347777 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0307472404 0.0299335029 0.0291446708 ... 0.0175173506 0.0177683402 0.0180419143]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24.6894 - val_loss: 18.0574\n",
      "Epoch 4/50\n",
      "KL loss: 0.0585821792 hist_true: [0.0155154988 0.0159424469 0.0163638461 ... 0.0176021867 0.0172014739 0.016791746] hist_pred: [0.0323856063 0.0317749046 0.0311586447 ... 0.0136708161 0.0137178535 0.0137827909]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - loss: 22.1024KL loss: 0.0154273678 hist_true: [0.0173790324 0.0178118106 0.0182331353 ... 0.0152251627 0.0147646694 0.0143018905] hist_pred: [0.0266567208 0.0263686292 0.0260713641 ... 0.0166415237 0.0166945513 0.0167589951]\n",
      "KL loss: 0.012412155 hist_true: [0.0173042696 0.017638443 0.0179640464 ... 0.01727199 0.0169301312 0.0165812671] hist_pred: [0.0251177605 0.0249490552 0.0247728508 ... 0.015769951 0.0156536866 0.0155428387]\n",
      "KL loss: 0.0223348308 hist_true: [0.00885939412 0.00943905 0.0100382594 ... 0.0199037157 0.0192578156 0.0185936] hist_pred: [0.0190040562 0.0187996663 0.018623 ... 0.0207933076 0.0205908399 0.0203757603]\n",
      "KL loss: 0.00760234939 hist_true: [0.0179702491 0.0183361173 0.0186905656 ... 0.0157383867 0.0153254196 0.0149086127] hist_pred: [0.0242914762 0.0242290497 0.0241563506 ... 0.0147823626 0.0145389559 0.0142975841]\n",
      "KL loss: 0.00714745652 hist_true: [0.016540356 0.0169219654 0.0172959901 ... 0.0172672905 0.0168909393 0.0165069364] hist_pred: [0.0229601469 0.0227945112 0.0226348713 ... 0.0178978294 0.0178485438 0.0178029742]\n",
      "KL loss: 0.00761631597 hist_true: [0.0178502705 0.0181914456 0.0185223054 ... 0.0163831152 0.0160052702 0.0156222479] hist_pred: [0.0244425405 0.024133401 0.0238323584 ... 0.0183967855 0.0184448194 0.0185002517]\n",
      "KL loss: 0.00607451051 hist_true: [0.0160844903 0.016420275 0.0167506654 ... 0.0189935 0.018721018 0.0184385236] hist_pred: [0.0217841752 0.0216838084 0.0215887465 ... 0.017964378 0.0178141482 0.0176590309]\n",
      "KL loss: 0.0191014782 hist_true: [0.024187509 0.024542395 0.02486315 ... 0.00938588474 0.00889702607 0.00842348766] hist_pred: [0.0360428952 0.0351224281 0.0342058763 ... 0.0122367609 0.0121646412 0.0120960847]\n",
      "KL loss: 0.00951201841 hist_true: [0.0142853968 0.0149157839 0.0155450692 ... 0.0142456135 0.0136191836 0.0129965106] hist_pred: [0.0167161934 0.0167472363 0.0168111399 ... 0.0194789879 0.0191840585 0.0188811366]\n",
      "KL loss: 0.00972917117 hist_true: [0.0173153039 0.0176893231 0.0180535298 ... 0.0164473448 0.0160524193 0.015651891] hist_pred: [0.0209888369 0.0207180157 0.0204682853 ... 0.0220175758 0.0221782122 0.0223401338]\n",
      "KL loss: 0.0124076195 hist_true: [0.0156889446 0.0160972085 0.0164994653 ... 0.0178826209 0.0175113678 0.0171308182] hist_pred: [0.0234755166 0.0233530141 0.0232312884 ... 0.0160325151 0.0158376377 0.015646724]\n",
      "KL loss: 0.00612926111 hist_true: [0.0186389815 0.0190106 0.0193686951 ... 0.0147671523 0.0143231833 0.0138779245] hist_pred: [0.0241933521 0.0240070913 0.0238163937 ... 0.0170810968 0.0169617031 0.0168376584]\n",
      "KL loss: 0.0202657618 hist_true: [0.0128564648 0.0133394944 0.013824204 ... 0.0196212586 0.0192230586 0.0188095775] hist_pred: [0.02142125 0.0214183815 0.0214208495 ... 0.0157997068 0.0154608311 0.0151184332]\n",
      "KL loss: 0.0351787843 hist_true: [0.0141737172 0.0147499507 0.0153242229 ... 0.0157414302 0.0151775638 0.0146105951] hist_pred: [0.0270635728 0.026838446 0.0266090333 ... 0.0124000413 0.0120738326 0.011756232]\n",
      "KL loss: 0.0572631881 hist_true: [0.0100744059 0.010619347 0.0111765331 ... 0.0205660556 0.0200522821 0.0195177868] hist_pred: [0.0242777634 0.0241828747 0.0240762681 ... 0.0158291347 0.0156540144 0.0154786026]\n",
      "KL loss: 0.095903568 hist_true: [0.00964295678 0.010306607 0.0109913656 ... 0.0163417086 0.0155657092 0.0147892283] hist_pred: [0.0297105052 0.0293698944 0.0290167816 ... 0.0143870534 0.0143970037 0.0144105572]\n",
      "KL loss: 0.0469436795 hist_true: [0.0141279986 0.0146462768 0.0151625872 ... 0.0171172246 0.0166216 0.016117759] hist_pred: [0.0278450344 0.0276488848 0.0274425149 ... 0.0134291267 0.0133687668 0.0133275958]\n",
      "KL loss: 0.129187316 hist_true: [0.0108531518 0.0114491684 0.0120564047 ... 0.0181543846 0.0175420735 0.0169182252] hist_pred: [0.0351311676 0.0343392976 0.033544451 ... 0.0114305811 0.0112680877 0.0111128716]\n",
      "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.0118  KL loss: 0.0131674409 hist_true: [0.0165570341 0.0168658476 0.0171687733 ... 0.0189310871 0.0186775662 0.0184148829] hist_pred: [0.0243421104 0.024155518 0.023967959 ... 0.0170718506 0.0170542449 0.0170468912]\n",
      "KL loss: 0.00843719207 hist_true: [0.0156500749 0.0160570461 0.0164582618 ... 0.0179347452 0.017564455 0.0171847437] hist_pred: [0.0206077434 0.0203498397 0.0201092772 ... 0.0223372541 0.0224494655 0.0225539841]\n",
      "KL loss: 0.00488088094 hist_true: [0.0185022671 0.0188111346 0.0191087015 ... 0.0161886346 0.0158258025 0.0154585671] hist_pred: [0.0237135794 0.0234917365 0.0232745 ... 0.0179804135 0.0179494228 0.0179205239]\n",
      "KL loss: 0.00545798801 hist_true: [0.017043829 0.0174509175 0.0178481676 ... 0.0161310155 0.0157068148 0.0152777098] hist_pred: [0.0204598587 0.0204637479 0.0204638299 ... 0.0198799018 0.0198997017 0.0199179016]\n",
      "KL loss: 0.00715300627 hist_true: [0.0197801776 0.0202372745 0.0206743442 ... 0.0121126911 0.0115900869 0.0110751595] hist_pred: [0.023148533 0.0230170675 0.0228891298 ... 0.0161731783 0.0159212239 0.0156643633]\n",
      "KL loss: 0.00902865082 hist_true: [0.0127126686 0.0132183395 0.0137263536 ... 0.0191324912 0.0186919551 0.0182370897] hist_pred: [0.0188709851 0.0189990941 0.0191288386 ... 0.0181526858 0.0179245025 0.0176919904]\n",
      "KL loss: 0.0225831531 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0252231043 0.024769064 0.0243237279 ... 0.0204492714 0.0206201933 0.0207873397]\n",
      "KL loss: 0.0961257666 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0285712332 0.028316468 0.0280509312 ... 0.012386525 0.0121707851 0.0119649917]\n",
      "KL loss: 0.00506526046 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0222090557 0.0220283251 0.0218524132 ... 0.0198750012 0.0199522749 0.0200329088]\n",
      "KL loss: 0.00514290389 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0215494577 0.0213782545 0.0212149359 ... 0.0203620624 0.0204345249 0.0205078255]\n",
      "KL loss: 0.0617713183 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.030828638 0.0302724671 0.0297202915 ... 0.0133366054 0.0132451355 0.0131669948]\n",
      "KL loss: 0.00427112821 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0230702683 0.0228765421 0.0226863772 ... 0.0187441073 0.0187675096 0.0187951922]\n",
      "KL loss: 0.00485418178 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0185587686 0.0184956323 0.0184391849 ... 0.0240097512 0.0243244041 0.0246470254]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.6752 - val_loss: 12.2498\n",
      "Epoch 5/50\n",
      "KL loss: 0.0561798438 hist_true: [0.0102165947 0.0108212307 0.0114402445 ... 0.0183309 0.0176910665 0.0170394331] hist_pred: [0.0246995352 0.0245749243 0.0244528279 ... 0.0143186422 0.014119491 0.0139339855]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.1719KL loss: 0.00537562743 hist_true: [0.0171459746 0.0175043121 0.017853843 ... 0.0169725604 0.0166033655 0.0162274633] hist_pred: [0.0200777929 0.019978635 0.0198874306 ... 0.0209767334 0.0210018493 0.0210207775]\n",
      "KL loss: 0.00228324253 hist_true: [0.0186697468 0.0189826135 0.0192836672 ... 0.0158562567 0.0154775809 0.0150951] hist_pred: [0.0223745089 0.0223081727 0.0222416315 ... 0.0168729071 0.0166911148 0.016508596]\n",
      "KL loss: 0.007310885 hist_true: [0.0193233229 0.0195443239 0.0197553262 ... 0.0166906714 0.0163907092 0.0160861332] hist_pred: [0.0255748034 0.0250391401 0.0245278925 ... 0.0196365286 0.0197772719 0.0199234784]\n",
      "KL loss: 0.0136483982 hist_true: [0.0179500449 0.0182186868 0.0184791218 ... 0.0177440885 0.0174640771 0.0171773415] hist_pred: [0.0268770214 0.0264635049 0.0260540769 ... 0.0171093103 0.0171491597 0.0171966571]\n",
      "KL loss: 0.00245439541 hist_true: [0.0190903619 0.0194479302 0.019790601 ... 0.014574063 0.0141401105 0.0137055758] hist_pred: [0.0224271044 0.0224894285 0.022540126 ... 0.0159932636 0.0158413015 0.0156966783]\n",
      "KL loss: 0.00513037853 hist_true: [0.0188662149 0.0191213265 0.0193661973 ... 0.0167084504 0.0163930971 0.0160728116] hist_pred: [0.0178979766 0.0180342942 0.0181685183 ... 0.0209537689 0.0209651906 0.0209758971]\n",
      "KL loss: 0.0398533791 hist_true: [0.0162856821 0.0166738462 0.0170548838 ... 0.0174984951 0.0171276778 0.0167487059] hist_pred: [0.0288922098 0.0285429321 0.0281916019 ... 0.011954 0.0116321994 0.0113151278]\n",
      "KL loss: 0.0501012914 hist_true: [0.0134253073 0.013969291 0.014513907 ... 0.017171368 0.0166406594 0.0161013585] hist_pred: [0.0290035587 0.0285193063 0.0280456804 ... 0.0126028946 0.0122891143 0.0119817881]\n",
      "KL loss: 0.0123711666 hist_true: [0.0187458359 0.0190053862 0.019254921 ... 0.0167742856 0.016457893 0.0161363464] hist_pred: [0.0264511146 0.0262007378 0.0259477217 ... 0.0143596055 0.0141516123 0.0139476499]\n",
      "KL loss: 0.00470204093 hist_true: [0.017547382 0.0179443918 0.0183303971 ... 0.0156748481 0.0152431615 0.0148078175] hist_pred: [0.0226763953 0.0226156972 0.0225518923 ... 0.0168819502 0.0167385414 0.0165962391]\n",
      "KL loss: 0.0605404899 hist_true: [0.0104739042 0.011075112 0.011689554 ... 0.0181886945 0.0175532456 0.016906308] hist_pred: [0.0258499123 0.0256793164 0.0255045276 ... 0.0144211333 0.0142365647 0.0140570439]\n",
      "KL loss: 0.00370648038 hist_true: [0.0181453209 0.0184659828 0.0187760424 ... 0.0164097901 0.0160452574 0.0156755839] hist_pred: [0.0227534361 0.0226557497 0.0225572903 ... 0.0174141191 0.0173169244 0.0172217079]\n",
      "KL loss: 0.0462686308 hist_true: [0.0144463303 0.0148985647 0.0153480377 ... 0.0183725655 0.0179708712 0.0175577495] hist_pred: [0.0290630553 0.0286124703 0.0281622261 ... 0.013802046 0.0136125861 0.0134264864]\n",
      "KL loss: 0.00529506058 hist_true: [0.0175065529 0.01784808 0.0181802846 ... 0.0168340541 0.0164712053 0.0161021687] hist_pred: [0.0210558325 0.0208991934 0.0207515676 ... 0.0205247197 0.0205592792 0.020589916]\n",
      "KL loss: 0.0220570695 hist_true: [0.0107806474 0.0114574162 0.0121499579 ... 0.0155679006 0.0148338797 0.0141020203] hist_pred: [0.0209206473 0.0208301414 0.0207621064 ... 0.0172914788 0.0171374418 0.0169928744]\n",
      "KL loss: 0.00626488589 hist_true: [0.0145528829 0.0149506209 0.0153456908 ... 0.0196838938 0.0193853062 0.019073762] hist_pred: [0.020584166 0.0204506796 0.0203285981 ... 0.0199251603 0.0198502466 0.0197675712]\n",
      "KL loss: 0.0110525955 hist_true: [0.0177849736 0.0182126481 0.0186276156 ... 0.0148641225 0.0144006135 0.013935904] hist_pred: [0.0260909814 0.0258488562 0.0256089438 ... 0.0137975439 0.0135105867 0.0132270316]\n",
      "KL loss: 0.0336976312 hist_true: [0.013933653 0.0146004157 0.0152679384 ... 0.0138168875 0.0131662209 0.0125221256] hist_pred: [0.0279015284 0.0272265971 0.026563501 ... 0.0178886224 0.0178042669 0.0177112184]\n",
      "KL loss: 0.0314864591 hist_true: [0.0190049261 0.0195376966 0.0200513396 ... 0.0117788324 0.0112287365 0.0106886448] hist_pred: [0.0195137337 0.0191519689 0.0188485235 ... 0.0208204892 0.0206554383 0.0204737019]\n",
      "KL loss: 0.00234563975 hist_true: [0.0159168988 0.0162941217 0.016665535 ... 0.0182293188 0.0178908426 0.0175426938] hist_pred: [0.0193988085 0.0193651 0.0193408132 ... 0.019696299 0.0195392128 0.0193700735]\n",
      "KL loss: 0.0286762249 hist_true: [0.0180756897 0.0183933284 0.018700771 ... 0.0165450163 0.0161862224 0.0158220585] hist_pred: [0.0292284545 0.0288748592 0.0285156127 ... 0.0125005133 0.0122947991 0.0121006258]\n",
      "KL loss: 0.0761921 hist_true: [0.0099604167 0.010518725 0.0110902628 ... 0.0201815609 0.0196354222 0.0190699119] hist_pred: [0.0272179 0.0268960968 0.0265705641 ... 0.0158631466 0.0158955082 0.0159412045]\n",
      "KL loss: 0.0126895551 hist_true: [0.0176388919 0.0181207135 0.0185891334 ... 0.0140177216 0.0135064488 0.0129967276] hist_pred: [0.0207048487 0.0205391627 0.0203868803 ... 0.0202326067 0.0202042628 0.0201729108]\n",
      "KL loss: 0.0278029907 hist_true: [0.0132345762 0.0137574654 0.0142809944 ... 0.0181098431 0.0176325236 0.017143853] hist_pred: [0.0261632036 0.0256407131 0.0251425989 ... 0.0160392821 0.0157570094 0.0154651199]\n",
      "KL loss: 0.0291793831 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0278648566 0.0273846574 0.0269159116 ... 0.0159663558 0.0159489643 0.0159399211]\n",
      "KL loss: 0.0916267708 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0273086652 0.0271659791 0.0270099826 ... 0.0118707158 0.0115671251 0.0112742195]\n",
      "KL loss: 0.0106321918 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0248476397 0.024571972 0.0243001077 ... 0.0174656659 0.0174573138 0.0174547806]\n",
      "KL loss: 0.00878365058 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0255983397 0.0252628867 0.0249330103 ... 0.0169946309 0.0169414952 0.016890632]\n",
      "KL loss: 0.0949795097 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0337102748 0.0330493934 0.0323919505 ... 0.010663406 0.0104732085 0.0102989413]\n",
      "KL loss: 0.00860799104 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0255664885 0.0252707228 0.0249783 ... 0.0167004261 0.0166630968 0.0166327264]\n",
      "KL loss: 0.00103085209 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0205076132 0.0204152483 0.0203260854 ... 0.0213362779 0.0214989558 0.0216683503]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.4370 - val_loss: 8.5035\n",
      "Epoch 6/50\n",
      "KL loss: 0.00369520858 hist_true: [0.0180776604 0.0183590446 0.0186314825 ... 0.017274769 0.0169654805 0.0166498926] hist_pred: [0.0200917665 0.0200131685 0.0199415293 ... 0.0207741708 0.0208132062 0.0208501834]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.7091KL loss: 0.00372752687 hist_true: [0.0133041432 0.0137834437 0.0142631494 ... 0.019143004 0.018735433 0.0183139574] hist_pred: [0.0169138592 0.0170165319 0.0171282366 ... 0.0215388499 0.0214888304 0.0214313753]\n",
      "KL loss: 0.00853938609 hist_true: [0.0197976083 0.0200039763 0.0201995913 ... 0.016302634 0.0159943793 0.0156822838] hist_pred: [0.0263873376 0.0261439793 0.0258966181 ... 0.0145360734 0.0143419597 0.0141514651]\n",
      "KL loss: 0.0665065125 hist_true: [0.00854845904 0.00920077413 0.00988037 ... 0.0167200379 0.0158886146 0.0150573393] hist_pred: [0.0272951797 0.0265082568 0.0257725921 ... 0.0172903966 0.017156383 0.0170130469]\n",
      "KL loss: 0.0389573537 hist_true: [0.0151270526 0.0156569723 0.016181821 ... 0.0156874582 0.0151570402 0.014623126] hist_pred: [0.0288674757 0.028541971 0.0282103699 ... 0.0124339703 0.0121917678 0.0119573958]\n",
      "KL loss: 0.00274418597 hist_true: [0.0179769229 0.0182464812 0.0185077395 ... 0.0176847614 0.0174016096 0.0171117987] hist_pred: [0.0221106447 0.0220200922 0.0219311975 ... 0.0176680367 0.0175185185 0.0173650645]\n",
      "KL loss: 0.00700948434 hist_true: [0.0185180753 0.0188280959 0.0191268977 ... 0.0160935447 0.0157228298 0.0153477229] hist_pred: [0.0255542845 0.0251597892 0.0247794129 ... 0.0169312041 0.0168218967 0.0167112183]\n",
      "KL loss: 0.0245386045 hist_true: [0.0175533555 0.0180215575 0.0184770375 ... 0.0143447807 0.013846064 0.0133478623] hist_pred: [0.0290467255 0.0287389494 0.0284222513 ... 0.0130385365 0.0129260235 0.0128274783]\n",
      "KL loss: 0.101517603 hist_true: [0.0146379657 0.0151794329 0.0157172736 ... 0.0160378255 0.015509123 0.0149760544] hist_pred: [0.0365201905 0.0357772522 0.0350182913 ... 0.00986361131 0.00969501585 0.00953811593]\n",
      "KL loss: 0.00836559758 hist_true: [0.0184892043 0.0191401597 0.0197722726 ... 0.0105199208 0.00993171614 0.00936033297] hist_pred: [0.0255258102 0.0253926944 0.0252560489 ... 0.0129139265 0.0125772357 0.0122477561]\n",
      "KL loss: 0.0143642081 hist_true: [0.0176069029 0.0179622117 0.0183075666 ... 0.0163969547 0.0160089452 0.015615508] hist_pred: [0.0271003488 0.0266820155 0.0262682904 ... 0.0162839703 0.0162264463 0.0161718708]\n",
      "KL loss: 0.0120845474 hist_true: [0.0145134199 0.0149404854 0.0153646953 ... 0.0189514495 0.0185942054 0.0182245784] hist_pred: [0.0222309977 0.0221096557 0.0219866801 ... 0.019430792 0.0194861293 0.0195429958]\n",
      "KL loss: 0.0240802076 hist_true: [0.0138818389 0.0143714491 0.0148596019 ... 0.0181884058 0.0177473892 0.017294975] hist_pred: [0.0236899573 0.0236422736 0.023587117 ... 0.0146929417 0.0143775344 0.01406042]\n",
      "KL loss: 0.0361111611 hist_true: [0.00987517182 0.0105721317 0.0112911295 ... 0.0153155783 0.014529814 0.0137500074] hist_pred: [0.0224667769 0.0224205498 0.0223843437 ... 0.0144620677 0.0141089242 0.0137610119]\n",
      "KL loss: 0.00315444 hist_true: [0.01880976 0.0192223713 0.0196193699 ... 0.0139331874 0.0134577258 0.0129837086] hist_pred: [0.0236662142 0.0235816333 0.0234991834 ... 0.0143028861 0.0139663043 0.0136319995]\n",
      "KL loss: 0.101536 hist_true: [0.010402563 0.011029073 0.0116704777 ... 0.0173807181 0.0167021919 0.016016474] hist_pred: [0.0314100198 0.0308675896 0.0303235892 ... 0.0113849165 0.0110923201 0.0108087743]\n",
      "KL loss: 0.00760940881 hist_true: [0.0180276204 0.0183783434 0.0187179521 ... 0.0159527138 0.0155547112 0.0151524069] hist_pred: [0.0247071236 0.024404224 0.024106089 ... 0.0178401601 0.0178049169 0.0177687164]\n",
      "KL loss: 0.0108487532 hist_true: [0.0136134364 0.0141495056 0.0146853924 ... 0.0172395445 0.01672576 0.0162033252] hist_pred: [0.0190757401 0.0189619884 0.0188612416 ... 0.0221365727 0.0221849345 0.0222246889]\n",
      "KL loss: 0.00493883248 hist_true: [0.0194864795 0.0197232217 0.0199487396 ... 0.0161794107 0.0158516299 0.0155199412] hist_pred: [0.0206199866 0.0205233935 0.0204327442 ... 0.0203468706 0.0203772075 0.0204067472]\n",
      "KL loss: 0.0149140256 hist_true: [0.016617218 0.0169012956 0.0171800796 ... 0.019420784 0.0192094389 0.0189890973] hist_pred: [0.0236566104 0.0235833433 0.0235045664 ... 0.0155588798 0.0153440498 0.0151305795]\n",
      "KL loss: 0.00906176 hist_true: [0.0165578015 0.0170244761 0.0174816512 ... 0.0155427773 0.0150697073 0.0145936292] hist_pred: [0.0236040838 0.0235700253 0.0235278 ... 0.0148918638 0.0146162128 0.0143405208]\n",
      "KL loss: 0.00567435659 hist_true: [0.0171898473 0.0175592322 0.0179194771 ... 0.0166648123 0.0162769537 0.0158829521] hist_pred: [0.0229542963 0.0228440203 0.022730628 ... 0.0172649268 0.0171231348 0.0169778187]\n",
      "KL loss: 0.0376157835 hist_true: [0.0148724075 0.0153164649 0.0157565046 ... 0.0180695429 0.0176711176 0.0172624122] hist_pred: [0.027783202 0.0274828877 0.027173439 ... 0.0144214407 0.0143056773 0.014197275]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1995 KL loss: 0.025880143 hist_true: [0.0196885765 0.0200035591 0.0203035418 ... 0.0145064592 0.014085249 0.0136634316] hist_pred: [0.0316554159 0.031117579 0.0305793155 ... 0.0117529286 0.0115651842 0.0113908052]\n",
      "KL loss: 0.0648076385 hist_true: [0.00828638487 0.00881868135 0.00936974213 ... 0.0222706441 0.0217237137 0.0211473145] hist_pred: [0.0251618773 0.0246748291 0.0241884403 ... 0.0212053191 0.0213644616 0.0215148553]\n",
      "KL loss: 0.0370478556 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0293119289 0.0288021322 0.0282919817 ... 0.015406115 0.0153949568 0.0153898858]\n",
      "KL loss: 0.0835518837 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0262731835 0.0262297876 0.026166616 ... 0.0122581311 0.011938503 0.0116254902]\n",
      "KL loss: 0.01223276 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.025189152 0.0249187592 0.0246518496 ... 0.0165562928 0.0164782237 0.0164049789]\n",
      "KL loss: 0.00974675361 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0255819969 0.025332788 0.0250833277 ... 0.0156226708 0.0154748335 0.0153300995]\n",
      "KL loss: 0.0757713541 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0326314308 0.0319662094 0.0313046612 ... 0.01231403 0.012164915 0.0120246969]\n",
      "KL loss: 0.00755494414 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0252393093 0.0249456596 0.0246561412 ... 0.0169196911 0.0168627556 0.0168095306]\n",
      "KL loss: 0.00168497581 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0185143556 0.0185414907 0.018570492 ... 0.0220757145 0.0222009849 0.0223278459]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.0385 - val_loss: 6.2102\n",
      "Epoch 7/50\n",
      "KL loss: 0.00188580761 hist_true: [0.0184066519 0.018725127 0.0190322567 ... 0.0161279701 0.0157575384 0.0153827593] hist_pred: [0.0202811733 0.0203303564 0.0203766394 ... 0.0183895 0.0182537623 0.0181146357]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.7206KL loss: 0.0709087923 hist_true: [0.0101987636 0.0107855247 0.0113874357 ... 0.0183003861 0.017635379 0.0169582125] hist_pred: [0.0272861551 0.0270128157 0.026725566 ... 0.0146592231 0.014480128 0.014300569]\n",
      "KL loss: 0.0307387225 hist_true: [0.0145818 0.0149873877 0.0153902024 ... 0.0193903893 0.0190674793 0.0187315736] hist_pred: [0.0259941667 0.0257368423 0.0254766587 ... 0.0156404804 0.0155305713 0.015425426]\n",
      "KL loss: 0.00703150779 hist_true: [0.0175693166 0.0179080535 0.0182372853 ... 0.0168316215 0.0164722186 0.0161067322] hist_pred: [0.0238299966 0.0235764273 0.0233263616 ... 0.0186627507 0.018687645 0.0187144279]\n",
      "KL loss: 0.0097836731 hist_true: [0.018159112 0.0185719784 0.0189714283 ... 0.0146753108 0.0142147867 0.0137536172] hist_pred: [0.0264810976 0.0261377431 0.0258020479 ... 0.0146364048 0.0143937953 0.0141520072]\n",
      "KL loss: 0.0285233203 hist_true: [0.0170887 0.0177596938 0.0184183866 ... 0.0111682974 0.0105495444 0.00994653348] hist_pred: [0.0197245739 0.0195869096 0.019468002 ... 0.0200427957 0.0198647585 0.0196685065]\n",
      "KL loss: 0.00847494416 hist_true: [0.0155747952 0.0160738342 0.016566027 ... 0.016030537 0.0155451242 0.0150552941] hist_pred: [0.0213029012 0.0212640278 0.0212196 ... 0.0192928258 0.0192670394 0.0192366019]\n",
      "KL loss: 0.0202807505 hist_true: [0.0150518641 0.0156800915 0.016303679 ... 0.0137681225 0.0131593896 0.0125558581] hist_pred: [0.0235396363 0.0231195707 0.0227226131 ... 0.0197078902 0.0196986627 0.019683253]\n",
      "KL loss: 0.00418260088 hist_true: [0.0175909866 0.0180361364 0.0184692778 ... 0.0146131022 0.0141223166 0.0136308307] hist_pred: [0.0225130841 0.0224297158 0.0223524887 ... 0.0162245799 0.0159993507 0.015774915]\n",
      "KL loss: 0.0131598599 hist_true: [0.0135281291 0.0140959239 0.0146646202 ... 0.016387064 0.015819015 0.0152454749] hist_pred: [0.0217095166 0.0215035919 0.0213075541 ... 0.0191178229 0.0189746637 0.0188203827]\n",
      "KL loss: 0.0117321312 hist_true: [0.0151723344 0.0158300865 0.016483536 ... 0.0129012773 0.012261536 0.0116312075] hist_pred: [0.0231402386 0.0232300293 0.0233132169 ... 0.0131544014 0.0128015503 0.0124558825]\n",
      "KL loss: 0.0709412 hist_true: [0.0165960323 0.0169941336 0.01738392 ... 0.0168983303 0.0165033303 0.0161015969] hist_pred: [0.0345661268 0.0338738561 0.0331766754 ... 0.0108626932 0.0107231345 0.0105993301]\n",
      "KL loss: 0.0055046035 hist_true: [0.0184303075 0.0187067613 0.0189734492 ... 0.0168826282 0.0165609457 0.0162337143] hist_pred: [0.0240526833 0.0238963384 0.0237394683 ... 0.0161164645 0.0159418192 0.0157678]\n",
      "KL loss: 0.0151529871 hist_true: [0.0165836383 0.0169364028 0.0172820389 ... 0.0178713985 0.0175389424 0.017197974] hist_pred: [0.0253316481 0.025090402 0.0248486064 ... 0.015946947 0.0158194602 0.015695462]\n",
      "KL loss: 0.0648579746 hist_true: [0.00983868726 0.010353161 0.0108796926 ... 0.0218225513 0.0213749651 0.0209023543] hist_pred: [0.0236262903 0.0236184988 0.0235983133 ... 0.0151807321 0.0149600543 0.0147418845]\n",
      "KL loss: 0.0381309092 hist_true: [0.00990974344 0.0105208531 0.0111481864 ... 0.0182222705 0.0175539497 0.0168744102] hist_pred: [0.0223198924 0.0222451631 0.022173414 ... 0.0154546443 0.0151183987 0.0147818951]\n",
      "KL loss: 0.0169565119 hist_true: [0.0192008447 0.0194484089 0.0196851268 ... 0.0163713787 0.016045602 0.0157154836] hist_pred: [0.0289712865 0.0285164565 0.0280618444 ... 0.0145434374 0.0144469608 0.0143570062]\n",
      "KL loss: 0.00779475784 hist_true: [0.0172797181 0.0176192354 0.0179499909 ... 0.0172293354 0.0168855656 0.0165350027] hist_pred: [0.0238454975 0.0237028431 0.0235577207 ... 0.0162335522 0.0160416681 0.0158473551]\n",
      "KL loss: 0.00129526691 hist_true: [0.018978633 0.0192561354 0.0195222422 ... 0.0161071345 0.0157554746 0.0153996982] hist_pred: [0.0215302967 0.021570053 0.0216027573 ... 0.017037861 0.0168763045 0.0167164188]\n",
      "KL loss: 0.021455938 hist_true: [0.0149736358 0.0154727511 0.0159669388 ... 0.0167158227 0.0162412152 0.0157599282] hist_pred: [0.0252251215 0.0250777416 0.024921963 ... 0.0146420086 0.0143876793 0.0141318692]\n",
      "KL loss: 0.00588714 hist_true: [0.0173507389 0.0176959243 0.0180321112 ... 0.0169711839 0.0166107826 0.0162438322] hist_pred: [0.0231409054 0.0230398588 0.0229364336 ... 0.0167336389 0.0165764242 0.0164186563]\n",
      "KL loss: 0.00797258504 hist_true: [0.0176329166 0.0179169029 0.0181930456 ... 0.0178650599 0.0175792463 0.0172861684] hist_pred: [0.0239433385 0.0237970445 0.0236483682 ... 0.0163131095 0.0161476489 0.0159817245]\n",
      "KL loss: 0.0110905636 hist_true: [0.0187215246 0.0191348214 0.0195328463 ... 0.0140149947 0.0135412486 0.0130688203] hist_pred: [0.0269854255 0.0267655421 0.0265383646 ... 0.0131262466 0.0128474487 0.0125734964]\n",
      "KL loss: 0.00186416367 hist_true: [0.0166937541 0.0170780588 0.0174540728 ... 0.0170653686 0.0166854095 0.0162984543] hist_pred: [0.0187888909 0.0188880153 0.0189872943 ... 0.0191986505 0.0190380495 0.0188699625]\n",
      "KL loss: 0.00664923713 hist_true: [0.0180978924 0.0183417536 0.018578006 ... 0.0180343594 0.0177818537 0.017522648] hist_pred: [0.0235888492 0.0234866384 0.0233798623 ... 0.0164075885 0.01626659 0.0161283985]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8110 KL loss: 0.0359554291 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.027898 0.0276693162 0.027421454 ... 0.0140132895 0.0138857225 0.0137634072]\n",
      "KL loss: 0.0560007505 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0223477148 0.0225477815 0.0227294844 ... 0.0132296029 0.0128392894 0.0124529144]\n",
      "KL loss: 0.0123944534 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.024906598 0.0246999376 0.0244916603 ... 0.0159864239 0.0158405062 0.0156965517]\n",
      "KL loss: 0.00873386394 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0247166697 0.0245865602 0.0244502574 ... 0.0150440335 0.0148277916 0.0146138761]\n",
      "KL loss: 0.0792384 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0315793753 0.0311302077 0.0306681618 ... 0.0113151744 0.0110885724 0.0108712353]\n",
      "KL loss: 0.00642314553 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0245503839 0.0243474077 0.0241441224 ... 0.0164154526 0.0162896309 0.0161655843]\n",
      "KL loss: 0.000161470613 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0198342297 0.0198429525 0.0198515262 ... 0.0201111417 0.0201133601 0.020115329]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7969 - val_loss: 4.9100\n",
      "Epoch 8/50\n",
      "KL loss: 0.00810901821 hist_true: [0.0186516289 0.0190615673 0.0194567014 ... 0.0141082108 0.0136339236 0.0131605193] hist_pred: [0.0255205333 0.0252213534 0.024923481 ... 0.0163798761 0.0162387639 0.0160943456]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.3832KL loss: 0.00166269811 hist_true: [0.0180598721 0.0185351707 0.0189957563 ... 0.0137086539 0.0132013541 0.0126967849] hist_pred: [0.0200493801 0.0202250965 0.0203975383 ... 0.015617189 0.0152819967 0.01494742]\n",
      "KL loss: 0.00151514541 hist_true: [0.0174605213 0.0177177917 0.0179685745 ... 0.0187221356 0.0184947923 0.0182597842] hist_pred: [0.0196743254 0.0196673125 0.0196617451 ... 0.0204920303 0.0205009338 0.0205071699]\n",
      "KL loss: 0.059448719 hist_true: [0.00927419215 0.00981562864 0.0103723137 ... 0.0212995447 0.0207743384 0.0202250965] hist_pred: [0.0222162474 0.0222994573 0.0223701037 ... 0.0150863267 0.0147884404 0.0144923562]\n",
      "KL loss: 0.0109378463 hist_true: [0.0159901232 0.0164090451 0.016821038 ... 0.0172203146 0.0168192387 0.0164104234] hist_pred: [0.0235630088 0.0234125257 0.0232553501 ... 0.0182423908 0.0182575602 0.0182754565]\n",
      "KL loss: 0.003848091 hist_true: [0.0172670372 0.0176226832 0.0179692432 ... 0.0168735944 0.0165038928 0.0161277987] hist_pred: [0.0222257581 0.0221100338 0.0219982881 ... 0.0175029673 0.0173220113 0.0171354879]\n",
      "KL loss: 0.0197827071 hist_true: [0.0166271627 0.0169912297 0.0173478089 ... 0.0175576359 0.0172054302 0.0168452114] hist_pred: [0.0267034862 0.0263719503 0.0260428283 ... 0.0149927465 0.014812612 0.0146340048]\n",
      "KL loss: 0.0113305086 hist_true: [0.0172038898 0.0175231751 0.0178345088 ... 0.0177647565 0.0174547955 0.0171373021] hist_pred: [0.0242371652 0.0241286363 0.0240143705 ... 0.0154381748 0.0152422329 0.015049017]\n",
      "KL loss: 0.00177781074 hist_true: [0.0177409686 0.0180006921 0.0182531308 ... 0.0182359107 0.0179830566 0.0177229475] hist_pred: [0.0209421385 0.0209131595 0.020883875 ... 0.0187677443 0.018682152 0.0185939018]\n",
      "KL loss: 0.0639677495 hist_true: [0.00930579286 0.00989533495 0.0105027603 ... 0.0193628892 0.0187194627 0.0180600211] hist_pred: [0.0242830347 0.0242449623 0.0241888165 ... 0.0152290398 0.0150158908 0.0148019502]\n",
      "KL loss: 0.0180086549 hist_true: [0.019795211 0.020314334 0.0208116248 ... 0.0112136649 0.0106662484 0.0101305088] hist_pred: [0.0186258908 0.0188250057 0.0190174971 ... 0.0181422867 0.0179467909 0.0177502166]\n",
      "KL loss: 0.00470416853 hist_true: [0.0192285031 0.0194485355 0.0196588654 ... 0.0168458428 0.0165529791 0.0162552744] hist_pred: [0.0239711329 0.0238725189 0.0237693414 ... 0.015368646 0.0151401693 0.0149123622]\n",
      "KL loss: 0.0192272142 hist_true: [0.00979160611 0.0104839401 0.0111987749 ... 0.0153139448 0.0145160975 0.0137242721] hist_pred: [0.017857017 0.0180772878 0.0182904433 ... 0.0185216069 0.0182553474 0.0179779474]\n",
      "KL loss: 0.00407764828 hist_true: [0.016439395 0.016738547 0.0170324016 ... 0.0193294752 0.0191011727 0.0188634265] hist_pred: [0.0209678765 0.0209420417 0.0209161788 ... 0.0186259095 0.018532509 0.0184368193]\n",
      "KL loss: 0.00727884145 hist_true: [0.0166295674 0.0169094093 0.0171840228 ... 0.0195098836 0.0193068255 0.0190948434] hist_pred: [0.0219405666 0.0219173 0.0218899455 ... 0.0172752142 0.0171207469 0.0169652272]\n",
      "KL loss: 0.0759222507 hist_true: [0.0148420939 0.015330459 0.0158146825 ... 0.0170040727 0.0165351629 0.0160584729] hist_pred: [0.0327788964 0.0322780237 0.0317624174 ... 0.0108531127 0.010646252 0.010449837]\n",
      "KL loss: 0.00654644333 hist_true: [0.0153738605 0.0158270299 0.016274618 ... 0.0172309354 0.0168036073 0.0163683183] hist_pred: [0.0212248247 0.0212498568 0.0212748498 ... 0.016046783 0.0157057419 0.0153578715]\n",
      "KL loss: 0.0119588086 hist_true: [0.0183482897 0.0186820049 0.0190041699 ... 0.015872933 0.0154828103 0.0150887] hist_pred: [0.0265295673 0.0262619108 0.02599301 ... 0.0140202008 0.0137491 0.0134780789]\n",
      "KL loss: 0.00135203544 hist_true: [0.0159314983 0.0162815508 0.0166261848 ... 0.0189007837 0.0186148286 0.0183187593] hist_pred: [0.0184803661 0.0186405983 0.0187964942 ... 0.0191900022 0.0190534033 0.0189121608]\n",
      "KL loss: 0.00963301398 hist_true: [0.0129562914 0.0135292206 0.0141045582 ... 0.0170195494 0.0164637975 0.0159004424] hist_pred: [0.0194889195 0.0196739286 0.0198516883 ... 0.01649471 0.0161620267 0.0158249289]\n",
      "KL loss: 0.00914323889 hist_true: [0.0160184987 0.0166281518 0.0172292776 ... 0.0132638225 0.0126707079 0.0120840007] hist_pred: [0.0230547916 0.0231132936 0.0231605768 ... 0.014561506 0.0142871737 0.0140165966]\n",
      "KL loss: 0.0112357754 hist_true: [0.0160627458 0.0164543539 0.0168393757 ... 0.0177131668 0.0173456594 0.0169693436] hist_pred: [0.0226487797 0.0226921439 0.0227246061 ... 0.0153272366 0.0150723048 0.0148186106]\n",
      "KL loss: 0.0132876793 hist_true: [0.0175922718 0.0180019364 0.0184001345 ... 0.0153831597 0.0149377733 0.0144896014] hist_pred: [0.0252710115 0.0252103955 0.0251394212 ... 0.012776074 0.0124107776 0.012048386]\n",
      "KL loss: 0.00373782334 hist_true: [0.0166774392 0.0171622075 0.0176367983 ... 0.0150402142 0.0145453 0.0140489088] hist_pred: [0.0210016482 0.0211155191 0.0212199204 ... 0.01638324 0.0161454454 0.0159072187]\n",
      "KL loss: 0.0128138438 hist_true: [0.0114903059 0.0121273464 0.0127746901 ... 0.0162878595 0.0156107116 0.0149300946] hist_pred: [0.0180922113 0.0183652807 0.01862479 ... 0.0187724121 0.0186345261 0.0184949152]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9360 KL loss: 0.0374861844 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0278156605 0.0276425797 0.0274456516 ... 0.0136678377 0.0135294227 0.0133969458]\n",
      "KL loss: 0.0713574365 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0237348024 0.0239057466 0.0240543988 ... 0.0122157168 0.0118272426 0.0114457933]\n",
      "KL loss: 0.0140918363 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0253794268 0.0251554511 0.0249278918 ... 0.0159007721 0.015773911 0.0156495273]\n",
      "KL loss: 0.00649065385 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0241092946 0.023987066 0.0238588396 ... 0.0159420874 0.0157630499 0.0155839669]\n",
      "KL loss: 0.0872636363 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0322291702 0.0317745022 0.031302996 ... 0.0108817397 0.0106578 0.0104440497]\n",
      "KL loss: 0.0074966033 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0248698685 0.0246745702 0.0244760215 ... 0.0160553195 0.0159167368 0.0157796163]\n",
      "KL loss: 0.000210279599 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0194498282 0.0194708165 0.0194921419 ... 0.0204398055 0.0204495452 0.0204582177]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9189 - val_loss: 3.8568\n",
      "Epoch 9/50\n",
      "KL loss: 0.00554189831 hist_true: [0.0194574669 0.0198391657 0.0202042442 ... 0.0136611871 0.0131911263 0.0127230873] hist_pred: [0.0205624849 0.0206241291 0.0206805561 ... 0.0177763943 0.0175924245 0.0174029768]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.2844KL loss: 0.00598684512 hist_true: [0.0166538619 0.0170368478 0.0174116 ... 0.0171869341 0.0168156382 0.0164373051] hist_pred: [0.0221870244 0.0221863333 0.0221776236 ... 0.0170777794 0.0169479456 0.0168197546]\n",
      "KL loss: 0.0137385521 hist_true: [0.0157397948 0.0161237903 0.0165020805 ... 0.0183878411 0.0180552341 0.0177127477] hist_pred: [0.0228350367 0.0228390377 0.0228357781 ... 0.015204858 0.0149241341 0.0146435313]\n",
      "KL loss: 0.0261792876 hist_true: [0.016522605 0.0168561433 0.0171831865 ... 0.018410597 0.0181154255 0.017811235] hist_pred: [0.0261697453 0.0260014627 0.0258245 ... 0.0136379916 0.0133728934 0.013111731]\n",
      "KL loss: 0.0113680912 hist_true: [0.016893493 0.0171680208 0.0174368918 ... 0.0192028079 0.0189865511 0.0187616758] hist_pred: [0.0239929911 0.023817597 0.0236418843 ... 0.0167046487 0.0165710635 0.0164373349]\n",
      "KL loss: 0.00564296125 hist_true: [0.0177876092 0.0180424284 0.0182899963 ... 0.018279098 0.0180322751 0.017778324] hist_pred: [0.0228515174 0.0227761716 0.0226980988 ... 0.0165770371 0.0163888168 0.016198907]\n",
      "KL loss: 0.0318008736 hist_true: [0.0152266948 0.0159904826 0.0167516023 ... 0.0109214634 0.010248919 0.00959701743] hist_pred: [0.0286514591 0.0285787564 0.0284691975 ... 0.0108518954 0.0105201248 0.010197184]\n",
      "KL loss: 0.0300912932 hist_true: [0.00997306593 0.0105669992 0.0111758262 ... 0.0188576803 0.0182303712 0.0175888371] hist_pred: [0.0203091502 0.0204253 0.0205355 ... 0.0166572444 0.0164007246 0.0161452517]\n",
      "KL loss: 0.00813636091 hist_true: [0.0186793692 0.018913487 0.0191388037 ... 0.0173740536 0.017097069 0.0168143436] hist_pred: [0.0245952234 0.0244723763 0.0243429821 ... 0.0152344592 0.0150346188 0.0148372864]\n",
      "KL loss: 0.0606103614 hist_true: [0.014320435 0.014980997 0.0156405363 ... 0.0136721814 0.0130329588 0.0124004558] hist_pred: [0.0312896892 0.0310591161 0.0307884961 ... 0.0113668293 0.0112268915 0.0110977162]\n",
      "KL loss: 0.07232517 hist_true: [0.00992564578 0.0104527287 0.0109927906 ... 0.0209507532 0.020437343 0.0199010726] hist_pred: [0.0248087011 0.0247536842 0.02468534 ... 0.0144085111 0.0141976923 0.0139929624]\n",
      "KL loss: 0.00502726249 hist_true: [0.0183124915 0.0186674502 0.0190103315 ... 0.0155001245 0.015085686 0.01466804] hist_pred: [0.0237045 0.0236015711 0.0234920233 ... 0.0164504 0.0163122602 0.0161756203]\n",
      "\u001b[1m12/25\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0562 KL loss: 0.00533575844 hist_true: [0.0175594501 0.0179485325 0.0183269102 ... 0.0157625061 0.0153328823 0.014899129] hist_pred: [0.0229202174 0.0228989571 0.0228688903 ... 0.0164262336 0.016281506 0.0161395427]\n",
      "KL loss: 0.0289670732 hist_true: [0.0151533624 0.0155459782 0.0159344599 ... 0.0189643726 0.0186435971 0.0183115285] hist_pred: [0.0259832609 0.0257712342 0.0255527105 ... 0.0148860794 0.0147111192 0.0145398127]\n",
      "KL loss: 0.00548047107 hist_true: [0.0156102749 0.0161206946 0.0166246034 ... 0.0155664291 0.0150497081 0.0145298056] hist_pred: [0.0211321767 0.0211903434 0.0212455429 ... 0.0162626505 0.0159805939 0.0156957936]\n",
      "KL loss: 0.0146466224 hist_true: [0.010270671 0.0108974501 0.0115394676 ... 0.017509412 0.0168268401 0.0161361452] hist_pred: [0.0175239611 0.0177992377 0.0180724915 ... 0.0171944089 0.016869083 0.0165428]\n",
      "KL loss: 0.00949725881 hist_true: [0.0154779116 0.0158870444 0.0162909441 ... 0.0180907045 0.0177220926 0.0173435975] hist_pred: [0.0223034192 0.0222584605 0.0222093128 ... 0.0169855 0.0168081205 0.0166285113]\n",
      "KL loss: 0.00723541435 hist_true: [0.0156178279 0.0162450261 0.0168651361 ... 0.0133522097 0.012751719 0.0121577354] hist_pred: [0.0191136263 0.0192785431 0.0194393769 ... 0.0175332222 0.0172796268 0.0170216057]\n",
      "KL loss: 0.00273279194 hist_true: [0.0184812825 0.0188110732 0.0191290397 ... 0.0157760382 0.0153847476 0.0149896899] hist_pred: [0.0207301304 0.0207499173 0.0207656417 ... 0.0184879042 0.0183802284 0.0182698369]\n",
      "KL loss: 0.00249519432 hist_true: [0.0184173323 0.0187504571 0.0190718286 ... 0.0158016887 0.015410128 0.0150147825] hist_pred: [0.0222779345 0.0223031752 0.022321878 ... 0.0155313266 0.0152445007 0.014955949]\n",
      "KL loss: 0.010017015 hist_true: [0.0170270335 0.0174278375 0.0178191345 ... 0.0162527394 0.0158346202 0.0154113257] hist_pred: [0.0243024305 0.0241990034 0.0240892377 ... 0.015183785 0.0149686746 0.0147563443]\n",
      "KL loss: 0.00672881864 hist_true: [0.0151158823 0.0155520551 0.0159836411 ... 0.0179296918 0.0175331142 0.0171266813] hist_pred: [0.0209962241 0.0209375918 0.0208789203 ... 0.019294003 0.0192441735 0.0191910062]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3810KL loss: 0.00551174767 hist_true: [0.0171022732 0.0175014623 0.0178909283 ... 0.0161817148 0.0157607514 0.0153346313] hist_pred: [0.0169468131 0.0171311945 0.0173155665 ... 0.0204784516 0.020340953 0.02019329]\n",
      "KL loss: 0.00812723488 hist_true: [0.0152768446 0.0158471856 0.0164118856 ... 0.0146922776 0.0141240116 0.0135563137] hist_pred: [0.0216756258 0.0218210965 0.0219544675 ... 0.0148291737 0.0145153766 0.0142035112]\n",
      "KL loss: 0.00368474913 hist_true: [0.0186157525 0.0189340338 0.0192404259 ... 0.0158344302 0.0154526308 0.0150670474] hist_pred: [0.0234686285 0.0233722925 0.0232736394 ... 0.01577623 0.0155415768 0.0153052779]\n",
      "KL loss: 0.0248531252 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0251294188 0.0251266677 0.0251012128 ... 0.0140506569 0.0138273519 0.013606797]\n",
      "KL loss: 0.062827751 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0225589667 0.022794839 0.0230097249 ... 0.0125307795 0.0121207824 0.0117171369]\n",
      "KL loss: 0.0137852691 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0248980187 0.0247437451 0.024582766 ... 0.0154630598 0.0152884824 0.0151159139]\n",
      "KL loss: 0.00635583326 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0237871297 0.023722833 0.0236493461 ... 0.0156575944 0.0154619608 0.0152673908]\n",
      "KL loss: 0.067371428 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0293942802 0.029147137 0.0288798343 ... 0.0115454178 0.0112783406 0.0110191461]\n",
      "KL loss: 0.00670619588 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0242890622 0.0241629202 0.0240311753 ... 0.0156655032 0.0154745048 0.0152841043]\n",
      "KL loss: 0.000401419384 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0204994399 0.020491818 0.0204834566 ... 0.0192497559 0.0191997159 0.0191485081]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.4011 - val_loss: 3.1529\n",
      "Epoch 10/50\n",
      "KL loss: 0.00383971538 hist_true: [0.017564293 0.0179517604 0.0183283668 ... 0.0158553626 0.0154352244 0.0150109846] hist_pred: [0.0193768423 0.0194325559 0.019487422 ... 0.0193067305 0.0191748664 0.0190357622]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 324ms/step - loss: 3.6153KL loss: 0.0517967232 hist_true: [0.00960558 0.0103476774 0.0111168306 ... 0.013761702 0.012908414 0.0120720807] hist_pred: [0.0248448122 0.024797868 0.024721114 ... 0.0144428872 0.0140643734 0.0136752445]\n",
      "KL loss: 0.0228214581 hist_true: [0.0106522581 0.011332633 0.0120295398 ... 0.0154052423 0.0146476235 0.0138930613] hist_pred: [0.020816708 0.0208225 0.0208279975 ... 0.0167515334 0.0165943038 0.0164549556]\n",
      "KL loss: 0.0351499021 hist_true: [0.00872461405 0.00930028874 0.00989656523 ... 0.0197141021 0.0190306064 0.0183291603] hist_pred: [0.018064389 0.0184495989 0.0188166201 ... 0.0165979397 0.0162652023 0.0159260798]\n",
      "KL loss: 0.0261896718 hist_true: [0.0139720412 0.0144686978 0.0149637051 ... 0.0179166459 0.0174661633 0.017005397] hist_pred: [0.0240716543 0.0240249541 0.0239707623 ... 0.0142127573 0.0139099602 0.01361]\n",
      "KL loss: 0.00372889638 hist_true: [0.0169969331 0.0173202176 0.0176361091 ... 0.0179383252 0.0176297203 0.0173130576] hist_pred: [0.0213451 0.0213651024 0.0213803109 ... 0.0173072014 0.0171242151 0.0169383325]\n",
      "KL loss: 0.00286611076 hist_true: [0.0186647959 0.0189161152 0.0191579834 ... 0.0170505401 0.0167500675 0.0164441019] hist_pred: [0.0205093455 0.0204442572 0.0203821938 ... 0.0200727135 0.0200678427 0.0200597569]\n",
      "KL loss: 0.0168871284 hist_true: [0.0152092483 0.0156228179 0.0160319973 ... 0.0182749592 0.0179018583 0.0175179765] hist_pred: [0.0232568905 0.0232374277 0.0232098121 ... 0.0150860604 0.0148039935 0.0145206805]\n",
      "KL loss: 0.00850270875 hist_true: [0.0162138082 0.0166169479 0.0170127507 ... 0.0172845758 0.0168970656 0.0165017415] hist_pred: [0.0226946827 0.0226704292 0.0226392597 ... 0.0162537601 0.0160512719 0.0158482045]\n",
      "KL loss: 0.00449332362 hist_true: [0.017704865 0.0180437174 0.0183726568 ... 0.0166513547 0.016286131 0.0159152411] hist_pred: [0.0229076259 0.022805417 0.0227021314 ... 0.0169950835 0.0168432854 0.0166901294]\n",
      "KL loss: 0.00306302216 hist_true: [0.0127261495 0.0132857515 0.0138486447 ... 0.0174952261 0.0169490613 0.0163933896] hist_pred: [0.0161514338 0.0164539255 0.0167555269 ... 0.0188387465 0.0185332596 0.0182164479]\n",
      "KL loss: 0.00241893623 hist_true: [0.0187802501 0.0190114714 0.0192337725 ... 0.0172741115 0.0169936381 0.0167075712] hist_pred: [0.0224241391 0.0222790707 0.0221365392 ... 0.0185716543 0.0185284205 0.0184848364]\n",
      "KL loss: 0.0117191728 hist_true: [0.0189500805 0.0192137696 0.0194667205 ... 0.0163985863 0.0160642415 0.0157252755] hist_pred: [0.0259507205 0.0258024465 0.0256452095 ... 0.0136929387 0.013431387 0.0131738987]\n",
      "KL loss: 0.0382774919 hist_true: [0.00909198076 0.00967939105 0.0102857556 ... 0.0193991363 0.0187344216 0.0180532] hist_pred: [0.0211606901 0.0211638678 0.0211559199 ... 0.0178751647 0.0176407322 0.0173948687]\n",
      "KL loss: 0.00118586607 hist_true: [0.0179973841 0.0182918701 0.0185770839 ... 0.0171486195 0.0168286376 0.0165025163] hist_pred: [0.0205405373 0.0206172187 0.0206879154 ... 0.0176409297 0.0174658261 0.0172885023]\n",
      "KL loss: 0.00267649442 hist_true: [0.0187157542 0.0191678107 0.0196037181 ... 0.0133362813 0.0128319412 0.0123313703] hist_pred: [0.0226573721 0.0227438 0.0228184722 ... 0.0143442014 0.0140224881 0.0137034869]\n",
      "KL loss: 0.0170023125 hist_true: [0.0159383677 0.0165213775 0.0170964096 ... 0.0137647726 0.0131823877 0.0126040671] hist_pred: [0.0254705474 0.0254151653 0.0253460128 ... 0.0133555364 0.013125794 0.0129082194]\n",
      "KL loss: 0.00790171511 hist_true: [0.0164268054 0.0167412814 0.0170500148 ... 0.018998934 0.0187445339 0.018480761] hist_pred: [0.0226620398 0.0225534644 0.0224433653 ... 0.0177015644 0.0175974108 0.017491769]\n",
      "KL loss: 0.0101510175 hist_true: [0.0183656216 0.0186865721 0.018996248 ... 0.0161280166 0.0157560743 0.0153797884] hist_pred: [0.0254071224 0.0252834465 0.0251483619 ... 0.0146289477 0.0144392671 0.0142546799]\n",
      "KL loss: 0.0373410396 hist_true: [0.0161942374 0.0165472012 0.0168940146 ... 0.0184496958 0.0181427114 0.0178263336] hist_pred: [0.028089162 0.0278192479 0.0275380574 ... 0.0133288391 0.0131448023 0.0129691325]\n",
      "KL loss: 0.00138974702 hist_true: [0.0170682725 0.0174684357 0.017858915 ... 0.0162267908 0.0158088859 0.015385869] hist_pred: [0.0195572767 0.0197297391 0.0198949501 ... 0.0173065811 0.0170789454 0.0168492291]\n",
      "KL loss: 0.00191539573 hist_true: [0.0178877711 0.0182706751 0.0186419 ... 0.0155219771 0.0150941368 0.0146630313] hist_pred: [0.020723151 0.0207622889 0.0207997803 ... 0.0171683691 0.0169177502 0.0166611262]\n",
      "KL loss: 0.00102209277 hist_true: [0.0180273764 0.0182994176 0.0185629111 ... 0.0175599903 0.0172697622 0.0169729814] hist_pred: [0.0202278662 0.0202765372 0.0203215778 ... 0.0185462628 0.0184164643 0.0182827152]\n",
      "KL loss: 0.0171217378 hist_true: [0.0197954196 0.0201945864 0.0205752775 ... 0.0130362138 0.0125510162 0.0120699368] hist_pred: [0.0283301715 0.0282725915 0.0281872563 ... 0.0104906447 0.0101753939 0.00987398531]\n",
      "KL loss: 0.00577266142 hist_true: [0.017544046 0.0179995745 0.018442655 ... 0.0145734241 0.0140832011 0.0135925459] hist_pred: [0.0232441407 0.0232336614 0.0232136231 ... 0.0155337909 0.0153271444 0.0151227023]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1366  KL loss: 0.0126904426 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.021891918 0.0220836326 0.0222554374 ... 0.014730867 0.0144412899 0.0141532421]\n",
      "KL loss: 0.0366321318 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0193669461 0.019721061 0.0200604107 ... 0.0142812086 0.0138544543 0.0134296091]\n",
      "KL loss: 0.00989479385 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0234528966 0.0234131757 0.0233637877 ... 0.0157528613 0.0155563084 0.0153609868]\n",
      "KL loss: 0.0031680204 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0221098866 0.0221553203 0.0221904013 ... 0.0162412804 0.0160355326 0.015830081]\n",
      "KL loss: 0.0461194366 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0258914325 0.0258905347 0.0258671772 ... 0.0123937912 0.0120810019 0.0117746722]\n",
      "KL loss: 0.00443278067 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0230847448 0.0230523106 0.0230121445 ... 0.0158506706 0.015632255 0.0154133728]\n",
      "KL loss: 0.00051666022 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0205788817 0.0205776431 0.020574918 ... 0.0190338939 0.018970754 0.0189064723]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1272 - val_loss: 2.5862\n",
      "Epoch 11/50\n",
      "KL loss: 0.00378087303 hist_true: [0.0189017523 0.0190867316 0.019264495 ... 0.0180253889 0.0178067256 0.0175825227] hist_pred: [0.0230103265 0.022935532 0.0228563361 ... 0.016650416 0.016492134 0.0163342301]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.2206KL loss: 0.00373910763 hist_true: [0.0180846658 0.0183343757 0.0185762625 ... 0.0179382 0.0176782571 0.0174116548] hist_pred: [0.0226145852 0.0225217771 0.022426175 ... 0.0178086907 0.0177411065 0.0176758654]\n",
      "KL loss: 0.0154030276 hist_true: [0.0143895634 0.0149000287 0.0154078379 ... 0.0169687513 0.01647548 0.0159744322] hist_pred: [0.0219035801 0.0220594052 0.0222002249 ... 0.0144817075 0.0141521944 0.0138254482]\n",
      "KL loss: 0.022571383 hist_true: [0.0180802345 0.0184093248 0.0187277514 ... 0.0163354538 0.0159646589 0.0155889466] hist_pred: [0.0270469617 0.0269193891 0.0267768241 ... 0.0121104699 0.0117948921 0.0114866719]\n",
      "KL loss: 0.00503282668 hist_true: [0.0177757759 0.0181253329 0.0184643399 ... 0.0163681824 0.0159886796 0.0156040862] hist_pred: [0.022885032 0.0228841566 0.0228706487 ... 0.0164641067 0.0163194686 0.0161765441]\n",
      "KL loss: 0.0171962958 hist_true: [0.0176728088 0.018124802 0.0185639244 ... 0.0145188244 0.0140319467 0.0135448305] hist_pred: [0.0182991214 0.0182900541 0.0182844419 ... 0.0220443867 0.0220217444 0.0219826344]\n",
      "KL loss: 0.00279689534 hist_true: [0.0180558376 0.018274704 0.0184870474 ... 0.0186351202 0.0184279568 0.018214101] hist_pred: [0.0217144284 0.0216867421 0.0216558874 ... 0.0178053658 0.0176957846 0.0175868217]\n",
      "KL loss: 0.00814590417 hist_true: [0.0179556143 0.0182626545 0.0185601823 ... 0.0169254337 0.0165870953 0.0162427407] hist_pred: [0.0240903255 0.0240140967 0.0239296053 ... 0.0151665453 0.0149358213 0.0147057809]\n",
      "KL loss: 0.00377444085 hist_true: [0.0148195419 0.0152689302 0.015714407 ... 0.0180063825 0.0176012125 0.0171858594] hist_pred: [0.0191104747 0.0192591697 0.0194032714 ... 0.0180085208 0.0177787021 0.0175421536]\n",
      "KL loss: 0.00509214 hist_true: [0.0194319338 0.019772768 0.0200985242 ... 0.0143655455 0.0139281247 0.0134905064] hist_pred: [0.0204358101 0.020469673 0.0205003917 ... 0.0183880497 0.0182463042 0.0181001201]\n",
      "KL loss: 0.00289561832 hist_true: [0.016668044 0.0170659069 0.0174554158 ... 0.016767852 0.0163660217 0.0159576964] hist_pred: [0.0203783978 0.0204656348 0.020545572 ... 0.017984774 0.0178396665 0.0176925492]\n",
      "KL loss: 0.0216499176 hist_true: [0.0136762401 0.0141532673 0.0146295708 ... 0.0187598504 0.0183472373 0.0179219581] hist_pred: [0.0221915357 0.0223195609 0.0224290937 ... 0.0158174206 0.0156484451 0.0154848816]\n",
      "KL loss: 0.00986974873 hist_true: [0.0179028865 0.0184870418 0.0190560389 ... 0.0118646296 0.0112819104 0.0107101174] hist_pred: [0.0245566498 0.0245227925 0.024468923 ... 0.0149069875 0.0146836387 0.0144601688]\n",
      "KL loss: 0.0103412289 hist_true: [0.0157355405 0.0161556825 0.0165695921 ... 0.0175316855 0.0171397869 0.0167393945] hist_pred: [0.0225720908 0.0225755665 0.0225717369 ... 0.0161714256 0.0159892309 0.0158098135]\n",
      "KL loss: 0.0290778019 hist_true: [0.0107647507 0.0114652971 0.0121833421 ... 0.0147057362 0.0139337126 0.0131691182] hist_pred: [0.0212271083 0.0214789659 0.0217142869 ... 0.0137330843 0.0133770872 0.0130322063]\n",
      "KL loss: 0.0173874088 hist_true: [0.00910944492 0.00971019 0.0103302225 ... 0.0191508122 0.0184877384 0.0178099517] hist_pred: [0.0165939648 0.0168932807 0.0171871632 ... 0.0183783118 0.0180186555 0.0176437777]\n",
      "KL loss: 0.0409532934 hist_true: [0.00768226897 0.00818992779 0.00871811528 ... 0.0233295579 0.0227933303 0.022222884] hist_pred: [0.017296847 0.0175696518 0.0178355463 ... 0.0186007936 0.0183611829 0.0181151461]\n",
      "KL loss: 0.00168616138 hist_true: [0.0171602964 0.0175462514 0.0179227106 ... 0.0163597371 0.0159514416 0.0155375963] hist_pred: [0.0186505653 0.0187762044 0.0189017914 ... 0.018514121 0.0182696842 0.0180149693]\n",
      "KL loss: 0.0156316869 hist_true: [0.0217627585 0.0221434869 0.0224988703 ... 0.0113143409 0.0108202333 0.0103354212] hist_pred: [0.0203964617 0.0204463713 0.020494489 ... 0.0174492411 0.0172140189 0.0169743486]\n",
      "KL loss: 0.0490221791 hist_true: [0.0115386089 0.0120209642 0.012508845 ... 0.0212781727 0.0209208746 0.02054343] hist_pred: [0.0233585145 0.0234057289 0.0234361719 ... 0.0149164498 0.0146712139 0.0144275324]\n",
      "KL loss: 0.00151190418 hist_true: [0.0149924112 0.0155310258 0.0160646625 ... 0.0157303754 0.0151991844 0.0146643994] hist_pred: [0.0174238626 0.017712377 0.0179989487 ... 0.0170839839 0.016729828 0.0163720585]\n",
      "KL loss: 0.00361815328 hist_true: [0.0173392314 0.0177603606 0.0181704573 ... 0.0154941892 0.0150467064 0.0145961931] hist_pred: [0.0217991974 0.0218840186 0.0219582412 ... 0.0157803036 0.0155193554 0.0152573623]\n",
      "KL loss: 0.0161671266 hist_true: [0.0191905517 0.019682616 0.0201556589 ... 0.0122242691 0.0116917705 0.0111670196] hist_pred: [0.0288902726 0.0287021231 0.0284935739 ... 0.0117725367 0.011580945 0.0114055751]\n",
      "KL loss: 0.00509502646 hist_true: [0.0167628359 0.0171863269 0.0176006425 ... 0.0161015708 0.015662631 0.0152187431] hist_pred: [0.01626979 0.0165074095 0.0167467743 ... 0.0201704614 0.0200003292 0.0198232513]\n",
      "KL loss: 0.051609654 hist_true: [0.0137081398 0.0142544 0.0148004303 ... 0.0168360639 0.0163042452 0.0157653131] hist_pred: [0.0273234639 0.0272490233 0.0271513 ... 0.0114370361 0.0110779461 0.0107237278]\n",
      "KL loss: 0.0192361735 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.023198016 0.023349952 0.0234803557 ... 0.0133088529 0.0129495198 0.0125926901]\n",
      "KL loss: 0.0569241345 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0217671935 0.0220428202 0.0222982205 ... 0.0127668316 0.0123339957 0.0119060203]\n",
      "KL loss: 0.0132113611 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0242258515 0.0241558 0.0240758061 ... 0.0149581749 0.0147150038 0.0144720841]\n",
      "KL loss: 0.00722036883 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0237088054 0.0236912277 0.0236624572 ... 0.0148390923 0.0145782344 0.0143184913]\n",
      "KL loss: 0.0572762787 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0274897013 0.0273959581 0.0272793733 ... 0.011705311 0.011390266 0.0110820411]\n",
      "KL loss: 0.0115174372 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0250758752 0.0249846168 0.0248831064 ... 0.0139297191 0.0136421071 0.0133562265]\n",
      "KL loss: 0.000958167482 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0209036488 0.0208969377 0.0208884832 ... 0.0185224526 0.0184243377 0.0183243528]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2298 - val_loss: 2.2106\n",
      "Epoch 12/50\n",
      "KL loss: 0.00459723501 hist_true: [0.0177953821 0.018287098 0.0187647231 ... 0.0137001732 0.0131837716 0.0126702758] hist_pred: [0.0226785187 0.0227487069 0.0228066482 ... 0.0151671916 0.0149214314 0.014677139]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - loss: 2.7906KL loss: 0.0404187962 hist_true: [0.00861548074 0.00916997436 0.00974395406 ... 0.0207679067 0.0201415028 0.0194921792] hist_pred: [0.0196472425 0.0197560117 0.0198642351 ... 0.0168726742 0.0165498666 0.0162208341]\n",
      "KL loss: 0.00862120744 hist_true: [0.0198937412 0.0204572808 0.0209971704 ... 0.0106295729 0.0100781107 0.00954097603] hist_pred: [0.0241004825 0.0240034331 0.0239012577 ... 0.0146867195 0.0143633531 0.0140356347]\n",
      "KL loss: 0.00282284152 hist_true: [0.0181025267 0.0185242072 0.0189325381 ... 0.0145306531 0.0140578216 0.0135845952] hist_pred: [0.0220828149 0.022207845 0.0223212782 ... 0.0144821843 0.0141514512 0.0138227437]\n",
      "KL loss: 0.00387220248 hist_true: [0.0180886574 0.0184606928 0.018820744 ... 0.0154737597 0.0150499251 0.0146229053] hist_pred: [0.022538729 0.0226114206 0.0226718821 ... 0.015198119 0.0149526447 0.0147106219]\n",
      "KL loss: 0.0012017563 hist_true: [0.0201742668 0.0203839596 0.0205815807 ... 0.0157335717 0.015402318 0.0150682013] hist_pred: [0.0206291936 0.0206802282 0.0207273066 ... 0.0176827554 0.0174941625 0.0173012726]\n",
      "KL loss: 0.0117824785 hist_true: [0.0159044228 0.0163446665 0.0167780854 ... 0.016792383 0.0163576026 0.0159158427] hist_pred: [0.0232865643 0.0232658628 0.023237614 ... 0.0147982314 0.0144845536 0.01416934]\n",
      "KL loss: 0.0290975198 hist_true: [0.0142428922 0.0148084955 0.0153721822 ... 0.0158168562 0.0152569916 0.0146937296] hist_pred: [0.0249041691 0.0249594785 0.0249939077 ... 0.0129508916 0.0126821436 0.0124236289]\n",
      "KL loss: 0.0144959129 hist_true: [0.0183842499 0.0186959282 0.0189966839 ... 0.0162562188 0.0158914719 0.0155220451] hist_pred: [0.0265182406 0.026331706 0.0261353273 ... 0.0136636468 0.0134168193 0.0131738968]\n",
      "KL loss: 0.00674243644 hist_true: [0.0184710082 0.0188803244 0.0192754027 ... 0.0143248755 0.0138538806 0.0133829955] hist_pred: [0.0212571807 0.0212598592 0.0212557316 ... 0.0188493952 0.0188381 0.018828908]\n",
      "KL loss: 0.000775739318 hist_true: [0.0185103882 0.0188041758 0.0190872792 ... 0.0164402444 0.0160923731 0.0157395881] hist_pred: [0.0206929725 0.0207548179 0.0208136048 ... 0.0170119964 0.0167622175 0.0165074207]\n",
      "KL loss: 0.0222220216 hist_true: [0.0102530029 0.0107577182 0.011272572 ... 0.0219018757 0.0214985777 0.0210713428] hist_pred: [0.0185686536 0.0187136624 0.0188554805 ... 0.0187257081 0.0185089428 0.0182827022]\n",
      "KL loss: 0.0894975066 hist_true: [0.00997191947 0.0105390828 0.0111197829 ... 0.019846594 0.0192783102 0.0186916981] hist_pred: [0.0271647 0.0270523764 0.0269129761 ... 0.0128648747 0.0125882979 0.0123144425]\n",
      "KL loss: 0.00640967 hist_true: [0.0178817138 0.0181620978 0.0184340402 ... 0.0175997242 0.0173065048 0.0170065835] hist_pred: [0.023196 0.0231582094 0.0231117401 ... 0.0160229132 0.0158359148 0.0156501718]\n",
      "KL loss: 0.00465136 hist_true: [0.0186576452 0.0189578198 0.019246662 ... 0.0161128752 0.0157496072 0.0153820422] hist_pred: [0.0209382139 0.0208559204 0.0207746811 ... 0.0199285783 0.0199240036 0.0199154839]\n",
      "KL loss: 0.0134669952 hist_true: [0.0165461935 0.0168893542 0.0172255896 ... 0.0181797091 0.0178690311 0.0175495353] hist_pred: [0.0240842197 0.0239929538 0.0238934066 ... 0.0156974141 0.0155221913 0.0153495409]\n",
      "KL loss: 0.00465420447 hist_true: [0.0155719081 0.0160119459 0.0164460596 ... 0.0172452815 0.0168253798 0.0163973719] hist_pred: [0.0205610488 0.0206037387 0.0206425935 ... 0.0178607926 0.0176730491 0.0174801424]\n",
      "KL loss: 0.0145038208 hist_true: [0.0178539176 0.0181140471 0.0183665454 ... 0.0180644188 0.0178040285 0.0175366309] hist_pred: [0.025226729 0.0250839591 0.0249337014 ... 0.0145945596 0.0143608376 0.0141289113]\n",
      "KL loss: 0.0177334938 hist_true: [0.015741393 0.0161668733 0.0165863615 ... 0.0172805339 0.0168664027 0.0164438877] hist_pred: [0.024009835 0.0240170825 0.0240095835 ... 0.0144534167 0.0142055452 0.0139616337]\n",
      "KL loss: 0.00164037012 hist_true: [0.0182532016 0.0185561683 0.0188488886 ... 0.0166084673 0.0162615366 0.015909303] hist_pred: [0.0207711086 0.0207956191 0.0208159219 ... 0.0182004292 0.0180630218 0.0179218985]\n",
      "KL loss: 0.0087311063 hist_true: [0.0168500114 0.0172403753 0.0176220201 ... 0.0166805536 0.0162800606 0.0158732496] hist_pred: [0.0226978473 0.0227850173 0.0228579901 ... 0.0148250554 0.0145643977 0.0143081099]\n",
      "KL loss: 0.00230847206 hist_true: [0.0177056342 0.018152101 0.0185862184 ... 0.0144527815 0.013958687 0.0134644592] hist_pred: [0.0206055 0.0207582414 0.0209002364 ... 0.0162604898 0.0159835555 0.0157034919]\n",
      "KL loss: 0.0107574156 hist_true: [0.0134110637 0.0139465155 0.0144822393 ... 0.0175350942 0.0170297 0.0165146142] hist_pred: [0.0197771341 0.0200081617 0.0202267859 ... 0.016568942 0.0163306724 0.0160926264]\n",
      "KL loss: 0.0122985626 hist_true: [0.00919098314 0.00978244189 0.010392502 ... 0.0192285627 0.0185614433 0.017878538] hist_pred: [0.0148392906 0.0152497562 0.0156640653 ... 0.0181810986 0.0178538561 0.017525956]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4347  KL loss: 0.00616288604 hist_true: [0.0163197145 0.0167472512 0.0171668716 ... 0.0165727641 0.0161440242 0.015709091] hist_pred: [0.0219625104 0.0219653863 0.0219603926 ... 0.0173661374 0.017247621 0.0171300229]\n",
      "KL loss: 0.00587844476 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0194136985 0.0197428837 0.0200560819 ... 0.014986421 0.0145991715 0.0142106395]\n",
      "KL loss: 0.0241162404 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.017567059 0.0179769117 0.0183757711 ... 0.0154193211 0.014983613 0.0145460656]\n",
      "KL loss: 0.00615561893 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0217522308 0.0218380634 0.0219126828 ... 0.0159072 0.0156542733 0.015400297]\n",
      "KL loss: 0.00170962873 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0210180245 0.0211388804 0.0212490205 ... 0.0163152292 0.0160657205 0.015814703]\n",
      "KL loss: 0.0309242252 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0231281575 0.0232921243 0.0234350152 ... 0.0131859006 0.012830995 0.0124806976]\n",
      "KL loss: 0.0053966688 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0228945985 0.0229327325 0.0229597408 ... 0.014886139 0.0145932185 0.014300175]\n",
      "KL loss: 0.000468128128 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0204325691 0.0204471629 0.0204597246 ... 0.0189528074 0.0188752133 0.0187958479]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4352 - val_loss: 1.8404\n",
      "Epoch 13/50\n",
      "KL loss: 0.00202866853 hist_true: [0.0174088385 0.017744448 0.0180710219 ... 0.0171355866 0.0167906526 0.0164391026] hist_pred: [0.0207096711 0.0207630098 0.0208112169 ... 0.0178294238 0.0176705346 0.0175084788]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.0066KL loss: 0.0179765932 hist_true: [0.00965987518 0.0103798397 0.0111247823 ... 0.0147873955 0.01398867 0.0132001517] hist_pred: [0.017968148 0.0182203352 0.018466739 ... 0.0165916476 0.016176058 0.0157518368]\n",
      "KL loss: 0.0341849178 hist_true: [0.010218096 0.0107777417 0.0113496734 ... 0.019926684 0.0193821453 0.0188192837] hist_pred: [0.0204938315 0.0206789747 0.0208485145 ... 0.0165296216 0.0162959751 0.0160615146]\n",
      "KL loss: 0.00213467982 hist_true: [0.0178017896 0.0181489475 0.0184856039 ... 0.0163707845 0.0159924701 0.0156091321] hist_pred: [0.0212694928 0.0213389527 0.0214007497 ... 0.0166537762 0.0164306927 0.0162059292]\n",
      "KL loss: 0.0123821367 hist_true: [0.014732657 0.0152013842 0.0156661142 ... 0.0176860988 0.0172557961 0.0168158375] hist_pred: [0.0219369866 0.0220134538 0.0220771767 ... 0.015960604 0.0157132614 0.0154641606]\n",
      "KL loss: 0.010369515 hist_true: [0.0202099103 0.0205108486 0.0207957085 ... 0.0140939048 0.0136673674 0.0132412584] hist_pred: [0.0275641419 0.0273685642 0.0271611903 ... 0.0123239756 0.0120295789 0.0117417164]\n",
      "KL loss: 0.0095066512 hist_true: [0.0149952052 0.0153662935 0.0157339852 ... 0.0197463967 0.01947763 0.0191967748] hist_pred: [0.0201729946 0.0203316286 0.0204810686 ... 0.0166292675 0.0163603257 0.016087994]\n",
      "KL loss: 0.0029026065 hist_true: [0.0179944057 0.0183662064 0.0187260676 ... 0.0156761184 0.0152645828 0.0148495976] hist_pred: [0.0217722598 0.0218025502 0.0218237247 ... 0.0170754809 0.0169227272 0.0167708322]\n",
      "KL loss: 0.00320496 hist_true: [0.0164418574 0.0168444254 0.0172391515 ... 0.0169755165 0.0165780243 0.0161735546] hist_pred: [0.020489255 0.0206101723 0.0207227394 ... 0.0167955272 0.0165417697 0.0162840411]\n",
      "KL loss: 0.0258857794 hist_true: [0.0099284891 0.0104858968 0.011056792 ... 0.0201165173 0.0195566677 0.0189771634] hist_pred: [0.0185711514 0.0188141298 0.0190507565 ... 0.0168888923 0.0165740028 0.0162552111]\n",
      "KL loss: 0.00120497891 hist_true: [0.0182694905 0.0184948947 0.0187129639 ... 0.018165268 0.017930517 0.0176893212] hist_pred: [0.0208433848 0.020856617 0.0208660811 ... 0.0184766445 0.0183831751 0.0182887036]\n",
      "KL loss: 0.00901235174 hist_true: [0.0169280972 0.017241098 0.0175471473 ... 0.0182782151 0.0179920103 0.017697433] hist_pred: [0.023342669 0.0232598875 0.0231703799 ... 0.0165733118 0.0164214112 0.0162691325]\n",
      "KL loss: 0.0310523827 hist_true: [0.00835902803 0.00891551 0.00949251931 ... 0.0210339837 0.0204159655 0.0197744723] hist_pred: [0.0175813194 0.0178424735 0.0180971306 ... 0.0186622515 0.0184577387 0.0182462707]\n",
      "KL loss: 0.00493865879 hist_true: [0.01723608 0.0175062399 0.0177700128 ... 0.0187812317 0.0185482185 0.0183071773] hist_pred: [0.0211876277 0.0212702919 0.0213446189 ... 0.016571749 0.0163385384 0.0161031988]\n",
      "KL loss: 0.00494707096 hist_true: [0.0176673532 0.0181556698 0.0186308157 ... 0.0137646459 0.0132396966 0.0127172228] hist_pred: [0.018240355 0.0184648763 0.0186837949 ... 0.0175196398 0.0171901807 0.0168503709]\n",
      "KL loss: 0.00830740388 hist_true: [0.0181869324 0.0185124 0.0188269094 ... 0.0162889697 0.0159204975 0.0155472914] hist_pred: [0.0249038655 0.0247610528 0.0246096421 ... 0.0154455882 0.0152695253 0.0150946435]\n",
      "KL loss: 0.00916318 hist_true: [0.0158520397 0.0163114443 0.0167638101 ... 0.0164723191 0.0160185117 0.0155587057] hist_pred: [0.0228466243 0.0228123851 0.0227713659 ... 0.0160243586 0.0157969352 0.0155679556]\n",
      "KL loss: 0.0439696908 hist_true: [0.011828348 0.0124122938 0.0130039537 ... 0.0174523 0.0168489888 0.0162365] hist_pred: [0.0246301889 0.0246722829 0.0246874057 ... 0.0145891821 0.0144093065 0.0142341759]\n",
      "KL loss: 0.00644415291 hist_true: [0.0167399924 0.0171068013 0.017465733 ... 0.0173479486 0.0169870798 0.0166186616] hist_pred: [0.0223804973 0.0223736484 0.0223598052 ... 0.0164361801 0.0162381902 0.0160395987]\n",
      "KL loss: 0.00910072587 hist_true: [0.0186301172 0.0189984366 0.019352939 ... 0.0149320485 0.0144995824 0.014065397] hist_pred: [0.0177582093 0.0178888794 0.0180188715 ... 0.0200765878 0.0199067499 0.0197239704]\n",
      "KL loss: 0.00319555565 hist_true: [0.0160430055 0.0164933745 0.0169360489 ... 0.016489476 0.0160463173 0.0155971693] hist_pred: [0.0199315213 0.0200734232 0.0202066712 ... 0.0176059715 0.0174225066 0.0172379222]\n",
      "KL loss: 0.00772002153 hist_true: [0.013470822 0.0140264938 0.0145829283 ... 0.0167998597 0.0162518118 0.0156966913] hist_pred: [0.0195495971 0.0196559168 0.019757688 ... 0.0179050714 0.0176545102 0.0173946433]\n",
      "KL loss: 0.000574173871 hist_true: [0.0182275921 0.0184942186 0.0187519696 ... 0.0173824765 0.0170880854 0.0167875197] hist_pred: [0.0188028589 0.0189571716 0.0191062093 ... 0.0187886413 0.0186268929 0.018459864]\n",
      "KL loss: 0.00570290256 hist_true: [0.02001114 0.0205586459 0.0210830141 ... 0.0105786985 0.0100204935 0.00947675575] hist_pred: [0.0245098025 0.0245578866 0.0245836787 ... 0.0133922 0.0130806062 0.0127723869]\n",
      "KL loss: 0.00331642758 hist_true: [0.015657397 0.016132867 0.0166017767 ... 0.0163198821 0.0158468243 0.0153680323] hist_pred: [0.0197288711 0.01988912 0.0200414807 ... 0.0171198323 0.0168558545 0.0165863447]\n",
      "KL loss: 0.00689642224 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0194188505 0.0197759587 0.0201169141 ... 0.0141996071 0.0137540027 0.0133083556]\n",
      "KL loss: 0.0268809386 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.017774418 0.0181955174 0.018604422 ... 0.0149856415 0.0145324115 0.0140782399]\n",
      "KL loss: 0.00760927238 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.021976199 0.0220733285 0.022158118 ... 0.0153489728 0.0150637375 0.0147778764]\n",
      "KL loss: 0.0019545923 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0210962538 0.0212269351 0.0213461835 ... 0.0160319582 0.0157668144 0.01550058]\n",
      "KL loss: 0.0304287188 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0228175074 0.0230072793 0.0231762119 ... 0.013009958 0.0126254242 0.0122450506]\n",
      "KL loss: 0.00751414336 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0233859234 0.023422163 0.0234458782 ... 0.0142223248 0.0139016574 0.0135817928]\n",
      "KL loss: 0.00182391482 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0214176383 0.0213988945 0.0213774387 ... 0.0179905836 0.0178722683 0.0177526176]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0588 - val_loss: 1.6266\n",
      "Epoch 14/50\n",
      "KL loss: 0.00247299578 hist_true: [0.0157692935 0.0161337629 0.0164929293 ... 0.0187861957 0.0184830762 0.0181696285] hist_pred: [0.019376453 0.019441437 0.0195050575 ... 0.0193213429 0.0192051455 0.0190828778]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.9540KL loss: 0.00550247636 hist_true: [0.0174948666 0.0178526677 0.0182005614 ... 0.0165572856 0.0161776952 0.0157924779] hist_pred: [0.0223309379 0.022399161 0.0224580336 ... 0.0149412705 0.0146349221 0.0143291065]\n",
      "KL loss: 0.00678722095 hist_true: [0.015033314 0.0154715013 0.0159052908 ... 0.0180044454 0.0176101774 0.0172059722] hist_pred: [0.0205557663 0.0206595492 0.0207527597 ... 0.0178661663 0.0177323688 0.0175969657]\n",
      "KL loss: 0.0029391502 hist_true: [0.0173609909 0.0178255606 0.0182782356 ... 0.014610542 0.0141177429 0.0136246961] hist_pred: [0.0213670507 0.0214959327 0.0216136836 ... 0.0154741881 0.0151719404 0.0148685211]\n",
      "KL loss: 0.00440500071 hist_true: [0.0178756882 0.0182730835 0.0186584219 ... 0.0152753741 0.0148344 0.0143909138] hist_pred: [0.0196030028 0.0196931586 0.0197779611 ... 0.0190600622 0.0189562514 0.0188478753]\n",
      "KL loss: 0.0278059952 hist_true: [0.00969416555 0.0102307163 0.0107806148 ... 0.0211759917 0.020674834 0.0201505329] hist_pred: [0.01984578 0.0198487025 0.0198428221 ... 0.0217932183 0.0219385289 0.0220792]\n",
      "KL loss: 0.0373526812 hist_true: [0.00970653445 0.0104110548 0.0111392634 ... 0.0150486324 0.0142426705 0.0134448186] hist_pred: [0.0219858643 0.02213482 0.0222622454 ... 0.0138525357 0.0133708445 0.0128849251]\n",
      "KL loss: 0.00619709725 hist_true: [0.0127825029 0.0133065684 0.0138331186 ... 0.0184299648 0.0179418847 0.0174410269] hist_pred: [0.0176952258 0.0179499295 0.0182013176 ... 0.01756813 0.0172448289 0.0169142988]\n",
      "KL loss: 0.00215309532 hist_true: [0.0182034746 0.0185563322 0.0188975129 ... 0.0156838894 0.0152767384 0.0148659833] hist_pred: [0.0216848329 0.0217770096 0.0218594242 ... 0.0155145237 0.0152145363 0.0149124097]\n",
      "KL loss: 0.0304263458 hist_true: [0.0159715619 0.0163761657 0.0167740434 ... 0.0175930187 0.0172159597 0.0168304201] hist_pred: [0.0279101804 0.0276005827 0.0272800773 ... 0.0146069592 0.0145028867 0.0144046731]\n",
      "KL loss: 0.0147227934 hist_true: [0.0128537677 0.0133841755 0.0139166703 ... 0.0182954017 0.017808849 0.0173103157] hist_pred: [0.0206969231 0.0207928102 0.0208802484 ... 0.0171351563 0.0169212651 0.0167041421]\n",
      "KL loss: 0.00274939626 hist_true: [0.0171706062 0.0175630506 0.017945651 ... 0.0162613168 0.0158498809 0.0154332668] hist_pred: [0.0210142601 0.0211008228 0.021179283 ... 0.0168298725 0.0166127309 0.0163933448]\n",
      "KL loss: 0.00385963637 hist_true: [0.0197015516 0.0200199988 0.0203231387 ... 0.0144665837 0.0140453661 0.0136237415] hist_pred: [0.0202447549 0.0202993061 0.0203517 ... 0.0178553481 0.0176409744 0.0174192563]\n",
      "KL loss: 0.00528829871 hist_true: [0.0156463906 0.015966462 0.0162825491 ... 0.0200659744 0.0198581498 0.0196395386] hist_pred: [0.0198970623 0.0200057365 0.0201079436 ... 0.0181441493 0.0179883409 0.0178302]\n",
      "KL loss: 0.00735263899 hist_true: [0.0159894861 0.0163964033 0.0167967286 ... 0.0174455084 0.0170566458 0.0166594274] hist_pred: [0.0220900048 0.022079004 0.0220596753 ... 0.017414 0.0172897354 0.0171647184]\n",
      "KL loss: 0.00126949139 hist_true: [0.0179041196 0.0181598533 0.0184079874 ... 0.0180813372 0.0178242549 0.0175602082] hist_pred: [0.0190790221 0.0191556402 0.0192293972 ... 0.0201615561 0.0201373193 0.0201108605]\n",
      "KL loss: 0.0123132663 hist_true: [0.0155780744 0.0161023028 0.0166199133 ... 0.0153376162 0.0148090767 0.0142781772] hist_pred: [0.0231644846 0.0232507531 0.0233196411 ... 0.0141669558 0.0138415135 0.013516211]\n",
      "KL loss: 0.00281352364 hist_true: [0.0165893268 0.0170132015 0.0174281858 ... 0.016373096 0.0159455426 0.0155124] hist_pred: [0.0203263182 0.0204002149 0.020468602 ... 0.0177262947 0.017522186 0.0173129849]\n",
      "KL loss: 0.001539947 hist_true: [0.0167462714 0.0170906577 0.0174276773 ... 0.0178427193 0.0175165087 0.0171820763] hist_pred: [0.0195121653 0.0196623132 0.0198051985 ... 0.0178231597 0.0176199581 0.0174130015]\n",
      "KL loss: 0.0255660377 hist_true: [0.00916132238 0.00973844808 0.0103334924 ... 0.0197753534 0.0191358738 0.0184779689] hist_pred: [0.0178580489 0.0181519203 0.0184323918 ... 0.0180693716 0.017800305 0.0175213385]\n",
      "KL loss: 0.00555975223 hist_true: [0.0142663941 0.0147734173 0.0152780432 ... 0.0172528 0.0167735107 0.0162857678] hist_pred: [0.019247409 0.019421909 0.0195864383 ... 0.0181410816 0.0179491062 0.017751094]\n",
      "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6821 KL loss: 0.00542242127 hist_true: [0.0119439503 0.0126831867 0.0134353256 ... 0.0134318369 0.0126978653 0.0119767115] hist_pred: [0.015924396 0.0164557826 0.0169791803 ... 0.0155090578 0.0151181417 0.0147382589]\n",
      "KL loss: 0.00320243486 hist_true: [0.0182909891 0.0185478795 0.0187961068 ... 0.0174816418 0.0171966292 0.0169054028] hist_pred: [0.0222077239 0.0222085323 0.0222023185 ... 0.0165546034 0.0163568389 0.0161579102]\n",
      "KL loss: 0.0134678744 hist_true: [0.0167230181 0.017426502 0.0181194879 ... 0.0109223947 0.0102907596 0.00967690535] hist_pred: [0.0249046925 0.0251574311 0.0253749881 ... 0.0108886501 0.0105372686 0.0101998271]\n",
      "KL loss: 0.00432408554 hist_true: [0.0181033593 0.018383028 0.0186537411 ... 0.0172765777 0.0169685613 0.0166542549] hist_pred: [0.0228574239 0.0228038616 0.0227432717 ... 0.0169947743 0.0168833341 0.0167746469]\n",
      "KL loss: 0.00573957711 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0188795626 0.0192689952 0.0196431857 ... 0.0142928399 0.0138408616 0.0133895194]\n",
      "KL loss: 0.0207258463 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.016885804 0.0173277073 0.0177594442 ... 0.0157062784 0.0152604636 0.0148117589]\n",
      "KL loss: 0.0069953287 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0216370542 0.0217624605 0.021874873 ... 0.0153607521 0.0150639238 0.0147660235]\n",
      "KL loss: 0.00203690026 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0210211519 0.0211721491 0.0213106368 ... 0.0158556961 0.0155804679 0.0153046297]\n",
      "KL loss: 0.0224734973 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0214340817 0.0216816887 0.0219106022 ... 0.0136953425 0.0132969264 0.0129003571]\n",
      "KL loss: 0.00564981624 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0227075741 0.0227816366 0.0228428487 ... 0.0146165928 0.0143038174 0.0139914015]\n",
      "KL loss: 0.00171512901 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0212386809 0.0212364234 0.0212310329 ... 0.0179425981 0.0178118497 0.0176792648]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6423 - val_loss: 1.3171\n",
      "Epoch 15/50\n",
      "KL loss: 0.0014097034 hist_true: [0.0179507434 0.0182016287 0.0184450224 ... 0.0181016494 0.0178475864 0.0175865702] hist_pred: [0.0205468386 0.0206220131 0.0206918027 ... 0.0175201669 0.0173280127 0.0171326753]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6815KL loss: 0.00198133616 hist_true: [0.0186813381 0.0190008618 0.0193082616 ... 0.0157256499 0.0153400125 0.0149508733] hist_pred: [0.0220817551 0.0220752787 0.022063734 ... 0.0165946893 0.0163811389 0.0161649399]\n",
      "KL loss: 0.00269490108 hist_true: [0.0180911105 0.0185559876 0.0190063175 ... 0.0138042383 0.013296878 0.0127915172] hist_pred: [0.0183349382 0.0186227299 0.0189011283 ... 0.0165474322 0.0161822736 0.0158106703]\n",
      "KL loss: 0.00572696049 hist_true: [0.0140502565 0.0145568941 0.0150618181 ... 0.0174992271 0.0170228649 0.0165371541] hist_pred: [0.0185918454 0.0187122077 0.0188291054 ... 0.0200652909 0.0199963823 0.0199201591]\n",
      "KL loss: 0.055184979 hist_true: [0.00912996847 0.00974569563 0.0103818187 ... 0.0183060318 0.017583549 0.016849855] hist_pred: [0.0229127593 0.0229871608 0.0230406839 ... 0.0151487859 0.0148680098 0.0145830121]\n",
      "KL loss: 0.0125876712 hist_true: [0.0168981813 0.0173465051 0.0177846085 ... 0.0154937357 0.0150303738 0.0145640709] hist_pred: [0.0250838362 0.0249850601 0.0248729531 ... 0.0147377215 0.0145332692 0.0143322088]\n",
      "KL loss: 0.00234696479 hist_true: [0.0178277083 0.0181066655 0.0183774401 ... 0.0176864322 0.0173956733 0.0170979556] hist_pred: [0.021242056 0.0212872513 0.021326432 ... 0.0170628428 0.0168613587 0.0166571196]\n",
      "KL loss: 0.00254943594 hist_true: [0.0173674431 0.0176689755 0.0179627277 ... 0.017895 0.0176006034 0.0172986723] hist_pred: [0.0208583828 0.0209309459 0.0209963843 ... 0.0173526555 0.0171718318 0.0169892125]\n",
      "KL loss: 0.00818867795 hist_true: [0.0128286714 0.0133556956 0.0138850929 ... 0.0183193833 0.0178292431 0.017326884] hist_pred: [0.0185487568 0.0187617205 0.0189647246 ... 0.0185770728 0.018406406 0.0182309672]\n",
      "KL loss: 0.00182942161 hist_true: [0.0171712749 0.0175068378 0.0178341214 ... 0.017426908 0.0170894638 0.0167446118] hist_pred: [0.0200186651 0.0200512782 0.0200819708 ... 0.0188838299 0.0187450182 0.0185989831]\n",
      "KL loss: 0.0222064368 hist_true: [0.00991718 0.0104671698 0.0110301785 ... 0.0205027815 0.0199721754 0.0194207765] hist_pred: [0.0172806289 0.0176390037 0.0179885272 ... 0.0172503348 0.0169518776 0.0166505538]\n",
      "KL loss: 0.00314569334 hist_true: [0.0164678805 0.0168956108 0.01731495 ... 0.0163874626 0.0159536824 0.0155141745] hist_pred: [0.020349266 0.0205300283 0.0206998773 ... 0.015990546 0.0156839937 0.0153746577]\n",
      "KL loss: 0.0116776507 hist_true: [0.0178119373 0.0182728022 0.0187202673 ... 0.0141952084 0.0136993891 0.01320461] hist_pred: [0.0165465511 0.0167994108 0.0170490593 ... 0.0201355927 0.0199748334 0.0198043492]\n",
      "KL loss: 0.00414738059 hist_true: [0.0141921351 0.0145851336 0.01497648 ... 0.020319039 0.0200497229 0.0197663456] hist_pred: [0.0185055044 0.0186119061 0.018714672 ... 0.0204064287 0.0203596149 0.0203073528]\n",
      "KL loss: 0.0130324699 hist_true: [0.010040394 0.0106166089 0.0112066 ... 0.0194114912 0.01881909 0.0182100497] hist_pred: [0.016425861 0.0167418029 0.0170478392 ... 0.0201092269 0.0199847873 0.0198531356]\n",
      "KL loss: 0.0227309857 hist_true: [0.0100819562 0.0107367337 0.0114094643 ... 0.0165982042 0.0158629399 0.0151249515] hist_pred: [0.0186143015 0.0189675111 0.0193094015 ... 0.0155437123 0.0151694966 0.0147916935]\n",
      "KL loss: 0.0075675752 hist_true: [0.0187901 0.0194432028 0.020076707 ... 0.0101556499 0.00956674479 0.00899630319] hist_pred: [0.0215579662 0.0218483694 0.0221126471 ... 0.0142879765 0.0139635904 0.0136380438]\n",
      "KL loss: 0.000590303564 hist_true: [0.019801544 0.0200101752 0.0202079564 ... 0.0162570067 0.0159461666 0.0156315472] hist_pred: [0.0216748677 0.021711953 0.0217419956 ... 0.0166191198 0.0164052825 0.0161897559]\n",
      "KL loss: 0.0068161306 hist_true: [0.0161546264 0.0165658258 0.0169697739 ... 0.0171675 0.0167692751 0.0163634215] hist_pred: [0.0215308219 0.0216368251 0.021731969 ... 0.015826134 0.0155690089 0.0153124]\n",
      "KL loss: 0.0034163706 hist_true: [0.0165039431 0.0169176199 0.0173230246 ... 0.0166487359 0.0162323192 0.0158095434] hist_pred: [0.0200329982 0.0200692974 0.0201022215 ... 0.0189524833 0.0188199803 0.0186802]\n",
      "KL loss: 0.00630427152 hist_true: [0.0188252274 0.0190304741 0.0192277767 ... 0.0177357066 0.0174917579 0.0172421616] hist_pred: [0.0239191167 0.0238183029 0.0237123743 ... 0.0156000117 0.0153859667 0.0151719609]\n",
      "KL loss: 0.00441667251 hist_true: [0.0176144596 0.0179752316 0.0183257032 ... 0.0163279064 0.0159384981 0.0155439703] hist_pred: [0.0224573482 0.0224763323 0.0224871803 ... 0.0157895051 0.0155440597 0.0152975889]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6192 KL loss: 0.00327341771 hist_true: [0.0178603753 0.0181664787 0.0184633471 ... 0.0170887709 0.0167582259 0.0164214391] hist_pred: [0.0219001379 0.021933265 0.0219589472 ... 0.0164608955 0.016253924 0.0160465688]\n",
      "KL loss: 0.00306531787 hist_true: [0.0175012 0.0179840103 0.0184539966 ... 0.0141577506 0.0136511326 0.0131459301] hist_pred: [0.0187695809 0.0189872012 0.0191982798 ... 0.0171253812 0.0168193728 0.0165072586]\n",
      "KL loss: 0.000831789337 hist_true: [0.0169132 0.0171836521 0.0174485166 ... 0.0192745663 0.0190657023 0.0188483391] hist_pred: [0.0187806636 0.0188541356 0.0189271476 ... 0.0203088783 0.0202670954 0.0202213936]\n",
      "KL loss: 0.00402122736 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0181579534 0.0185796805 0.0189875253 ... 0.0146123907 0.0141539332 0.0136951944]\n",
      "KL loss: 0.0153918881 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0160834473 0.0165353604 0.0169793945 ... 0.0164667685 0.0160313025 0.0155907804]\n",
      "KL loss: 0.00463161245 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0207116101 0.0208821557 0.0210404936 ... 0.0158083607 0.0155076357 0.0152047984]\n",
      "KL loss: 0.00122910528 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0204450414 0.020620333 0.0207836926 ... 0.0161980651 0.0159222 0.0156446602]\n",
      "KL loss: 0.0152220763 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0200508237 0.0203487929 0.0206306875 ... 0.0145625025 0.0141706634 0.0137791513]\n",
      "KL loss: 0.00569887226 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0226747543 0.022756055 0.0228240732 ... 0.0145856524 0.0142727681 0.0139605301]\n",
      "KL loss: 0.00100317085 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0207799375 0.0207951255 0.0208073091 ... 0.0183731019 0.0182608217 0.0181465782]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6185 - val_loss: 1.1903\n",
      "Epoch 16/50\n",
      "KL loss: 0.0114303175 hist_true: [0.0140199233 0.014491871 0.0149621814 ... 0.018406231 0.0179841742 0.0175501909] hist_pred: [0.0199585315 0.0201950129 0.0204181354 ... 0.0158007275 0.0154814059 0.0151600819]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3432KL loss: 0.00854742341 hist_true: [0.017576158 0.018124748 0.0186596438 ... 0.0128121059 0.0122506404 0.0116959596] hist_pred: [0.0244813226 0.0245532058 0.0246063266 ... 0.0128000369 0.0124623617 0.0121291485]\n",
      "KL loss: 0.00346999429 hist_true: [0.0191199705 0.0193251576 0.0195216276 ... 0.0172921401 0.0170270447 0.0167567451] hist_pred: [0.0184310135 0.0185133554 0.018595539 ... 0.0207071044 0.0206805803 0.0206493065]\n",
      "KL loss: 0.00388217438 hist_true: [0.0100224568 0.0106225675 0.0112379519 ... 0.0183266886 0.0176565554 0.016973868] hist_pred: [0.0114085609 0.0117926514 0.0121863391 ... 0.0219214857 0.0215029847 0.0210597012]\n",
      "KL loss: 0.00337540498 hist_true: [0.0165119823 0.0169224516 0.0173246954 ... 0.0167084206 0.0162962731 0.0158776511] hist_pred: [0.0200809464 0.0201169606 0.0201494973 ... 0.0189342257 0.0188075528 0.0186741222]\n",
      "KL loss: 0.00270721433 hist_true: [0.017323181 0.0176662188 0.0180003531 ... 0.0170634408 0.0167084914 0.0163468588] hist_pred: [0.0211069472 0.0211780574 0.0212409124 ... 0.0169548765 0.0167412423 0.0165244229]\n",
      "KL loss: 0.00150122424 hist_true: [0.018347634 0.0186197273 0.0188823715 ... 0.0170999859 0.0167900193 0.0164741594] hist_pred: [0.0211277548 0.0212037116 0.0212722886 ... 0.0167216919 0.0164963119 0.016268773]\n",
      "KL loss: 0.000681610778 hist_true: [0.0153083345 0.0157178827 0.0161226224 ... 0.0183261856 0.01796652 0.0175964963] hist_pred: [0.0168722887 0.0171379056 0.0173985548 ... 0.0192568563 0.0190325119 0.0187984835]\n",
      "KL loss: 0.00955179892 hist_true: [0.00981340371 0.0104096849 0.0110219549 ... 0.0187514238 0.0181036666 0.0174422376] hist_pred: [0.0148617495 0.0152728502 0.0156755317 ... 0.020552801 0.0203905664 0.0202171914]\n",
      "KL loss: 0.00876142457 hist_true: [0.0177418124 0.0182052553 0.0186554641 ... 0.0142069189 0.0137070026 0.0132079432] hist_pred: [0.0240815803 0.0241783559 0.0242562275 ... 0.0128177283 0.0124687804 0.0121254753]\n",
      "KL loss: 0.00160808279 hist_true: [0.0195510797 0.0197648033 0.0199681669 ... 0.0165117737 0.0162085388 0.015901072] hist_pred: [0.0223897621 0.0224130228 0.0224272702 ... 0.0159714 0.0157444309 0.015517259]\n",
      "KL loss: 0.000577817205 hist_true: [0.019034503 0.0193552058 0.019662682 ... 0.0152433189 0.0148415091 0.0144372862] hist_pred: [0.0198872332 0.0200682878 0.0202407967 ... 0.0165166035 0.0162314903 0.0159435384]\n",
      "KL loss: 0.0108500635 hist_true: [0.0109191807 0.0115604447 0.0122151 ... 0.0164880324 0.0157908909 0.0150902532] hist_pred: [0.0167896263 0.0172016695 0.0176059622 ... 0.0169523954 0.0166515894 0.016350532]\n",
      "KL loss: 0.00341758179 hist_true: [0.0171635132 0.0175895672 0.0180052668 ... 0.0155411838 0.0150865018 0.0146285128] hist_pred: [0.0178178847 0.018033931 0.0182444248 ... 0.0189231746 0.0187137555 0.018495433]\n",
      "KL loss: 0.00199890696 hist_true: [0.0186556932 0.0189660285 0.019264644 ... 0.0159298629 0.0155552747 0.0151767302] hist_pred: [0.0216326285 0.0216411147 0.0216432717 ... 0.0174381118 0.0172911808 0.017142728]\n",
      "KL loss: 0.011238141 hist_true: [0.00996628217 0.0105722453 0.0111936135 ... 0.01853179 0.0178907868 0.0172372553] hist_pred: [0.0162940621 0.0165898986 0.0168847051 ... 0.0180923194 0.0177097768 0.0173165575]\n",
      "KL loss: 0.00214343425 hist_true: [0.0189951807 0.0192037728 0.0194038041 ... 0.0174170099 0.0171563383 0.0168903042] hist_pred: [0.0224909894 0.0224270616 0.0223591235 ... 0.0173357334 0.0172147378 0.0170942601]\n",
      "KL loss: 0.00641057733 hist_true: [0.0215660539 0.0219962578 0.022399947 ... 0.0108870333 0.0103792241 0.00988280587] hist_pred: [0.0223305132 0.0224092193 0.0224770065 ... 0.0148043651 0.0144821582 0.0141597297]\n",
      "KL loss: 0.00196754793 hist_true: [0.013826469 0.0142970132 0.0147663932 ... 0.0187295191 0.0183215607 0.0179009959] hist_pred: [0.0167162139 0.0169852469 0.0172496215 ... 0.0193620268 0.0191330891 0.0188935716]\n",
      "KL loss: 0.00551917218 hist_true: [0.0166297387 0.0170178767 0.0173980445 ... 0.016987063 0.0165948626 0.0161954518] hist_pred: [0.0216849744 0.0217629317 0.0218305904 ... 0.0161579791 0.0159254353 0.0156922899]\n",
      "KL loss: 0.00274698948 hist_true: [0.0195304472 0.0197372176 0.0199340209 ... 0.0166695975 0.0163764395 0.016078895] hist_pred: [0.0232947357 0.0232371725 0.0231737718 ... 0.0158060081 0.0155893601 0.0153727606]\n",
      "KL loss: 0.0106857242 hist_true: [0.016861476 0.0172984805 0.0177256223 ... 0.015741257 0.0152878212 0.0148305316] hist_pred: [0.0237456672 0.0237781201 0.0237974711 ... 0.0138194421 0.0134979216 0.0131798349]\n",
      "KL loss: 0.00775029603 hist_true: [0.0177043471 0.0180112664 0.0183094162 ... 0.0172699392 0.0169441588 0.0166116841] hist_pred: [0.0230289456 0.0230515581 0.023064319 ... 0.0148110008 0.014513446 0.0142158251]\n",
      "KL loss: 0.00710988231 hist_true: [0.0166370962 0.0169829614 0.0173217468 ... 0.017957937 0.0176347103 0.0173030049] hist_pred: [0.0222041626 0.0222154371 0.0222194735 ... 0.0163851567 0.016181048 0.0159765724]\n",
      "KL loss: 0.000845087692 hist_true: [0.0198925305 0.0202047341 0.0205011871 ... 0.0143576581 0.0139380069 0.0135182925] hist_pred: [0.02131298 0.0214209799 0.0215196069 ... 0.0157125853 0.0154121267 0.0151094021]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2055 KL loss: 0.00556328567 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0184229519 0.0188567061 0.0192757919 ... 0.013905366 0.0134094367 0.0129148318]\n",
      "KL loss: 0.0210976638 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0165706314 0.0170466527 0.01751283 ... 0.0153775085 0.0148981549 0.014416486]\n",
      "KL loss: 0.00783637725 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0215289 0.0216877703 0.0218323953 ... 0.0149209527 0.0145930117 0.0142646618]\n",
      "KL loss: 0.00183053897 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0207495056 0.0209277235 0.021092914 ... 0.0157799013 0.0154932551 0.0152062578]\n",
      "KL loss: 0.022834722 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0210658479 0.0213549752 0.0216253251 ... 0.0133317122 0.0128957061 0.0124621615]\n",
      "KL loss: 0.00797476619 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0230554119 0.023148356 0.0232262686 ... 0.0138372127 0.0134868352 0.0131380074]\n",
      "KL loss: 0.00478761457 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0226043239 0.0225476194 0.0224871896 ... 0.0168041736 0.0166354682 0.0164660215]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2065 - val_loss: 1.1145\n",
      "Epoch 17/50\n",
      "KL loss: 0.00786941126 hist_true: [0.0187858772 0.0192297921 0.0196576081 ... 0.0133531652 0.0128482329 0.0123467501] hist_pred: [0.0186399221 0.0188232679 0.0190000292 ... 0.018098874 0.0178421624 0.0175764058]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2203KL loss: 0.00929568335 hist_true: [0.0168674905 0.0172632337 0.0176498722 ... 0.016615659 0.0162156336 0.0158097073] hist_pred: [0.0230771676 0.0231291316 0.0231676232 ... 0.0146213071 0.0143277505 0.014035292]\n",
      "KL loss: 0.00217391318 hist_true: [0.0181318279 0.0184902828 0.0188370645 ... 0.0156799126 0.015270439 0.0148573862] hist_pred: [0.0216599908 0.0217502769 0.021831926 ... 0.015280311 0.0149458991 0.0146080656]\n",
      "KL loss: 0.00599101745 hist_true: [0.0107414853 0.0112812892 0.0118306875 ... 0.0201031901 0.0195999872 0.0190776605] hist_pred: [0.0150573663 0.0154077141 0.0157591421 ... 0.0191558711 0.0188296922 0.0184930675]\n",
      "KL loss: 0.00182044227 hist_true: [0.0179579649 0.0183151104 0.0186610781 ... 0.0159279034 0.0155253075 0.0151183698] hist_pred: [0.0210041553 0.0210907161 0.0211685263 ... 0.0168972146 0.0166852325 0.0164712705]\n",
      "KL loss: 0.0277444478 hist_true: [0.00898944493 0.00956970546 0.0101689445 ... 0.01977125 0.0191231333 0.0184569675] hist_pred: [0.0170397703 0.0174591243 0.0178658199 ... 0.0162663199 0.0158540923 0.0154372416]\n",
      "KL loss: 0.00200137962 hist_true: [0.0180434454 0.0183813665 0.0187085085 ... 0.0161902495 0.0158079322 0.015420883] hist_pred: [0.021170469 0.0213051308 0.0214282665 ... 0.0159089379 0.0156473331 0.0153857982]\n",
      "KL loss: 0.00359583879 hist_true: [0.0189127401 0.0194057543 0.0198804829 ... 0.0125814723 0.0120591158 0.0115434099] hist_pred: [0.0233260263 0.0234492533 0.0235515535 ... 0.0137765687 0.0134791732 0.0131880706]\n",
      "KL loss: 0.00899193063 hist_true: [0.020203054 0.02067299 0.0211207028 ... 0.0115462383 0.011018062 0.0104995715] hist_pred: [0.0216283631 0.0216951314 0.0217509195 ... 0.0164971184 0.0162632726 0.0160249695]\n",
      "KL loss: 0.00664684735 hist_true: [0.0136101618 0.0142067457 0.0148046818 ... 0.0154308118 0.0148127712 0.0141931325] hist_pred: [0.0193716902 0.0195408165 0.0197040923 ... 0.0163101666 0.0159225408 0.0155287171]\n",
      "KL loss: 0.0114132417 hist_true: [0.00986325182 0.0104191843 0.010988689 ... 0.0202551298 0.0197002124 0.0191250816] hist_pred: [0.0158481281 0.0161575694 0.0164620932 ... 0.0199545734 0.0197420828 0.0195190869]\n",
      "KL loss: 0.00609101541 hist_true: [0.0173008423 0.0177203957 0.0181293115 ... 0.0154979201 0.0150453849 0.0145896096] hist_pred: [0.023253113 0.023205163 0.0231484193 ... 0.0158963259 0.0156724248 0.0154463341]\n",
      "KL loss: 0.00714934897 hist_true: [0.0153993554 0.0158023983 0.0162003953 ... 0.0183788445 0.0180278961 0.0176666155] hist_pred: [0.0203106608 0.0204860643 0.0206507724 ... 0.0163536649 0.0160932317 0.0158322919]\n",
      "KL loss: 0.0032060456 hist_true: [0.0185128804 0.0188820809 0.0192381926 ... 0.0149811599 0.0145453308 0.0141076911] hist_pred: [0.0226793494 0.0227578841 0.022823697 ... 0.0144787915 0.0141501734 0.0138216093]\n",
      "KL loss: 0.00117854308 hist_true: [0.0151082044 0.0155542381 0.0159955788 ... 0.0177095477 0.0172980763 0.0168772042] hist_pred: [0.0173038654 0.0175851714 0.0178597886 ... 0.018501116 0.0182637554 0.018020818]\n",
      "KL loss: 0.00570908189 hist_true: [0.0166298319 0.016999647 0.0173617173 ... 0.017464349 0.0171080418 0.0167440381] hist_pred: [0.0217485838 0.0218051486 0.021851968 ... 0.0164826307 0.0162745528 0.0160656683]\n",
      "KL loss: 0.0086301351 hist_true: [0.0181913674 0.0185859259 0.0189674851 ... 0.0149442637 0.0144962175 0.0140464893] hist_pred: [0.0162479356 0.0165267959 0.0168029387 ... 0.0197335985 0.0195155758 0.0192868337]\n",
      "KL loss: 0.00218102941 hist_true: [0.0138895148 0.0143818017 0.0148727838 ... 0.0180772468 0.0176296607 0.0171710923] hist_pred: [0.0149075808 0.0151877087 0.015471423 ... 0.0207934082 0.0205488354 0.0202874634]\n",
      "KL loss: 0.00801304169 hist_true: [0.015283687 0.0157473721 0.016205702 ... 0.0170643106 0.0166201834 0.0161682926] hist_pred: [0.0212032106 0.0213234108 0.0214332361 ... 0.0157393292 0.0154360225 0.0151298214]\n",
      "KL loss: 0.00557553256 hist_true: [0.0177891199 0.0181014203 0.0184045099 ... 0.0170474965 0.0167104956 0.0163671747] hist_pred: [0.0230155289 0.0229807887 0.0229393672 ... 0.0158078 0.0155753735 0.0153418044]\n",
      "KL loss: 0.00337244477 hist_true: [0.0137106609 0.0141840028 0.0146565046 ... 0.0188095793 0.0184017159 0.0179810394] hist_pred: [0.0145159727 0.0148077318 0.0150993858 ... 0.0225174092 0.022455303 0.0223808214]\n",
      "KL loss: 0.00418383628 hist_true: [0.0179230701 0.0182445832 0.0185560938 ... 0.0167098958 0.016357759 0.0160000399] hist_pred: [0.022469366 0.022476444 0.0224779621 ... 0.015458975 0.015168421 0.0148758143]\n",
      "KL loss: 0.0364754684 hist_true: [0.0096444441 0.0103210043 0.011019703 ... 0.0159131456 0.015128023 0.0143454624] hist_pred: [0.0193048306 0.0197573975 0.0201947168 ... 0.0121430466 0.0116218906 0.011111958]\n",
      "KL loss: 0.0016363574 hist_true: [0.0177226271 0.0179751255 0.0182206295 ... 0.0184234474 0.0181844793 0.017938219] hist_pred: [0.0205403436 0.0206006281 0.0206559841 ... 0.017860556 0.0176936686 0.0175234452]\n",
      "KL loss: 0.00236351602 hist_true: [0.0188490022 0.0192244127 0.0195852201 ... 0.0145246899 0.0140788639 0.0136325639] hist_pred: [0.0223632958 0.022425618 0.0224751011 ... 0.015645111 0.0153987147 0.0151516283]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0058 KL loss: 0.00193424243 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0170096811 0.0174789447 0.017937094 ... 0.0149833849 0.0144976899 0.0140105374]\n",
      "KL loss: 0.00932384841 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0146848587 0.0151777035 0.0156664178 ... 0.0172595102 0.0168090817 0.0163510162]\n",
      "KL loss: 0.00294886972 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0197706223 0.0199956838 0.0202089045 ... 0.0160921663 0.0157740545 0.0154527212]\n",
      "KL loss: 0.00071895594 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0198263451 0.0200460684 0.0202536657 ... 0.0162732098 0.0159829799 0.0156909544]\n",
      "KL loss: 0.0104059223 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0187268853 0.0190845951 0.0194285698 ... 0.0150248418 0.0146037117 0.0141809247]\n",
      "KL loss: 0.00402005669 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0217588618 0.0219012238 0.0220299494 ... 0.0147790927 0.0144454772 0.014111558]\n",
      "KL loss: 0.00179374358 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0211897548 0.0211984944 0.0212034564 ... 0.0178433023 0.0177040081 0.0175628383]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0074 - val_loss: 0.9086\n",
      "Epoch 18/50\n",
      "KL loss: 0.00348937185 hist_true: [0.0161038823 0.0165451914 0.0169788599 ... 0.0165824126 0.016146319 0.0157039687] hist_pred: [0.0192749016 0.0194167085 0.0195492897 ... 0.0191255 0.0190356541 0.0189423151]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.0614KL loss: 0.00601217384 hist_true: [0.0170004461 0.0173436943 0.0176789425 ... 0.0175109487 0.0171731301 0.0168278031] hist_pred: [0.0218274761 0.02190792 0.0219785441 ... 0.0156899877 0.015422564 0.0151546849]\n",
      "KL loss: 0.00409827894 hist_true: [0.0103287324 0.0108834477 0.0114496853 ... 0.0200650301 0.0195387136 0.0189936552] hist_pred: [0.0137034478 0.0141025 0.0144992433 ... 0.0214146 0.0212201606 0.0210103616]\n",
      "KL loss: 0.00488099363 hist_true: [0.0165098086 0.0168494172 0.0171824526 ... 0.0182796139 0.017973965 0.0176593959] hist_pred: [0.0206954405 0.0208329409 0.0209591221 ... 0.016754888 0.016544288 0.0163336657]\n",
      "KL loss: 0.0200711172 hist_true: [0.00858270749 0.00917726848 0.0097938925 ... 0.0193413515 0.0186418854 0.0179269854] hist_pred: [0.015879 0.0162788518 0.0166693907 ... 0.0189861823 0.018753333 0.0185120702]\n",
      "KL loss: 0.00145110581 hist_true: [0.0179145187 0.0181898866 0.018456934 ... 0.0176460631 0.0173568614 0.0170608927] hist_pred: [0.0206332672 0.0207056105 0.0207711272 ... 0.0179072879 0.0177794136 0.0176520552]\n",
      "KL loss: 0.00584017672 hist_true: [0.0163378268 0.016685877 0.017027583 ... 0.0183359534 0.0180264264 0.0177077074] hist_pred: [0.0212611966 0.0213286281 0.021387713 ... 0.016967617 0.0167845227 0.0166015904]\n",
      "KL loss: 0.00094961 hist_true: [0.0175483208 0.0178830791 0.0182084795 ... 0.0169527195 0.0166010112 0.0162430629] hist_pred: [0.0193986315 0.0195466913 0.0196879 ... 0.0181568973 0.0179829 0.0178055596]\n",
      "KL loss: 0.00972089544 hist_true: [0.0159300603 0.0165064596 0.0170746613 ... 0.0139660817 0.0133930147 0.0128230667] hist_pred: [0.0168004464 0.0170285348 0.0172536578 ... 0.019380698 0.019098267 0.0188000649]\n",
      "KL loss: 0.00338702812 hist_true: [0.018537404 0.0188076906 0.0190681331 ... 0.0168551821 0.0165358298 0.0162110329] hist_pred: [0.0224279333 0.0224579535 0.0224788189 ... 0.015635252 0.0153727932 0.0151088573]\n",
      "KL loss: 0.000688890927 hist_true: [0.0180315208 0.0183087215 0.0185771622 ... 0.0174539071 0.0171564519 0.0168525465] hist_pred: [0.0188446455 0.0189985856 0.0191464256 ... 0.0189789981 0.0188496355 0.0187167898]\n",
      "KL loss: 0.000757962931 hist_true: [0.0186255388 0.0188982673 0.0191607587 ... 0.0166953821 0.0163693186 0.016038131] hist_pred: [0.0191947185 0.0193393808 0.0194783788 ... 0.0182875246 0.0180979222 0.0179030206]\n",
      "KL loss: 0.0110451737 hist_true: [0.0153690577 0.0159791075 0.0165834147 ... 0.0137542235 0.013151451 0.0125534702] hist_pred: [0.0230195057 0.0230208151 0.0230076537 ... 0.0155193601 0.0152161224 0.0149048613]\n",
      "KL loss: 0.00458901515 hist_true: [0.0172032025 0.0176022649 0.0179913845 ... 0.0160440467 0.0156194717 0.0151901934] hist_pred: [0.0223235171 0.0223352518 0.0223388225 ... 0.0159215871 0.0156535935 0.0153816]\n",
      "KL loss: 0.00770475715 hist_true: [0.0175446365 0.0180219281 0.0184863489 ... 0.014173327 0.0136646722 0.0131570511] hist_pred: [0.0165756531 0.016866548 0.0171537232 ... 0.0188260339 0.0185500626 0.0182644315]\n",
      "KL loss: 0.00127133308 hist_true: [0.0188481733 0.0191138461 0.0193689838 ... 0.0165052172 0.0161741413 0.0158382524] hist_pred: [0.0191813428 0.0193133298 0.0194400437 ... 0.0185954906 0.0184300151 0.018259434]\n",
      "KL loss: 0.0146427993 hist_true: [0.0145788994 0.015031673 0.0154813537 ... 0.0181662608 0.0177564044 0.0173356] hist_pred: [0.0222634934 0.0223065 0.0223384667 ... 0.0159233045 0.0156757254 0.0154254185]\n",
      "KL loss: 0.0107509792 hist_true: [0.0132140415 0.0139809726 0.0147553869 ... 0.0120587153 0.011338898 0.0106373541] hist_pred: [0.0161210857 0.016511403 0.0168938246 ... 0.0171883665 0.0167195927 0.01623681]\n",
      "KL loss: 0.0260268543 hist_true: [0.00923189614 0.00985127222 0.0104915174 ... 0.0179270059 0.0171955545 0.0164556336] hist_pred: [0.0185129549 0.0187830813 0.0190359484 ... 0.0178905353 0.0176039506 0.0173033588]\n",
      "KL loss: 0.00123373838 hist_true: [0.0160617679 0.0164910778 0.0169130471 ... 0.0168984178 0.0164795704 0.0160536524] hist_pred: [0.0165625829 0.0168633405 0.0171590783 ... 0.0189762581 0.0187251903 0.0184652153]\n",
      "KL loss: 0.00263806083 hist_true: [0.0174663235 0.017889997 0.0183022823 ... 0.0152615206 0.0148045709 0.0143451728] hist_pred: [0.0213365033 0.0214715619 0.0215953421 ... 0.0151261911 0.014775415 0.0144217284]\n",
      "KL loss: 0.00116461329 hist_true: [0.0176172387 0.0179700255 0.018312797 ... 0.0164625291 0.0160802752 0.0156925321] hist_pred: [0.0200169384 0.0202096552 0.020391576 ... 0.0163081381 0.0160164703 0.0157221984]\n",
      "KL loss: 0.00216366211 hist_true: [0.0197618231 0.0201204829 0.0204619374 ... 0.0137643898 0.0133109726 0.0128591256] hist_pred: [0.0215880703 0.0216578767 0.0217190031 ... 0.0160893705 0.0158264302 0.0155610312]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8606 KL loss: 0.031757392 hist_true: [0.00924596749 0.00981187541 0.010394725 ... 0.0201502964 0.0195384398 0.0189064015] hist_pred: [0.0184851643 0.0187853053 0.0190733131 ... 0.0175384786 0.0173672941 0.0171990357]\n",
      "KL loss: 0.00129249669 hist_true: [0.0182558801 0.0186574459 0.0190457907 ... 0.0146965599 0.0142365061 0.0137754688] hist_pred: [0.0210734159 0.021202147 0.0213234052 ... 0.0152828358 0.0149408849 0.0145978006]\n",
      "KL loss: 0.0116501134 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0197166204 0.0201423634 0.0205491129 ... 0.0126621816 0.0121555729 0.0116542261]\n",
      "KL loss: 0.0230617914 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0168336 0.0173058547 0.017767597 ... 0.0151291154 0.0146485278 0.0141668012]\n",
      "KL loss: 0.00979275443 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0218875501 0.022042701 0.0221829899 ... 0.014401502 0.0140466597 0.0136917448]\n",
      "KL loss: 0.00413897401 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0218042843 0.0219494607 0.0220799465 ... 0.0148963053 0.0145858573 0.0142762484]\n",
      "KL loss: 0.0235084295 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0210025497 0.0213054977 0.021589512 ... 0.0131463902 0.0126980525 0.0122527052]\n",
      "KL loss: 0.0113313813 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0239836611 0.0240368247 0.0240739807 ... 0.0132794166 0.0129253455 0.0125739211]\n",
      "KL loss: 0.00458719209 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0224775914 0.0224308036 0.0223800279 ... 0.0168312415 0.0166608356 0.0164896678]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8702 - val_loss: 0.8644\n",
      "Epoch 19/50\n",
      "KL loss: 0.0195452925 hist_true: [0.014883223 0.0155235631 0.0161601249 ... 0.0136756422 0.0130596161 0.0124496063] hist_pred: [0.0243017636 0.0244395398 0.0245531481 ... 0.0118656661 0.0114540188 0.0110496869]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.9038KL loss: 0.00349056302 hist_true: [0.0170890726 0.0174827613 0.0178668629 ... 0.0163153149 0.0159021132 0.0154834632] hist_pred: [0.0213458817 0.0213584919 0.0213645156 ... 0.0176154599 0.0174396187 0.0172580406]\n",
      "KL loss: 0.0618357435 hist_true: [0.00966200884 0.0102959359 0.0109485807 ... 0.0174506623 0.0167220216 0.015986111] hist_pred: [0.0226734839 0.0229808036 0.0232588705 ... 0.0128996186 0.0126246009 0.0123621821]\n",
      "KL loss: 0.0273469053 hist_true: [0.0093866149 0.00990330614 0.0104345577 ... 0.0217079036 0.0211998262 0.0206654] hist_pred: [0.0164050423 0.0168217216 0.0172322411 ... 0.0166598 0.0162686128 0.0158746168]\n",
      "KL loss: 0.016616147 hist_true: [0.00996163767 0.010610099 0.0112769 ... 0.0168421287 0.0161129944 0.0153801395] hist_pred: [0.0169461016 0.0173772406 0.0178008489 ... 0.0154153733 0.0149492584 0.0144812977]\n",
      "KL loss: 0.0045263716 hist_true: [0.0172232725 0.0175691657 0.0179064367 ... 0.0171204414 0.0167641211 0.0164009109] hist_pred: [0.0218049958 0.0218717847 0.0219272822 ... 0.0164930597 0.0163032264 0.016113935]\n",
      "KL loss: 0.000475175446 hist_true: [0.0201552156 0.0203834623 0.020598907 ... 0.0154111097 0.0150577798 0.0147019839] hist_pred: [0.0208400637 0.0209329054 0.0210191961 ... 0.0165654 0.0163023546 0.0160354283]\n",
      "KL loss: 0.0020082253 hist_true: [0.016569864 0.0171496179 0.0177191459 ... 0.0132028945 0.012621101 0.012045322] hist_pred: [0.0192409568 0.0195295308 0.0198068731 ... 0.0148070809 0.0143410405 0.0138714146]\n",
      "KL loss: 0.00226570014 hist_true: [0.0172786713 0.0176076852 0.0179282743 ... 0.0174448192 0.0171151627 0.0167783778] hist_pred: [0.0174188465 0.0176125728 0.0178017896 ... 0.0203602202 0.020270586 0.0201744977]\n",
      "KL loss: 0.00327113061 hist_true: [0.0158308968 0.01628449 0.0167313069 ... 0.0165992137 0.0161510427 0.0156965107] hist_pred: [0.0199499168 0.020105429 0.020252848 ... 0.016737774 0.0164491534 0.0161552876]\n",
      "KL loss: 0.00120635889 hist_true: [0.0193407219 0.0195715707 0.0197919123 ... 0.0164843295 0.0161710139 0.0158533081] hist_pred: [0.0214828607 0.021480063 0.0214722473 ... 0.0178769194 0.0177651364 0.0176531617]\n",
      "KL loss: 0.00455815764 hist_true: [0.0185548961 0.0188873 0.0192076303 ... 0.0156116756 0.0152125936 0.0148100993] hist_pred: [0.0235577766 0.0235330835 0.0234989952 ... 0.0148828905 0.0146047231 0.0143265193]\n",
      "KL loss: 0.00128619233 hist_true: [0.0175460447 0.0178998783 0.0182439014 ... 0.0165302716 0.0161493383 0.0157627594] hist_pred: [0.0195260849 0.0196676124 0.0198021587 ... 0.0180966798 0.0179204233 0.0177404303]\n",
      "KL loss: 0.003237464 hist_true: [0.0173570532 0.017752815 0.0181381237 ... 0.0159529094 0.0155307176 0.0151041644] hist_pred: [0.0166059863 0.0168926194 0.0171759203 ... 0.0190819129 0.0188488197 0.0186085738]\n",
      "KL loss: 0.00354887499 hist_true: [0.0146538876 0.015090961 0.0155246258 ... 0.0185506344 0.0181752071 0.0177884623] hist_pred: [0.0184051506 0.0185013935 0.018595377 ... 0.0204805117 0.0204108767 0.0203325208]\n",
      "KL loss: 0.0066087381 hist_true: [0.0171603505 0.01753534 0.0179009959 ... 0.0166194923 0.0162290875 0.0158326961] hist_pred: [0.0231249481 0.0230791494 0.0230249632 ... 0.0161815081 0.0159838237 0.0157844629]\n",
      "KL loss: 0.0155185601 hist_true: [0.0138738006 0.0144499214 0.0150252972 ... 0.0160111599 0.0154471137 0.0148791224] hist_pred: [0.0224293917 0.0224925 0.0225409083 ... 0.0157837812 0.0155385295 0.0152898608]\n",
      "KL loss: 0.0005843197 hist_true: [0.0187137611 0.0189314131 0.0191408657 ... 0.0176567063 0.0174023435 0.0171422139] hist_pred: [0.0203114729 0.0203638226 0.0204118099 ... 0.0184953846 0.0183753092 0.0182524584]\n",
      "KL loss: 0.0133378264 hist_true: [0.0180988852 0.018716732 0.0193179324 ... 0.0112673044 0.0106807612 0.0101078777] hist_pred: [0.0173504222 0.0176925082 0.018026948 ... 0.0171497222 0.0168254543 0.0164965503]\n",
      "KL loss: 0.0022292519 hist_true: [0.0160917528 0.0164941903 0.0168897025 ... 0.0174542293 0.017072456 0.0166825037] hist_pred: [0.0189594198 0.0190719925 0.0191811901 ... 0.0192543715 0.01912787 0.0189956967]\n",
      "KL loss: 0.00305884518 hist_true: [0.0184313245 0.0188963134 0.0193457752 ... 0.0134068327 0.0128938528 0.0123843197] hist_pred: [0.0202985406 0.0204688534 0.0206289 ... 0.0162255652 0.0159240216 0.0156178735]\n",
      "KL loss: 0.00709088 hist_true: [0.013496168 0.0139928889 0.0144895632 ... 0.018416388 0.0179698355 0.0175112057] hist_pred: [0.018685244 0.0189191438 0.0191445705 ... 0.017157631 0.0168480892 0.0165312011]\n",
      "KL loss: 0.00057847728 hist_true: [0.0181690026 0.0185019802 0.0188239273 ... 0.0161277466 0.0157464109 0.0153604876] hist_pred: [0.0195959378 0.01976908 0.0199342016 ... 0.0171092637 0.0168499425 0.0165866]\n",
      "KL loss: 0.00156673882 hist_true: [0.0155475298 0.015911974 0.0162717085 ... 0.0191032477 0.018813096 0.0185120888] hist_pred: [0.0182546414 0.0184221324 0.0185844619 ... 0.0194842406 0.0193545166 0.0192186274]\n",
      "KL loss: 0.00713250786 hist_true: [0.0162937548 0.0166545343 0.0170087107 ... 0.0181284808 0.0178028774 0.0174683202] hist_pred: [0.0216485932 0.021718407 0.0217777677 ... 0.0164643936 0.016253503 0.0160417445]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1468 KL loss: 0.000460361771 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0160540957 0.0165335927 0.0170046501 ... 0.0159662645 0.0154993059 0.0150281154]\n",
      "KL loss: 0.0036580083 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0133375041 0.0138385156 0.0143394368 ... 0.0187051669 0.0182814114 0.0178458765]\n",
      "KL loss: 0.000847025309 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0185128618 0.0187822301 0.01904165 ... 0.0169769637 0.0166687854 0.0163553227]\n",
      "KL loss: 0.000243168033 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0191731323 0.0194178913 0.0196514148 ... 0.0166820958 0.0163919814 0.0160988569]\n",
      "KL loss: 0.00485150889 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0172535349 0.0176469591 0.018030202 ... 0.0161754768 0.0157650132 0.0153498575]\n",
      "KL loss: 0.00164975075 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0205980707 0.0207849834 0.0209595654 ... 0.0155889876 0.0152659435 0.0149407368]\n",
      "KL loss: 0.000785386423 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0205352157 0.0205673128 0.0205959212 ... 0.0184881371 0.0183782112 0.0182663575]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1413 - val_loss: 0.6965\n",
      "Epoch 20/50\n",
      "KL loss: 0.00720590539 hist_true: [0.0143407136 0.0148030035 0.0152626513 ... 0.0183099341 0.0179019142 0.0174827687] hist_pred: [0.0198626872 0.0200097132 0.0201474782 ... 0.0178134255 0.0176487956 0.0174825899]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6893KL loss: 0.000682309968 hist_true: [0.0165635739 0.0168884508 0.0172069296 ... 0.0185618605 0.0182808284 0.0179908331] hist_pred: [0.0182930548 0.0184438769 0.0185915828 ... 0.019401066 0.0192522258 0.0190963838]\n",
      "KL loss: 0.000502057606 hist_true: [0.0160597619 0.0164373256 0.0168083943 ... 0.0181097165 0.0177731514 0.0174274445] hist_pred: [0.0172082167 0.0174620301 0.0177106019 ... 0.019156374 0.0189589579 0.0187548455]\n",
      "KL loss: 0.0043095029 hist_true: [0.0129165892 0.0133709442 0.0138266617 ... 0.0203796 0.0200404078 0.0196847264] hist_pred: [0.0168923791 0.0171447191 0.0173912123 ... 0.0198921021 0.0197352469 0.0195703115]\n",
      "KL loss: 0.00112483185 hist_true: [0.017836798 0.0181229133 0.0184004847 ... 0.0175466798 0.0172476042 0.0169418044] hist_pred: [0.0193335954 0.0194216836 0.0195060633 ... 0.0192980133 0.0191965438 0.0190905519]\n",
      "KL loss: 0.00367262866 hist_true: [0.0180432871 0.0183433723 0.0186338071 ... 0.0169764757 0.0166462 0.0163099431] hist_pred: [0.0177092217 0.0178579427 0.0180046689 ... 0.0205531623 0.0204799 0.0203996953]\n",
      "KL loss: 0.00115025602 hist_true: [0.0175911617 0.0179243367 0.0182482228 ... 0.0168792866 0.0165222716 0.0161589924] hist_pred: [0.0194633398 0.0195819568 0.0196955986 ... 0.0183917321 0.0182222277 0.0180478953]\n",
      "KL loss: 0.00747364108 hist_true: [0.0178368669 0.0183507148 0.0188502986 ... 0.0131858839 0.01264749 0.0121140797] hist_pred: [0.0229189228 0.0230055582 0.0230720062 ... 0.0163250118 0.0162550807 0.0161913279]\n",
      "KL loss: 0.0015722597 hist_true: [0.0176160578 0.0180915482 0.0185536705 ... 0.0142287631 0.0137305539 0.0132333534] hist_pred: [0.0189204905 0.0192196965 0.0195050389 ... 0.0163148809 0.0160052534 0.0156936757]\n",
      "KL loss: 0.019997865 hist_true: [0.0167822856 0.0175028555 0.0182127934 ... 0.0105859926 0.00995027 0.00933405757] hist_pred: [0.0185559485 0.0188697036 0.0191636477 ... 0.0181977861 0.0179984607 0.017787315]\n",
      "KL loss: 0.00171167857 hist_true: [0.0182651319 0.0185308028 0.0187875237 ... 0.0173471048 0.0170517191 0.0167502332] hist_pred: [0.0214891247 0.021471573 0.0214518756 ... 0.0175914057 0.0174279977 0.0172612872]\n",
      "KL loss: 0.00240452029 hist_true: [0.0169458147 0.0172477253 0.0175430141 ... 0.0184915438 0.0182217602 0.0179434903] hist_pred: [0.0202778578 0.020367844 0.0204507634 ... 0.0180521756 0.0179087948 0.0177636538]\n",
      "KL loss: 0.00110529247 hist_true: [0.0171717871 0.0175782703 0.0179746319 ... 0.01596714 0.015538441 0.0151053276] hist_pred: [0.019107163 0.0192940794 0.0194749068 ... 0.0173429977 0.0170779712 0.0168084763]\n",
      "KL loss: 0.0114849759 hist_true: [0.00938277 0.00992898643 0.0104903467 ... 0.0208958834 0.0203421917 0.0197652709] hist_pred: [0.0149515197 0.0153306 0.0157016795 ... 0.0208789762 0.0207044855 0.0205139536]\n",
      "KL loss: 0.00172965787 hist_true: [0.0196553208 0.0199377369 0.0202065017 ... 0.0151287671 0.0147420792 0.014353375] hist_pred: [0.0199213624 0.0200444646 0.0201616958 ... 0.0174487066 0.0172199663 0.0169866532]\n",
      "KL loss: 0.00102268672 hist_true: [0.0181491319 0.0185565408 0.0189508907 ... 0.0147167146 0.0142536005 0.013789434] hist_pred: [0.0192570668 0.0194681436 0.0196731035 ... 0.0163514391 0.016006602 0.0156563818]\n",
      "KL loss: 0.0239080824 hist_true: [0.0114521775 0.012050244 0.0126572419 ... 0.0175895691 0.0169805344 0.0163620878] hist_pred: [0.0200875718 0.0203579273 0.0206156597 ... 0.0144609082 0.0140552679 0.0136511493]\n",
      "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8353 KL loss: 0.0286766011 hist_true: [0.00914470479 0.00969917607 0.0102702826 ... 0.0207548253 0.0201785155 0.0195798371] hist_pred: [0.017820647 0.0181436166 0.0184529983 ... 0.0178890713 0.0176306479 0.0173626672]\n",
      "KL loss: 0.00237478549 hist_true: [0.0150974635 0.0156053649 0.0161083974 ... 0.0162178315 0.0157148689 0.0152066201] hist_pred: [0.0183098055 0.0186230578 0.018929543 ... 0.0156634487 0.0152523983 0.0148390383]\n",
      "KL loss: 0.00710591488 hist_true: [0.0174600072 0.0177725088 0.0180766173 ... 0.0175288077 0.0172122084 0.0168885] hist_pred: [0.0225978941 0.0226393938 0.0226702988 ... 0.015310877 0.015040963 0.0147708664]\n",
      "KL loss: 0.013578115 hist_true: [0.00948639121 0.0101466486 0.0108290035 ... 0.0165054183 0.0157352034 0.0149643216] hist_pred: [0.0163604561 0.0166731626 0.0169774238 ... 0.0181046799 0.0176261757 0.0171244238]\n",
      "KL loss: 0.000674179755 hist_true: [0.0175310057 0.0177882 0.018038705 ... 0.0186199453 0.0183879491 0.0181484055] hist_pred: [0.0191642921 0.0192447659 0.0193228889 ... 0.0196177624 0.0195330959 0.019443877]\n",
      "KL loss: 0.00379849039 hist_true: [0.0146158487 0.0150872031 0.0155550512 ... 0.017733328 0.0173004419 0.0168578234] hist_pred: [0.0187830478 0.0189741552 0.019158192 ... 0.0181450248 0.0179351401 0.0177196544]\n",
      "KL loss: 0.00177027239 hist_true: [0.0185561217 0.0189127 0.0192564726 ... 0.0151511263 0.0147254411 0.0142974472] hist_pred: [0.0187053084 0.0189133212 0.0191149209 ... 0.0174469817 0.0171540491 0.0168534]\n",
      "KL loss: 0.00183158787 hist_true: [0.0168378558 0.0172429457 0.0176390428 ... 0.0163878221 0.0159690045 0.0155445645] hist_pred: [0.0195846986 0.0197215825 0.0198519547 ... 0.0178382639 0.0176269319 0.0174102485]\n",
      "KL loss: 0.00182914792 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0165716819 0.017077677 0.0175738409 ... 0.0146334283 0.0141085517 0.0135833919]\n",
      "KL loss: 0.00551276281 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0136369979 0.0141521776 0.0146665145 ... 0.017943738 0.0174859073 0.0170184541]\n",
      "KL loss: 0.00238444726 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0193019621 0.019557666 0.0198017415 ... 0.0161304977 0.0157956947 0.0154572045]\n",
      "KL loss: 0.000250442157 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0191619433 0.0194124468 0.0196515732 ... 0.0165762976 0.0162780639 0.0159768537]\n",
      "KL loss: 0.00796776637 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0178047176 0.0182089899 0.0186013654 ... 0.0151965497 0.0147468382 0.0142947277]\n",
      "KL loss: 0.00299375085 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0211654138 0.0213429611 0.0215069391 ... 0.0149709461 0.0146278599 0.0142837223]\n",
      "KL loss: 0.00180577952 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0211908668 0.0212010816 0.021207327 ... 0.0178456716 0.017708838 0.0175704081]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8724 - val_loss: 0.6578\n",
      "Epoch 21/50\n",
      "KL loss: 0.00345293805 hist_true: [0.0179914627 0.0184395537 0.0188737568 ... 0.0142574664 0.0137712229 0.0132856686] hist_pred: [0.0201087538 0.0202307608 0.0203446839 ... 0.0172590651 0.0170001965 0.0167335104]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1723KL loss: 0.00733987289 hist_true: [0.0119538587 0.0126258889 0.0133073442 ... 0.01518392 0.0144967698 0.0138117811] hist_pred: [0.0162015129 0.0164676011 0.0167297889 ... 0.0187526867 0.018360693 0.0179533269]\n",
      "KL loss: 0.0405674577 hist_true: [0.00915419217 0.00975246355 0.01037018 ... 0.0188432224 0.0181475785 0.017438015] hist_pred: [0.0184825789 0.0189541318 0.0194067657 ... 0.014254244 0.0138321603 0.0134126758]\n",
      "KL loss: 0.0033264386 hist_true: [0.0157044623 0.0162172057 0.0167230275 ... 0.0154333198 0.014914088 0.0143920779] hist_pred: [0.0197685119 0.019963108 0.0201474559 ... 0.0163906273 0.0160715375 0.0157472808]\n",
      "KL loss: 0.00502878893 hist_true: [0.0164194386 0.016925754 0.0174225271 ... 0.0149068637 0.0143973818 0.0138871539] hist_pred: [0.017489247 0.0177454427 0.0179938767 ... 0.018989889 0.018781811 0.0185644161]\n",
      "KL loss: 0.0133792888 hist_true: [0.0155223152 0.0160884503 0.0166474208 ... 0.0146771818 0.0141201019 0.0135632195] hist_pred: [0.0235272814 0.0236230493 0.0236990768 ... 0.0140468497 0.0137700243 0.0134970685]\n",
      "KL loss: 0.00154242979 hist_true: [0.0172378942 0.0175837968 0.017920956 ... 0.0171179809 0.0167630389 0.0164012592] hist_pred: [0.0200577136 0.020183105 0.0203018803 ... 0.0175046735 0.0173146706 0.0171236228]\n",
      "KL loss: 0.00855196267 hist_true: [0.00878443383 0.0093928976 0.0100233639 ... 0.0187130161 0.0179953333 0.0172653981] hist_pred: [0.0134616476 0.0139276963 0.0143941855 ... 0.0195435807 0.0192123186 0.018871326]\n",
      "KL loss: 0.000908000628 hist_true: [0.0185297746 0.0187655147 0.0189928133 ... 0.0175591484 0.0172896925 0.0170142613] hist_pred: [0.019007314 0.0191092696 0.0192085244 ... 0.0193480868 0.0192307476 0.0191079862]\n",
      "KL loss: 0.00277042831 hist_true: [0.0149210459 0.015343694 0.0157623328 ... 0.0185485799 0.0181854926 0.0178112499] hist_pred: [0.0183910672 0.0185987651 0.0187996924 ... 0.018487975 0.0183015764 0.0181112755]\n",
      "KL loss: 0.000835579063 hist_true: [0.0182853099 0.0184925925 0.0186932664 ... 0.0185200591 0.0183136556 0.0181008819] hist_pred: [0.0204583015 0.0204818156 0.0205028821 ... 0.0187108126 0.0186141841 0.0185156222]\n",
      "KL loss: 0.00160246901 hist_true: [0.0171677507 0.0174714196 0.0177677795 ... 0.0181339476 0.0178479329 0.0175539386] hist_pred: [0.0200786795 0.020152282 0.020221021 ... 0.0184420627 0.0183096658 0.0181744881]\n",
      "KL loss: 0.00168448174 hist_true: [0.0173300318 0.0176563207 0.0179742016 ... 0.0174066406 0.017075289 0.0167368073] hist_pred: [0.0178727284 0.0180410575 0.0182056408 ... 0.0198680442 0.0197404139 0.0196050443]\n",
      "KL loss: 0.00325238332 hist_true: [0.0181008782 0.0184976477 0.0188817102 ... 0.0149968266 0.0145478593 0.0140970666] hist_pred: [0.0191685446 0.0193434395 0.0195089672 ... 0.0182833914 0.0181106757 0.017933391]\n",
      "KL loss: 0.000860795146 hist_true: [0.0177041758 0.0180229302 0.018332513 ... 0.0170262121 0.0166837871 0.0163349733] hist_pred: [0.0196487829 0.0197825991 0.0199094377 ... 0.0179434828 0.0177501142 0.017552156]\n",
      "KL loss: 0.00354720838 hist_true: [0.0135917738 0.0140357073 0.0144792479 ... 0.0197402183 0.0193910673 0.0190272555] hist_pred: [0.0165490378 0.0167114194 0.0168715678 ... 0.0225305576 0.0225645863 0.0225891769]\n",
      "KL loss: 0.00691332249 hist_true: [0.0218768492 0.0222800206 0.0226566698 ... 0.010871917 0.010365895 0.00987089705] hist_pred: [0.022108309 0.0222294051 0.0223345645 ... 0.0149976602 0.0146830082 0.0143656945]\n",
      "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9569 KL loss: 0.00602094503 hist_true: [0.0159581713 0.0163447317 0.0167250726 ... 0.0179976374 0.0176471379 0.0172875188] hist_pred: [0.0204617437 0.0206366405 0.0208002254 ... 0.0159422103 0.0156335346 0.0153218992]\n",
      "KL loss: 0.00214895234 hist_true: [0.0186578 0.018863678 0.0190620515 ... 0.0179724302 0.0177393071 0.0175002795] hist_pred: [0.0220432244 0.022002155 0.0219568256 ... 0.017684456 0.0175773259 0.0174704827]\n",
      "KL loss: 0.00637220964 hist_true: [0.0178020652 0.0181179 0.0184242055 ... 0.0170031264 0.0166654699 0.016321687] hist_pred: [0.0232273657 0.0232137926 0.0231891312 ... 0.0158461332 0.0156634692 0.0154833617]\n",
      "KL loss: 0.00239258539 hist_true: [0.0161790885 0.0165266506 0.016868284 ... 0.0185799971 0.018281104 0.0179726258] hist_pred: [0.016993802 0.0171603058 0.0173242707 ... 0.0216449276 0.0216405019 0.0216296352]\n",
      "KL loss: 0.00822421908 hist_true: [0.0131852804 0.0138324192 0.0144832274 ... 0.0147359809 0.0140793379 0.0134252878] hist_pred: [0.0195384528 0.0197462738 0.0199445561 ... 0.0155417295 0.015109716 0.0146729397]\n",
      "KL loss: 0.0241341032 hist_true: [0.0106522543 0.0112448055 0.0118494118 ... 0.0183943138 0.0177835394 0.0171603952] hist_pred: [0.0195924453 0.0198092721 0.0200181436 ... 0.0156725701 0.0152886463 0.01490077]\n",
      "KL loss: 0.00766772404 hist_true: [0.0140915737 0.0146152154 0.0151369534 ... 0.0170602575 0.0165617261 0.0160552934] hist_pred: [0.0198774 0.019994216 0.0200987626 ... 0.0186965764 0.0185571518 0.0184094161]\n",
      "KL loss: 0.0056111319 hist_true: [0.0161041431 0.0164923519 0.0168738011 ... 0.0177639723 0.01740239 0.0170319285] hist_pred: [0.0206549522 0.0208203197 0.0209730938 ... 0.0162388906 0.0159826633 0.015725648]\n",
      "KL loss: 0.00923294201 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0192060582 0.0196397342 0.0200560242 ... 0.0130527709 0.012544442 0.0120400889]\n",
      "KL loss: 0.0171982031 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0159494653 0.016435571 0.0169138573 ... 0.015855588 0.0153787052 0.0148985954]\n",
      "KL loss: 0.00810453389 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0212829523 0.0214711986 0.021645 ... 0.0146068064 0.014242609 0.013877687]\n",
      "KL loss: 0.00417044479 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0216774866 0.0218393318 0.0219861548 ... 0.0147574982 0.0144328838 0.0141091691]\n",
      "KL loss: 0.0179203525 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0200166348 0.0203516558 0.0206699111 ... 0.0137526877 0.0133019565 0.0128525952]\n",
      "KL loss: 0.00952016935 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0233953241 0.0234806091 0.0235502031 ... 0.0134786069 0.0131133636 0.0127498377]\n",
      "KL loss: 0.00317594269 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0219933763 0.0219613593 0.021925671 ... 0.0173664372 0.0172228627 0.0170785654]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9196 - val_loss: 0.6190\n",
      "Epoch 22/50\n",
      "KL loss: 0.00163865276 hist_true: [0.0152428681 0.0157144908 0.0161808077 ... 0.0169352628 0.0164817441 0.0160208028] hist_pred: [0.0178723056 0.0180760622 0.0182784982 ... 0.0182625577 0.0179938395 0.0177180134]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 2.4700KL loss: 0.00122491666 hist_true: [0.0177494958 0.0180851277 0.0184109304 ... 0.0166199226 0.0162525065 0.0158793516] hist_pred: [0.0203473065 0.0204834044 0.0206115898 ... 0.016617693 0.0163497906 0.0160787832]\n",
      "KL loss: 0.0205557719 hist_true: [0.00962994248 0.0102456165 0.0108792149 ... 0.0181869771 0.0174999647 0.0168023538] hist_pred: [0.018030677 0.0182774 0.0185158383 ... 0.0181138348 0.0178649202 0.0176080409]\n",
      "KL loss: 0.001233991 hist_true: [0.0198140927 0.0201014839 0.0203743409 ... 0.0148856035 0.0144922687 0.0140975518] hist_pred: [0.0225894041 0.0225688331 0.0225438066 ... 0.0157197807 0.0154451402 0.0151676442]\n",
      "KL loss: 0.00459041446 hist_true: [0.0201550052 0.0206587408 0.021138981 ... 0.0112139573 0.0106784729 0.0101540694] hist_pred: [0.0240879431 0.024150461 0.0241903886 ... 0.0137980217 0.0134732286 0.0131472824]\n",
      "KL loss: 0.0151104126 hist_true: [0.0153473513 0.0157619137 0.0161714908 ... 0.0181529336 0.0177829489 0.0174029116] hist_pred: [0.0234505292 0.0233984292 0.0233363211 ... 0.0158702806 0.0156533793 0.0154338088]\n",
      "KL loss: 0.000324082794 hist_true: [0.018337803 0.0186042972 0.01886167 ... 0.0172090437 0.0169059671 0.0165968928] hist_pred: [0.0193488169 0.0194815751 0.0196098387 ... 0.0180194322 0.0178031251 0.0175806377]\n",
      "KL loss: 0.0168157034 hist_true: [0.0187103506 0.0189726613 0.019224951 ... 0.0167688653 0.0164506976 0.0161273386] hist_pred: [0.0262217876 0.0261036381 0.025973713 ... 0.0127125261 0.0123821832 0.0120554706]\n",
      "KL loss: 0.0118418233 hist_true: [0.0121064819 0.0126298321 0.0131577598 ... 0.0192503724 0.0187792741 0.0182928108] hist_pred: [0.0192183685 0.0192677118 0.0193132702 ... 0.0204824489 0.0204385333 0.0203836858]\n",
      "KL loss: 0.00359070464 hist_true: [0.0124454787 0.0129515305 0.013460665 ... 0.019473793 0.0190429427 0.0185968243] hist_pred: [0.0157764498 0.0161566921 0.0165298525 ... 0.0190315694 0.0187836792 0.0185284223]\n",
      "KL loss: 0.00197443715 hist_true: [0.0205796268 0.0208925288 0.0211872477 ... 0.0135590974 0.0131222848 0.0126875769] hist_pred: [0.0235074162 0.0235230494 0.02352475 ... 0.0150881633 0.0148690455 0.0146531872]\n",
      "KL loss: 0.00252450071 hist_true: [0.0149307381 0.0154210711 0.0159066431 ... 0.016929578 0.0164615326 0.0159858409] hist_pred: [0.0182319209 0.0185167361 0.0187918637 ... 0.0172890127 0.0170150027 0.0167376213]\n",
      "KL loss: 0.00286231283 hist_true: [0.0163279 0.0168062318 0.0172758512 ... 0.0154951047 0.015006613 0.0145151] hist_pred: [0.0173751134 0.0176161211 0.0178535841 ... 0.0184853505 0.0182084 0.0179224014]\n",
      "KL loss: 0.00631222641 hist_true: [0.0111815687 0.0116673773 0.0121598048 ... 0.0216044541 0.0212486777 0.0208716113] hist_pred: [0.0155785652 0.0158770829 0.0161735099 ... 0.0203627348 0.0201657191 0.0199577212]\n",
      "KL loss: 0.00733532198 hist_true: [0.0105901398 0.0112992395 0.0120269721 ... 0.0146864 0.0139118824 0.0131452503] hist_pred: [0.0134005211 0.0138713652 0.0143444408 ... 0.0191526897 0.0187890623 0.0184164215]\n",
      "KL loss: 0.00657298835 hist_true: [0.0155431228 0.015983684 0.0164183043 ... 0.0172958449 0.0168784223 0.0164527725] hist_pred: [0.0205824804 0.0207702778 0.0209448375 ... 0.016045928 0.0157928541 0.01554171]\n",
      "KL loss: 0.0017894468 hist_true: [0.0171684865 0.0174485669 0.0177221037 ... 0.0186648779 0.0184197612 0.0181665439] hist_pred: [0.0198957343 0.0200111978 0.0201207176 ... 0.0177509971 0.0175481979 0.0173410773]\n",
      "KL loss: 0.00390839856 hist_true: [0.0164750759 0.0168045908 0.0171278939 ... 0.0185517147 0.0182638597 0.0179667454] hist_pred: [0.0151611827 0.0154397544 0.0157159027 ... 0.0221633501 0.022125572 0.0220793243]\n",
      "KL loss: 0.00742120156 hist_true: [0.0128239524 0.0133475307 0.0138733732 ... 0.0184624568 0.017982915 0.017490834] hist_pred: [0.0180337373 0.0182978883 0.0185562577 ... 0.0172575191 0.0169422422 0.0166217145]\n",
      "KL loss: 0.0021085497 hist_true: [0.0173176806 0.0176543985 0.0179824382 ... 0.0172054339 0.0168601703 0.0165080838] hist_pred: [0.0205709971 0.0206068363 0.0206385162 ... 0.0183305331 0.0181999523 0.018065881]\n",
      "KL loss: 0.0281140413 hist_true: [0.00949038472 0.0100638932 0.0106534865 ... 0.0198946334 0.0192963798 0.0186797641] hist_pred: [0.0169529542 0.0174030717 0.0178448614 ... 0.0152185326 0.0147652561 0.0143135255]\n",
      "KL loss: 0.00238681072 hist_true: [0.0176745113 0.0179774761 0.0182716902 ... 0.0174440388 0.017131146 0.0168114472] hist_pred: [0.0211121459 0.0211821869 0.0212448109 ... 0.0169455614 0.0167418439 0.0165365208]\n",
      "KL loss: 0.00118314475 hist_true: [0.0182850901 0.0186931174 0.0190872382 ... 0.0146359615 0.0141766807 0.0137166018] hist_pred: [0.0199532174 0.0201738235 0.0203808546 ... 0.0162203182 0.0159240067 0.0156242047]\n",
      "KL loss: 0.0029238821 hist_true: [0.0177157912 0.018090751 0.0184548926 ... 0.0158695746 0.015454513 0.0150352968] hist_pred: [0.0213970505 0.0215465724 0.0216835774 ... 0.0151444357 0.0148294512 0.014514802]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8141  KL loss: 0.0248635802 hist_true: [0.0151744587 0.0157313421 0.0162830558 ... 0.015046753 0.0144886104 0.0139295673] hist_pred: [0.0262546018 0.0261489879 0.0260247346 ... 0.0135546913 0.0133043723 0.0130559588]\n",
      "KL loss: 0.0117294667 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.019195389 0.0196708292 0.020128252 ... 0.0123002436 0.0117601585 0.0112271393]\n",
      "KL loss: 0.0164969396 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0156529974 0.0161555968 0.0166513026 ... 0.0158081017 0.0153154181 0.0148196919]\n",
      "KL loss: 0.00792774744 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0211777184 0.0213748142 0.0215573125 ... 0.014616156 0.0142504564 0.0138841113]\n",
      "KL loss: 0.00247189822 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0208607223 0.0210569948 0.0212392695 ... 0.0152216684 0.0148958 0.0145695517]\n",
      "KL loss: 0.0187917631 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0199463069 0.0203003921 0.0206373036 ... 0.0135147898 0.0130506838 0.012588759]\n",
      "KL loss: 0.0104484651 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0235397015 0.0236281753 0.0237001926 ... 0.0132786594 0.0129089411 0.0125415679]\n",
      "KL loss: 0.00404922059 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.022289183 0.0222502686 0.0222072862 ... 0.0170211717 0.0168609917 0.0167001914]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8179 - val_loss: 0.6332\n",
      "Epoch 23/50\n",
      "KL loss: 0.0067778 hist_true: [0.0160938986 0.016683504 0.0172643494 ... 0.0135682393 0.0129885301 0.0124137634] hist_pred: [0.0216883812 0.0218998548 0.0220890027 ... 0.0149980132 0.0147083439 0.0144171473]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 1.4056KL loss: 0.000930730952 hist_true: [0.0187791567 0.0190234091 0.0192581508 ... 0.0170338359 0.0167370699 0.0164349414] hist_pred: [0.0188994426 0.0190318711 0.0191609226 ... 0.0188041031 0.0186375473 0.01846526]\n",
      "KL loss: 0.00297397515 hist_true: [0.0184090901 0.0187263023 0.0190323722 ... 0.0160978083 0.0157229714 0.0153436521] hist_pred: [0.0223714057 0.0224115811 0.0224424377 ... 0.0155435344 0.0152749009 0.0150049124]\n",
      "KL loss: 0.00461958721 hist_true: [0.0128448606 0.0133128436 0.013782423 ... 0.0200831909 0.0197183676 0.0193374604] hist_pred: [0.0170072373 0.0172538701 0.017496597 ... 0.0192673448 0.0190408435 0.0188041404]\n",
      "KL loss: 0.000347825466 hist_true: [0.01889004 0.0191218797 0.0193444248 ... 0.0171139278 0.016826978 0.016534688] hist_pred: [0.0200590882 0.0201603789 0.020255791 ... 0.0178448074 0.0176592842 0.0174699612]\n",
      "KL loss: 0.00534814503 hist_true: [0.0111579644 0.0117892744 0.0124324923 ... 0.0166480206 0.0159729254 0.0152933057] hist_pred: [0.0153646702 0.0157280304 0.016089702 ... 0.0185018405 0.0181202311 0.0177263711]\n",
      "KL loss: 0.00886036828 hist_true: [0.0206236877 0.0210162848 0.0213877 ... 0.0122261569 0.0117302239 0.0112407766] hist_pred: [0.0284339655 0.0281704068 0.0278924741 ... 0.0125717102 0.0123096127 0.0120516401]\n",
      "KL loss: 0.00291868253 hist_true: [0.0173275862 0.0176621433 0.0179880764 ... 0.0172282886 0.0168843418 0.0165334791] hist_pred: [0.0211426485 0.0212177448 0.0212856252 ... 0.0165779982 0.0163314417 0.0160815865]\n",
      "KL loss: 0.00413055066 hist_true: [0.0179263055 0.0182491355 0.0185619816 ... 0.0166584831 0.016301902 0.0159397274] hist_pred: [0.0226765182 0.0226405915 0.0225969553 ... 0.0169400349 0.0168163013 0.0166951157]\n",
      "KL loss: 0.00783736631 hist_true: [0.00986819249 0.010532652 0.0112166218 ... 0.0164088383 0.0156550817 0.0149000874] hist_pred: [0.0145479832 0.0150638763 0.0155749368 ... 0.0173946675 0.016943913 0.0164820198]\n",
      "KL loss: 0.00134011917 hist_true: [0.0172106884 0.0175636709 0.0179077908 ... 0.0170113314 0.0166483093 0.0162786338] hist_pred: [0.0198640339 0.0200218093 0.0201716218 ... 0.0170015879 0.0167439729 0.0164824687]\n",
      "KL loss: 0.011974901 hist_true: [0.0133805862 0.0139581831 0.0145370811 ... 0.0163798239 0.0158087816 0.0152325658] hist_pred: [0.0206189789 0.0207702816 0.0209065564 ... 0.0170905609 0.0168908257 0.0166868269]\n",
      "KL loss: 0.000950607937 hist_true: [0.0173571054 0.01766406 0.0179629903 ... 0.0178195052 0.0175202247 0.0172135178] hist_pred: [0.0178902801 0.0180744343 0.018253874 ... 0.0196917243 0.0195663217 0.0194349326]\n",
      "\u001b[1m13/25\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7676  KL loss: 0.0027666064 hist_true: [0.0171963945 0.0176427867 0.0180780627 ... 0.0151543152 0.0146814026 0.0142063061] hist_pred: [0.0201050565 0.0201848932 0.0202617329 ... 0.0174361244 0.0171769485 0.0169100575]\n",
      "KL loss: 0.00623985566 hist_true: [0.0110901427 0.0117249489 0.0123723727 ... 0.0164131746 0.0157152079 0.0150138047] hist_pred: [0.0154986363 0.015931638 0.0163617227 ... 0.0175937749 0.0172638055 0.0169332]\n",
      "KL loss: 0.00505231693 hist_true: [0.0178643279 0.0181931593 0.0185119901 ... 0.0166230854 0.016261654 0.0158946589] hist_pred: [0.0171633475 0.0173485074 0.0175310429 ... 0.0207867138 0.0207202025 0.0206475873]\n",
      "KL loss: 0.00364773301 hist_true: [0.00883754529 0.00941613782 0.0100144576 ... 0.0198563393 0.0192017667 0.0185289327] hist_pred: [0.0117984014 0.0122771794 0.0127612809 ... 0.0208357 0.0204636101 0.0200743619]\n",
      "KL loss: 0.000422165962 hist_true: [0.0188913196 0.0190634597 0.0192290097 ... 0.0183046833 0.0181076396 0.0179051571] hist_pred: [0.0198967271 0.0199338626 0.0199691653 ... 0.019356709 0.0192891192 0.0192191377]\n",
      "KL loss: 0.00590025 hist_true: [0.0161952917 0.0166184101 0.0170338061 ... 0.0169033092 0.016492432 0.0160746556] hist_pred: [0.021150846 0.0213107467 0.0214557573 ... 0.0160587188 0.0158343576 0.015611832]\n",
      "KL loss: 0.00547671318 hist_true: [0.0155346664 0.0159706268 0.016400842 ... 0.0173749253 0.0169606023 0.0165377725] hist_pred: [0.0208359938 0.0208955202 0.0209483188 ... 0.0174123 0.0172089599 0.0170007907]\n",
      "KL loss: 0.0017261398 hist_true: [0.0148869734 0.0153626567 0.0158341154 ... 0.0172590651 0.0168080945 0.0163486693] hist_pred: [0.0176908392 0.0179447047 0.0181920249 ... 0.0180775337 0.0177819319 0.0174763165]\n",
      "KL loss: 0.00131608965 hist_true: [0.0167574491 0.0171380658 0.0175104346 ... 0.017020192 0.0166380517 0.0162489098] hist_pred: [0.0192256104 0.0193762779 0.0195212327 ... 0.01802825 0.0178172495 0.0176008698]\n",
      "KL loss: 0.00102342642 hist_true: [0.019045772 0.0195056852 0.0199479666 ... 0.0128624626 0.0123478984 0.0118385395] hist_pred: [0.020769041 0.0209747814 0.021171283 ... 0.0142053077 0.0137864267 0.0133683728]\n",
      "KL loss: 0.000569909695 hist_true: [0.0183596388 0.0186141673 0.0188599583 ... 0.0174287334 0.0171427485 0.0168506801] hist_pred: [0.0201353338 0.0202395152 0.0203374475 ... 0.0176957436 0.0175047144 0.0173103418]\n",
      "KL loss: 0.0066310484 hist_true: [0.0172096435 0.0176079627 0.0179961734 ... 0.0160943791 0.0156744793 0.0152498018] hist_pred: [0.0231993049 0.0231729653 0.0231361222 ... 0.0159870647 0.0157902204 0.0155925248]\n",
      "KL loss: 0.0128747765 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0195074752 0.0199728552 0.0204191115 ... 0.0122009302 0.011668982 0.0111443065]\n",
      "KL loss: 0.0171939284 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0156795438 0.0161889456 0.0166912321 ... 0.0156661943 0.0151692778 0.0146699222]\n",
      "KL loss: 0.00914245658 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0214228556 0.0216171257 0.021796193 ... 0.0143350875 0.0139603755 0.0135855693]\n",
      "KL loss: 0.00411438802 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0215226039 0.0217015967 0.0218652394 ... 0.0146614183 0.0143243279 0.013988019]\n",
      "KL loss: 0.0215717107 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0203078724 0.0206592418 0.0209923424 ... 0.0131287668 0.0126566151 0.0121876765]\n",
      "KL loss: 0.0111804232 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.023605451 0.0236998126 0.0237772055 ... 0.0130859353 0.0127057694 0.0123281842]\n",
      "KL loss: 0.00434699096 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.022425212 0.0223791972 0.0223291386 ... 0.016945811 0.0167852454 0.016624229]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8020 - val_loss: 0.5593\n",
      "Epoch 24/50\n",
      "KL loss: 0.00158537738 hist_true: [0.0178014729 0.0181179568 0.0184249822 ... 0.0169646163 0.0166234951 0.0162762422] hist_pred: [0.020752592 0.0208245963 0.0208893176 ... 0.0174466893 0.0172513388 0.0170515738]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3248KL loss: 0.0152415549 hist_true: [0.0183398314 0.0187603924 0.0191667415 ... 0.0143150846 0.0138419867 0.0133692771] hist_pred: [0.0270279888 0.0269041024 0.0267636068 ... 0.0122957369 0.0119963046 0.0117038749]\n",
      "KL loss: 0.00564340176 hist_true: [0.0176349543 0.0179991703 0.0183528829 ... 0.0162431821 0.0158494897 0.0154508511] hist_pred: [0.0229502022 0.0229663569 0.0229716208 ... 0.0152928904 0.0150328 0.0147726685]\n",
      "KL loss: 0.000393795664 hist_true: [0.0184438769 0.0187251102 0.0189962573 ... 0.0167944562 0.0164683815 0.0161369275] hist_pred: [0.0198672079 0.0200176258 0.0201598275 ... 0.0172495022 0.0170111768 0.0167685151]\n",
      "KL loss: 0.00236637052 hist_true: [0.0183754712 0.0186528824 0.0189206675 ... 0.0169393662 0.0166194178 0.0162938293] hist_pred: [0.0216203742 0.021696927 0.0217645634 ... 0.0159861501 0.0157257151 0.0154638253]\n",
      "KL loss: 0.00408405811 hist_true: [0.0174147449 0.0178362709 0.0182465799 ... 0.0153795164 0.0149282059 0.0144742075] hist_pred: [0.0211413689 0.0211685449 0.0211876146 ... 0.0179764405 0.0178278573 0.0176731888]\n",
      "KL loss: 0.0014837468 hist_true: [0.0196011197 0.0198287722 0.0200453158 ... 0.0161755495 0.0158512276 0.0155230304] hist_pred: [0.0198502243 0.0199371893 0.0200195517 ... 0.0184108 0.0182567649 0.0180982985]\n",
      "KL loss: 0.0198564865 hist_true: [0.0129678408 0.0134409918 0.0139154335 ... 0.0197740216 0.0193937533 0.018998079] hist_pred: [0.0206024777 0.0207761731 0.0209379271 ... 0.0158961229 0.0156000853 0.015302429]\n",
      "KL loss: 0.00799202174 hist_true: [0.00960356742 0.0103260344 0.011074448 ... 0.0144010754 0.0135701206 0.0127520021] hist_pred: [0.0134466104 0.0139505211 0.0144588081 ... 0.0180762112 0.0176666491 0.0172514021]\n",
      "KL loss: 0.000657952391 hist_true: [0.0171026289 0.0174081288 0.0177064724 ... 0.0181826036 0.0178969298 0.0176031552] hist_pred: [0.0183697864 0.0185284019 0.018682437 ... 0.0194486436 0.0193279944 0.0192027744]\n",
      "KL loss: 0.00543120317 hist_true: [0.0143666938 0.014813236 0.0152569357 ... 0.0187549349 0.0183820762 0.0179974679] hist_pred: [0.0187703315 0.0190040134 0.0192286298 ... 0.0173416249 0.017072659 0.0167985819]\n",
      "KL loss: 0.00534960767 hist_true: [0.0182800777 0.0187527686 0.0192105491 ... 0.0133751659 0.0128540341 0.0123365829] hist_pred: [0.0239192322 0.0238520224 0.0237767641 ... 0.014873513 0.0145960748 0.0143185798]\n",
      "KL loss: 0.00175417168 hist_true: [0.016165711 0.0165195614 0.0168674197 ... 0.0184316095 0.0181198828 0.0177985672] hist_pred: [0.0184617694 0.018563861 0.0186639056 ... 0.0203093421 0.0202425141 0.0201689564]\n",
      "KL loss: 0.00736007188 hist_true: [0.0105360346 0.0111214975 0.0117188049 ... 0.0188758057 0.0182906538 0.0176912267] hist_pred: [0.0152655281 0.0156662147 0.0160611663 ... 0.0193501916 0.0191031639 0.0188473091]\n",
      "KL loss: 0.000739094685 hist_true: [0.0171140879 0.0173834804 0.0176468305 ... 0.0189813431 0.0187581778 0.0185267739] hist_pred: [0.0190439653 0.0191548429 0.0192616917 ... 0.0193672497 0.0192685649 0.0191662628]\n",
      "KL loss: 0.00354461465 hist_true: [0.0118202856 0.0124172848 0.0130217774 ... 0.0173158459 0.0167144407 0.0161047913] hist_pred: [0.0150549123 0.0154598346 0.0158601 ... 0.0190737974 0.0187885463 0.0184962098]\n",
      "KL loss: 0.00172166293 hist_true: [0.0118463114 0.0123590175 0.0128767677 ... 0.0199536961 0.0195188839 0.0190669317] hist_pred: [0.0131556662 0.0135137178 0.0138734244 ... 0.0223555919 0.0221626218 0.0219504628]\n",
      "KL loss: 0.0587832481 hist_true: [0.00901661348 0.00957297627 0.0101464521 ... 0.0208668429 0.0202926788 0.0196958408] hist_pred: [0.021168869 0.0214276463 0.0216656 ... 0.0157481488 0.0156112127 0.0154836215]\n",
      "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7238 KL loss: 0.00331792608 hist_true: [0.0186867584 0.0192016624 0.0196996499 ... 0.0121797388 0.0116242496 0.011077147] hist_pred: [0.020511359 0.0207337942 0.0209436882 ... 0.0150723467 0.0147322621 0.0143933482]\n",
      "KL loss: 0.00616820343 hist_true: [0.0152871599 0.0157286543 0.0161651727 ... 0.0175303109 0.017113464 0.0166876093] hist_pred: [0.0207388513 0.020818878 0.0208896 ... 0.0176786743 0.0175159685 0.0173503701]\n",
      "KL loss: 0.0180630032 hist_true: [0.0196772031 0.0202202089 0.0207408536 ... 0.0110847428 0.0105355727 0.00999873783] hist_pred: [0.016741341 0.0171578 0.0175612345 ... 0.0175799113 0.0172908884 0.0169971194]\n",
      "KL loss: 0.0025601564 hist_true: [0.0165653527 0.0170965772 0.0176173728 ... 0.0142911198 0.0137591986 0.0132287201] hist_pred: [0.0182067193 0.0184759293 0.018736979 ... 0.0168729462 0.0165169928 0.0161540601]\n",
      "KL loss: 0.00251868134 hist_true: [0.0155890435 0.0160456952 0.0164958593 ... 0.0169282928 0.0164920371 0.0160485134] hist_pred: [0.0189791247 0.0192233752 0.0194573365 ... 0.0169217 0.0166435298 0.0163625851]\n",
      "KL loss: 0.0168332495 hist_true: [0.00878946763 0.0093085384 0.00984367169 ... 0.0225987919 0.0221300237 0.0216328] hist_pred: [0.0143207125 0.0147719458 0.0152194807 ... 0.0191041902 0.0187771972 0.0184396394]\n",
      "KL loss: 0.00566871185 hist_true: [0.0163477678 0.0167390052 0.0171229374 ... 0.0173236765 0.0169427656 0.0165539626] hist_pred: [0.0215632915 0.0216165 0.021662211 ... 0.0162766539 0.016013328 0.0157460719]\n",
      "KL loss: 0.0162333939 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0200707056 0.0205291212 0.0209666025 ... 0.0117263356 0.0111931982 0.0106688393]\n",
      "KL loss: 0.0176058579 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0157283451 0.0162392966 0.0167428907 ... 0.0156138102 0.0151181528 0.0146202501]\n",
      "KL loss: 0.0118547846 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0220259279 0.0222022161 0.0223622955 ... 0.0138364276 0.0134512857 0.0130670695]\n",
      "KL loss: 0.0054501188 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0219819676 0.0221461393 0.0222942494 ... 0.0142881032 0.0139418878 0.013597046]\n",
      "KL loss: 0.0244545545 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.020608712 0.0209622886 0.0212965701 ... 0.0127340183 0.0122524146 0.0117751956]\n",
      "KL loss: 0.0118981544 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0237556566 0.0238450281 0.0239172578 ... 0.0129546048 0.012570451 0.0121890651]\n",
      "KL loss: 0.00376521563 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0222180653 0.0221783165 0.0221347678 ... 0.0171375871 0.0169828534 0.0168273319]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7819 - val_loss: 0.5155\n",
      "Epoch 25/50\n",
      "KL loss: 0.00498096645 hist_true: [0.0162543375 0.0166457035 0.0170299113 ... 0.0174861625 0.0171136819 0.0167330727] hist_pred: [0.0211014412 0.0211705361 0.021234639 ... 0.01614758 0.015835695 0.0155180153]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 1.7450KL loss: 0.00301239057 hist_true: [0.0192013346 0.0195069276 0.0197994206 ... 0.0152811576 0.0148865227 0.0144893611] hist_pred: [0.0233823583 0.0233731698 0.0233535822 ... 0.0150850005 0.0148247508 0.0145646706]\n",
      "KL loss: 0.00698436704 hist_true: [0.0166953765 0.0171404816 0.0175759457 ... 0.0158178527 0.0153635666 0.0149052506] hist_pred: [0.0224669017 0.0225533079 0.0226268023 ... 0.0145414406 0.0141983693 0.0138542112]\n",
      "KL loss: 0.00357874716 hist_true: [0.0191782471 0.0194961298 0.019800568 ... 0.0150782131 0.0146704772 0.0142606441] hist_pred: [0.0191517193 0.0192620326 0.0193706788 ... 0.018326778 0.0181019548 0.0178686958]\n",
      "KL loss: 0.00284879585 hist_true: [0.0132110473 0.0137653537 0.0143210432 ... 0.0171864647 0.0166492425 0.0161035713] hist_pred: [0.0165914577 0.0169613641 0.0173243713 ... 0.0171910468 0.0167970471 0.0163943954]\n",
      "KL loss: 0.01920899 hist_true: [0.0135039454 0.013959649 0.0144152623 ... 0.0195091926 0.0191374831 0.0187513381] hist_pred: [0.0219850149 0.022016516 0.022037778 ... 0.0167033784 0.0165156964 0.0163266]\n",
      "KL loss: 0.0045987349 hist_true: [0.0188467372 0.019086834 0.0193173327 ... 0.0170392934 0.0167467687 0.0164490379] hist_pred: [0.0234486293 0.0233960226 0.0233361349 ... 0.0156469978 0.0154308174 0.0152152823]\n",
      "KL loss: 0.0157732442 hist_true: [0.0142993191 0.0147448182 0.0151878428 ... 0.0188073535 0.0184318721 0.0180442911] hist_pred: [0.0212525446 0.0214120839 0.021557942 ... 0.0153671382 0.0150645468 0.0147615448]\n",
      "KL loss: 0.00515829306 hist_true: [0.0170538854 0.0175613631 0.0180574656 ... 0.0140834739 0.0135528073 0.0130238906] hist_pred: [0.0175890904 0.0178057477 0.018022079 ... 0.0178708285 0.0175240729 0.0171664804]\n",
      "KL loss: 0.00317041716 hist_true: [0.0182062 0.0185870826 0.0189553462 ... 0.0151767461 0.0147418994 0.0143047627] hist_pred: [0.0226959419 0.0226913113 0.0226797163 ... 0.0154039692 0.0151035013 0.0147990473]\n",
      "KL loss: 0.00462296512 hist_true: [0.0198115762 0.0202436838 0.0206561759 ... 0.0124976076 0.0119905705 0.0114895729] hist_pred: [0.0201936569 0.0203986224 0.0205904637 ... 0.0160990469 0.0157990381 0.0154952304]\n",
      "KL loss: 0.00169821782 hist_true: [0.020292297 0.0206328556 0.0209554 ... 0.0133810611 0.0129238348 0.0124692358] hist_pred: [0.0219594873 0.0220452622 0.022120012 ... 0.0154079 0.0151214367 0.0148344366]\n",
      "KL loss: 0.00616478641 hist_true: [0.0168073 0.0171493236 0.0174837969 ... 0.0178239513 0.0174992904 0.0171664581] hist_pred: [0.0217233635 0.0217975583 0.0218620747 ... 0.0161048491 0.0158735551 0.0156426281]\n",
      "KL loss: 0.00764829293 hist_true: [0.0114679532 0.0119588049 0.0124554131 ... 0.0210818928 0.0207018815 0.0203015041] hist_pred: [0.0103433887 0.0107027348 0.0110716522 ... 0.0263971686 0.0263741855 0.0263250768]\n",
      "KL loss: 0.0103063937 hist_true: [0.018565828 0.0189257246 0.0192725956 ... 0.0151043702 0.0146779595 0.0142494729] hist_pred: [0.017104689 0.0172926802 0.0174782258 ... 0.0207990389 0.0207290575 0.0206524562]\n",
      "KL loss: 0.00162496057 hist_true: [0.0174469966 0.0177721083 0.0180885922 ... 0.0172487181 0.0169106536 0.0165657047] hist_pred: [0.0204376522 0.0205332134 0.0206224322 ... 0.0172157735 0.0169845577 0.0167485382]\n",
      "KL loss: 0.0152507098 hist_true: [0.0199859831 0.0204475019 0.0208879039 ... 0.0118884007 0.011366236 0.0108525418] hist_pred: [0.0164691079 0.016844919 0.0172148794 ... 0.0173180159 0.0169450473 0.0165650174]\n",
      "KL loss: 0.00477686711 hist_true: [0.0099226 0.0104837595 0.0110584283 ... 0.0200707559 0.0195118897 0.018933801] hist_pred: [0.0134474272 0.0139016323 0.0143565498 ... 0.019756278 0.0194300339 0.0190925747]\n",
      "KL loss: 0.0156208519 hist_true: [0.0131689869 0.0136255762 0.0140827447 ... 0.0200168062 0.0196671896 0.0193021391] hist_pred: [0.0198182 0.0200264286 0.0202232152 ... 0.0165707543 0.0163064916 0.0160404518]\n",
      "KL loss: 0.00451010652 hist_true: [0.0129314363 0.0134339398 0.0139380386 ... 0.0189699344 0.0185308829 0.0180780571] hist_pred: [0.0171953887 0.0174427554 0.0176840592 ... 0.0194193684 0.0192299839 0.0190315638]\n",
      "KL loss: 0.00533121871 hist_true: [0.00968931802 0.0103038931 0.0109357731 ... 0.0184128191 0.0177549329 0.0170859732] hist_pred: [0.0137932952 0.0142332697 0.0146759059 ... 0.0183810275 0.0179156158 0.0174383335]\n",
      "KL loss: 0.00173025648 hist_true: [0.016785875 0.0171212144 0.0174492951 ... 0.0179946 0.0176812522 0.0173595771] hist_pred: [0.0196515452 0.0197967608 0.0199347399 ... 0.017775178 0.0175796337 0.017380856]\n",
      "KL loss: 0.00451665092 hist_true: [0.0178272482 0.0184901841 0.019137267 ... 0.0108188204 0.0102174282 0.00963238254] hist_pred: [0.0226987917 0.0230626278 0.0233989507 ... 0.0108720455 0.0104196146 0.0099792527]\n",
      "KL loss: 0.00101369852 hist_true: [0.0173283517 0.0176458228 0.0179551225 ... 0.0176086724 0.0172921 0.0169682112] hist_pred: [0.0190592557 0.0191869698 0.019309381 ... 0.0190446209 0.0189178158 0.0187865682]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6291  KL loss: 0.0188528448 hist_true: [0.00870424 0.00930937566 0.00993662421 ... 0.0188630223 0.0181462299 0.0174163785] hist_pred: [0.0156330597 0.0160521902 0.0164694916 ... 0.0178093277 0.0175100043 0.0172086358]\n",
      "KL loss: 0.000133405905 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0154217295 0.0159313418 0.0164346527 ... 0.0159251969 0.0154243791 0.0149192885]\n",
      "KL loss: 0.00158468098 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0124749485 0.01298761 0.0135029238 ... 0.0194092821 0.0189858284 0.0185483508]\n",
      "KL loss: 0.000107339467 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.017565826 0.0178688224 0.0181633625 ... 0.0176111087 0.0173066389 0.0169952363]\n",
      "KL loss: 4.66252386e-05 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0185518581 0.0188300833 0.0190977845 ... 0.0168349743 0.0165278465 0.0162168071]\n",
      "KL loss: 0.00264446856 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0162728336 0.0167019684 0.017123064 ... 0.0166935548 0.0162762161 0.0158528723]\n",
      "KL loss: 0.00152617984 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0203568283 0.0205650423 0.0207607821 ... 0.0154946 0.015153856 0.0148106525]\n",
      "KL loss: 0.000247460208 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0199253913 0.0199830048 0.0200372115 ... 0.0190032907 0.0189123843 0.0188192204]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6307 - val_loss: 0.4440\n",
      "Epoch 26/50\n",
      "KL loss: 0.00626737904 hist_true: [0.00929773692 0.00986840297 0.010455925 ... 0.0200076681 0.0193947293 0.0187624115] hist_pred: [0.0119979363 0.012336175 0.0126802595 ... 0.0244683195 0.0243864693 0.0242836196]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4520KL loss: 0.00362874847 hist_true: [0.0102633443 0.0108980071 0.0115490519 ... 0.0169934668 0.0162816197 0.0155646801] hist_pred: [0.0127439043 0.0132207284 0.0136967571 ... 0.0196558051 0.0191935096 0.0187115949]\n",
      "KL loss: 0.00150198815 hist_true: [0.0176189877 0.0179725531 0.0183160678 ... 0.0164486784 0.0160659142 0.0156777091] hist_pred: [0.0181612968 0.0183751658 0.0185827557 ... 0.0187985804 0.0186388493 0.0184764937]\n",
      "KL loss: 0.00536073186 hist_true: [0.0149902599 0.0156055782 0.0162166748 ... 0.0139823621 0.013373482 0.0127687212] hist_pred: [0.0176822152 0.0179545209 0.0182189979 ... 0.0176437218 0.0173045043 0.0169546437]\n",
      "KL loss: 0.00091734156 hist_true: [0.0187921356 0.0190898124 0.0193759296 ... 0.0159654878 0.0155973248 0.0152251674] hist_pred: [0.0207760707 0.0208623856 0.020941535 ... 0.0170397833 0.0168194417 0.0165957455]\n",
      "KL loss: 0.00229337066 hist_true: [0.0175288506 0.0178184658 0.0181002636 ... 0.0179182161 0.0176328104 0.0173400752] hist_pred: [0.0208226759 0.0209004749 0.0209703092 ... 0.0174238663 0.0172490291 0.0170722529]\n",
      "KL loss: 0.00153540226 hist_true: [0.0184710566 0.0187688656 0.0190560017 ... 0.0164026525 0.0160502438 0.0156929214] hist_pred: [0.0212600641 0.0213681124 0.0214663614 ... 0.0159321502 0.0156488102 0.015362788]\n",
      "KL loss: 0.00110495649 hist_true: [0.0198840164 0.0203648172 0.0208243653 ... 0.0116937598 0.011162214 0.0106400596] hist_pred: [0.0215481743 0.0217830185 0.0220042616 ... 0.013104937 0.0126678152 0.012234062]\n",
      "KL loss: 0.00250169169 hist_true: [0.0171242449 0.0176524613 0.0181686152 ... 0.0136788888 0.0131364819 0.0125974845] hist_pred: [0.0210372414 0.0212406125 0.0214345623 ... 0.0138390651 0.0134035628 0.0129688531]\n",
      "KL loss: 0.00105170067 hist_true: [0.0182761531 0.0185960084 0.0189048704 ... 0.0162743405 0.0159083027 0.0155376215] hist_pred: [0.0192515422 0.0194227155 0.0195854716 ... 0.0181174558 0.0179408416 0.0177611243]\n",
      "KL loss: 0.00368315401 hist_true: [0.0133225173 0.0137903886 0.0142585766 ... 0.019442929 0.0190578662 0.0186583567] hist_pred: [0.0171250235 0.0173748694 0.0176195074 ... 0.0195680652 0.0194113422 0.0192487258]\n",
      "KL loss: 0.00122564635 hist_true: [0.0189072043 0.0192091484 0.0194987729 ... 0.0157961734 0.0154246222 0.0150495628] hist_pred: [0.0215748046 0.0216151681 0.0216497742 ... 0.0165180564 0.0162887648 0.0160574075]\n",
      "KL loss: 0.00231882744 hist_true: [0.0196972173 0.0199377611 0.0201663561 ... 0.0158056989 0.0154608823 0.0151127772] hist_pred: [0.020444138 0.0204840526 0.0205193479 ... 0.0186238699 0.0185193848 0.0184120163]\n",
      "KL loss: 0.000845480477 hist_true: [0.0168097131 0.0171408728 0.0174649097 ... 0.0180277731 0.0177169144 0.0173976552] hist_pred: [0.0187880695 0.0189409126 0.0190888178 ... 0.0187829845 0.0186192468 0.0184503719]\n",
      "KL loss: 0.0016817851 hist_true: [0.0180140957 0.0183880888 0.0187503267 ... 0.0155204 0.0150964735 0.014669274] hist_pred: [0.0191035774 0.0192735847 0.0194369834 ... 0.0177797284 0.0175356492 0.0172850136]\n",
      "KL loss: 0.00616603531 hist_true: [0.0142108547 0.0146313049 0.0150497351 ... 0.0195580833 0.0192306135 0.0188896749] hist_pred: [0.0192587767 0.0193858519 0.0195079111 ... 0.0183718596 0.0181735214 0.0179678015]\n",
      "KL loss: 0.00439148303 hist_true: [0.013444622 0.013918547 0.014392456 ... 0.0191134866 0.0187114552 0.0182956867] hist_pred: [0.0179085061 0.0180560537 0.0182007588 ... 0.0199136827 0.0197612792 0.019597983]\n",
      "KL loss: 0.0137344124 hist_true: [0.0169854555 0.0173000265 0.01760743 ... 0.0181538835 0.0178601556 0.0175580941] hist_pred: [0.024589939 0.0244636796 0.024330046 ... 0.0155240428 0.0153539022 0.0151867345]\n",
      "KL loss: 0.00369588239 hist_true: [0.0171686783 0.0177365392 0.0182917491 ... 0.0129137933 0.0123438351 0.0117805786] hist_pred: [0.0216672085 0.0218495224 0.02201996 ... 0.0139972959 0.013650232 0.0133099]\n",
      "KL loss: 0.00914800353 hist_true: [0.0182070024 0.0185890738 0.0189584941 ... 0.0151359504 0.0146974521 0.0142566534] hist_pred: [0.0159297548 0.0162278 0.0165225156 ... 0.0200570337 0.0198612511 0.0196550284]\n",
      "KL loss: 0.00305695 hist_true: [0.0164477043 0.0169386715 0.0174201913 ... 0.0151538774 0.0146545265 0.0141533175] hist_pred: [0.0204302296 0.0205836929 0.0207278989 ... 0.016192155 0.0159026626 0.0156114912]\n",
      "KL loss: 0.0132708512 hist_true: [0.00904071424 0.00956144836 0.0100975316 ... 0.0221947767 0.0217093155 0.0211964361] hist_pred: [0.0151417563 0.015444315 0.0157439 ... 0.0209352858 0.0207241382 0.0204954948]\n",
      "KL loss: 0.00791114 hist_true: [0.00962571707 0.0102651836 0.0109235691 ... 0.0176205989 0.0169177316 0.0162073057] hist_pred: [0.0141212931 0.0146479011 0.0151685113 ... 0.0185425542 0.0181878414 0.0178220943]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5668 KL loss: 0.00168470992 hist_true: [0.0184686165 0.018792564 0.0191049259 ... 0.0159045067 0.0155210206 0.0151335485] hist_pred: [0.0195335746 0.0196495764 0.0197604913 ... 0.0181984641 0.0180029459 0.0178011246]\n",
      "KL loss: 0.000786790391 hist_true: [0.0177482404 0.0180406049 0.0183245353 ... 0.0175177958 0.0172115453 0.0168983936] hist_pred: [0.0198041052 0.0199336465 0.0200562179 ... 0.0177230313 0.0175173599 0.0173074082]\n",
      "KL loss: 0.00454536267 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0180256758 0.0184767526 0.0189139061 ... 0.0141305896 0.013637485 0.0131453509]\n",
      "KL loss: 0.00938263256 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0147197768 0.015210676 0.0156973284 ... 0.0172733739 0.0168265589 0.0163721871]\n",
      "KL loss: 0.0028919722 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.019629173 0.0198652335 0.020089699 ... 0.0159900058 0.0156546757 0.0153157441]\n",
      "KL loss: 0.00248611975 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0208425261 0.0210406017 0.0212247837 ... 0.015181087 0.0148510383 0.0145207029]\n",
      "KL loss: 0.00960406475 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0184086673 0.0187857449 0.0191495027 ... 0.0150818164 0.0146552883 0.0142272329]\n",
      "KL loss: 0.0067980811 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0226722844 0.0227820147 0.0228770804 ... 0.014037759 0.0136833088 0.0133294677]\n",
      "KL loss: 0.000725615537 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0205617733 0.020586146 0.0206073541 ... 0.0186079498 0.0185096078 0.0184095725]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5817 - val_loss: 0.4567\n",
      "Epoch 27/50\n",
      "KL loss: 0.00273736124 hist_true: [0.0109339356 0.0114851343 0.0120456247 ... 0.0195750277 0.0190538615 0.018515788] hist_pred: [0.0139063476 0.0142951664 0.0146839591 ... 0.0204654243 0.0201690327 0.0198558196]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8633KL loss: 0.011569282 hist_true: [0.0164169837 0.0167378411 0.017052846 ... 0.0188501496 0.018582793 0.0183059927] hist_pred: [0.0229214262 0.022896735 0.0228648409 ... 0.015900217 0.0156824477 0.0154647753]\n",
      "KL loss: 0.00136220898 hist_true: [0.017401848 0.0176575501 0.017906962 ... 0.0188480467 0.0186279584 0.0184001196] hist_pred: [0.0201107152 0.0201449394 0.0201765709 ... 0.0191390663 0.0190643612 0.0189874955]\n",
      "KL loss: 0.00176936365 hist_true: [0.0177838579 0.0180724803 0.0183526464 ... 0.0175627284 0.0172623228 0.0169551019] hist_pred: [0.0207221415 0.0208156426 0.020900812 ... 0.0172597952 0.0170702338 0.0168789588]\n",
      "KL loss: 0.0194115043 hist_true: [0.0144366622 0.0148908729 0.0153422328 ... 0.0183797032 0.0179805513 0.0175701454] hist_pred: [0.0226614196 0.0227364656 0.0227972418 ... 0.0151120219 0.0148599092 0.0146105103]\n",
      "KL loss: 0.00345003698 hist_true: [0.0184167847 0.0187121704 0.0189971402 ... 0.0165218506 0.0161750503 0.0158231184] hist_pred: [0.0179201644 0.0180917569 0.0182589572 ... 0.0199548677 0.0198534373 0.0197462253]\n",
      "KL loss: 0.00964214653 hist_true: [0.0216839146 0.021949023 0.0221945029 ... 0.0129389409 0.0125012044 0.0120669203] hist_pred: [0.0204520579 0.0205036104 0.0205501877 ... 0.0180142559 0.0178269818 0.0176324863]\n",
      "KL loss: 0.0136428718 hist_true: [0.0099983383 0.0105503388 0.0111151384 ... 0.0203857943 0.0198555 0.0193050746] hist_pred: [0.0161595419 0.0165224429 0.0168766454 ... 0.0191448424 0.0189083721 0.0186610147]\n",
      "KL loss: 0.00205655489 hist_true: [0.021236103 0.0217299443 0.0221965704 ... 0.0103561068 0.00982847 0.0093149282] hist_pred: [0.02495775 0.025072271 0.0251643155 ... 0.0112192538 0.01080555 0.0104018422]\n",
      "KL loss: 0.0293910857 hist_true: [0.00906501058 0.0096403854 0.0102339583 ... 0.0199380182 0.0193030871 0.0186490752] hist_pred: [0.0171896853 0.0176133 0.0180243198 ... 0.0162122604 0.0158502739 0.0154892616]\n",
      "KL loss: 0.00619808398 hist_true: [0.0133211641 0.0137746911 0.0142284436 ... 0.0198811516 0.019529555 0.0191629138] hist_pred: [0.0183967222 0.0185511801 0.018699931 ... 0.0196242612 0.0195134599 0.0193971023]\n",
      "KL loss: 0.00599022489 hist_true: [0.0106223552 0.0112066157 0.0118026203 ... 0.0187305324 0.0181380771 0.0175318513] hist_pred: [0.0144172162 0.0148004685 0.0151786655 ... 0.02140994 0.0212738104 0.0211235136]\n",
      "KL loss: 0.00229171617 hist_true: [0.0161375199 0.0166171901 0.0170883965 ... 0.0157824885 0.0153053356 0.0148243727] hist_pred: [0.0179403517 0.018158447 0.0183723047 ... 0.0183238182 0.0180909764 0.0178546757]\n",
      "KL loss: 0.00410209224 hist_true: [0.0149833374 0.0154488664 0.0159096643 ... 0.017466506 0.0170361269 0.0165969227] hist_pred: [0.0184178036 0.0185766555 0.0187279601 ... 0.020174101 0.0201348048 0.020090865]\n",
      "KL loss: 0.00263712928 hist_true: [0.0166635439 0.0171489846 0.0176244341 ... 0.0150032779 0.0145043898 0.0140041206] hist_pred: [0.0194100589 0.0196151659 0.0198091399 ... 0.0172002334 0.0169536732 0.0167034436]\n",
      "KL loss: 0.0251480266 hist_true: [0.0126195606 0.013202901 0.0137906093 ... 0.0168740936 0.0162864421 0.0156917255] hist_pred: [0.0229043588 0.0229602177 0.0229952838 ... 0.0165331103 0.0163934249 0.0162491146]\n",
      "KL loss: 0.0051406743 hist_true: [0.0139463898 0.014381743 0.0148157217 ... 0.0195280816 0.0191851221 0.0188285131] hist_pred: [0.0181400962 0.0183788687 0.018610185 ... 0.018087497 0.0178426914 0.0175915658]\n",
      "KL loss: 0.00530382898 hist_true: [0.0138136847 0.0142449904 0.0146752503 ... 0.0198363662 0.0195097513 0.0191689488] hist_pred: [0.0184716228 0.0186337214 0.0187910739 ... 0.0188120082 0.018607283 0.0183934029]\n",
      "KL loss: 0.00769335916 hist_true: [0.0178297479 0.0181882232 0.0185358 ... 0.0161021166 0.0157074966 0.0153083224] hist_pred: [0.0241019409 0.0240466204 0.0239800941 ... 0.0152400555 0.0150428284 0.0148492893]\n",
      "KL loss: 0.00122428592 hist_true: [0.0178533047 0.0182400271 0.0186150353 ... 0.0155043714 0.0150749907 0.0146424323] hist_pred: [0.020129798 0.0202868618 0.020435065 ... 0.0166947674 0.0164307393 0.0161636919]\n",
      "KL loss: 0.00179727841 hist_true: [0.0186131168 0.0189165249 0.0192084983 ... 0.0161392894 0.0157770757 0.0154105425] hist_pred: [0.0181440432 0.0183570348 0.0185639895 ... 0.0184679367 0.0182444956 0.0180139877]\n",
      "KL loss: 0.0101617146 hist_true: [0.0164747778 0.01687143 0.0172602739 ... 0.0170475319 0.0166547317 0.0162546858] hist_pred: [0.022413278 0.022532925 0.0226373132 ... 0.0145063102 0.0141886035 0.0138718188]\n",
      "KL loss: 0.00218550977 hist_true: [0.0161597524 0.0165977515 0.0170280971 ... 0.0165609773 0.0161257591 0.0156844016] hist_pred: [0.0196582247 0.0197961051 0.0199293233 ... 0.0170819517 0.0167914461 0.0164944325]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6019 KL loss: 0.00154991634 hist_true: [0.0177673604 0.0182676129 0.0187536757 ... 0.0135327708 0.0130031714 0.0124768084] hist_pred: [0.019826252 0.0201065186 0.0203726515 ... 0.0152058154 0.014847599 0.0144884707]\n",
      "KL loss: 0.00325336913 hist_true: [0.0156709962 0.016104022 0.0165308639 ... 0.0172860119 0.0168726481 0.0164510421] hist_pred: [0.016031865 0.0162898321 0.016545115 ... 0.0207404681 0.0205898099 0.0204270855]\n",
      "KL loss: 0.0149253085 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0195826888 0.0200696755 0.0205368809 ... 0.0117586497 0.0112130502 0.0106765842]\n",
      "KL loss: 0.014516551 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0151819717 0.0157024227 0.0162172616 ... 0.0160108898 0.0155124338 0.0150103765]\n",
      "KL loss: 0.010410225 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.021616688 0.0218122751 0.0219920855 ... 0.014031508 0.0136437006 0.0132563077]\n",
      "KL loss: 0.00445540901 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0215430018 0.0217296295 0.0219005626 ... 0.014471462 0.0141209019 0.0137711968]\n",
      "KL loss: 0.0201165508 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0198861361 0.0202627052 0.0206215978 ... 0.0131949354 0.0127131175 0.0122345043]\n",
      "KL loss: 0.0115981782 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0236763526 0.0237696934 0.0238459241 ... 0.0129982438 0.0126143908 0.0122332303]\n",
      "KL loss: 0.00315655884 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0219252557 0.0219009984 0.0218727738 ... 0.0173283666 0.017178474 0.0170276165]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6149 - val_loss: 0.4585\n",
      "Epoch 28/50\n",
      "KL loss: 0.0013076975 hist_true: [0.0199923906 0.0202823579 0.0205573663 ... 0.0145521481 0.0141430525 0.0137332138] hist_pred: [0.0225478429 0.0225531384 0.0225506872 ... 0.0157133192 0.0154483905 0.0151810236]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8581KL loss: 0.00283358293 hist_true: [0.0184126273 0.0188001301 0.0191742759 ... 0.0147777973 0.0143281212 0.0138772521] hist_pred: [0.0220363922 0.0222161971 0.022377599 ... 0.0142699499 0.0139395548 0.0136117851]\n",
      "KL loss: 0.000559367938 hist_true: [0.0191153046 0.0192949977 0.0194671024 ... 0.0178191401 0.017594222 0.0173641127] hist_pred: [0.0197561234 0.0198124237 0.0198660456 ... 0.0192034673 0.0191135053 0.0190200228]\n",
      "KL loss: 0.00144249678 hist_true: [0.0190071017 0.0192917567 0.0195646193 ... 0.0159448981 0.0155844884 0.0152202714] hist_pred: [0.0218882486 0.0219099503 0.0219242629 ... 0.0166136548 0.0164013747 0.0161865968]\n",
      "KL loss: 0.00206836662 hist_true: [0.0171874035 0.0175319705 0.0178680494 ... 0.0171971153 0.0168445799 0.0164850187] hist_pred: [0.02017 0.0202313494 0.0202872418 ... 0.0186616313 0.0185418818 0.0184175465]\n",
      "KL loss: 0.00175524375 hist_true: [0.0174422637 0.0178981144 0.0183420107 ... 0.0146562187 0.0141663328 0.0136758545] hist_pred: [0.0205048956 0.0207407754 0.0209658947 ... 0.0141820973 0.0137492055 0.0133158388]\n",
      "KL loss: 0.00821905117 hist_true: [0.0155959446 0.0160633661 0.0165244713 ... 0.0165992081 0.0161417089 0.0156778339] hist_pred: [0.0219944026 0.0220302027 0.0220543221 ... 0.0169428233 0.016784776 0.0166256186]\n",
      "KL loss: 0.000560346758 hist_true: [0.019173706 0.0193849299 0.0195870027 ... 0.0171006955 0.0168242119 0.0165427271] hist_pred: [0.0209366102 0.0209788457 0.0210158452 ... 0.017610088 0.0174385365 0.0172639377]\n",
      "KL loss: 0.000536956824 hist_true: [0.0193366334 0.0196600817 0.0199691895 ... 0.0148369949 0.0144243101 0.0140103102] hist_pred: [0.0208098982 0.0209692698 0.0211173929 ... 0.0156950746 0.0153817935 0.0150659103]\n",
      "KL loss: 0.00380564667 hist_true: [0.0163350869 0.0167151727 0.0170880649 ... 0.0176390558 0.0172809139 0.0169144813] hist_pred: [0.020757433 0.0208225176 0.0208815299 ... 0.0174685456 0.017282404 0.017093556]\n",
      "KL loss: 0.0120135145 hist_true: [0.0106818974 0.0113180354 0.011968066 ... 0.0169557519 0.0162736028 0.015585972] hist_pred: [0.0161864404 0.016719345 0.0172363035 ... 0.0174663924 0.0172498096 0.0170347225]\n",
      "KL loss: 0.00807518605 hist_true: [0.0167583581 0.0172789842 0.0177885778 ... 0.0142720379 0.0137433 0.0132157207] hist_pred: [0.0149918646 0.0153923342 0.0157899223 ... 0.0187415704 0.0183917265 0.0180308819]\n",
      "KL loss: 0.00076203 hist_true: [0.0181358624 0.0184044838 0.0186643694 ... 0.0174798667 0.0171886049 0.0168909766] hist_pred: [0.0182665661 0.0184470527 0.018622227 ... 0.0191477388 0.0189968571 0.0188408196]\n",
      "KL loss: 0.00135626621 hist_true: [0.0169271771 0.0172097981 0.0174864419 ... 0.0189601444 0.0187259112 0.0184830688] hist_pred: [0.0195605867 0.0196337271 0.0197031144 ... 0.0193471517 0.0192681123 0.0191860646]\n",
      "KL loss: 0.0404172242 hist_true: [0.00816886406 0.00872304384 0.00929868594 ... 0.0210994612 0.0204662699 0.0198091641] hist_pred: [0.0184954684 0.0187793057 0.0190467909 ... 0.0180813614 0.0178787839 0.0176698379]\n",
      "KL loss: 0.00372269191 hist_true: [0.0182719436 0.018583253 0.018884 ... 0.0164055713 0.0160453636 0.0156800989] hist_pred: [0.0223930757 0.022454733 0.0225046147 ... 0.0153781623 0.015109852 0.0148413777]\n",
      "KL loss: 0.000748527353 hist_true: [0.0175543558 0.017840758 0.0181194153 ... 0.0179342963 0.0176500939 0.0173584707] hist_pred: [0.0195447765 0.0196771193 0.0198037848 ... 0.0180017203 0.0178115312 0.0176176317]\n",
      "KL loss: 0.00185094704 hist_true: [0.0201360583 0.0203856491 0.020621594 ... 0.0150491912 0.0146726919 0.0142943282] hist_pred: [0.0235486608 0.0234828908 0.0234100241 ... 0.0156528112 0.0154298618 0.0152064851]\n",
      "KL loss: 0.00749821262 hist_true: [0.0129604526 0.0134935984 0.0140285501 ... 0.0180222262 0.017517807 0.0170017667] hist_pred: [0.0180597957 0.0183668435 0.0186645519 ... 0.017277386 0.0170156509 0.0167516842]\n",
      "KL loss: 0.00593622401 hist_true: [0.0147781866 0.0154131632 0.0160448737 ... 0.0137840305 0.0131613789 0.0125440909] hist_pred: [0.0198640693 0.0200875457 0.0202983487 ... 0.0157624297 0.0154111274 0.0150567386]\n",
      "KL loss: 0.00515233167 hist_true: [0.0155889653 0.0163085945 0.0170227699 ... 0.0115617421 0.0109147672 0.0102840643] hist_pred: [0.0193168782 0.0196500607 0.019971272 ... 0.0143841086 0.0139431357 0.0135027701]\n",
      "KL loss: 0.00479259714 hist_true: [0.013147139 0.0137694962 0.0143946419 ... 0.0155191729 0.0148968538 0.0142731862] hist_pred: [0.0171645675 0.0175683759 0.0179629568 ... 0.0169547945 0.0166892018 0.0164264981]\n",
      "KL loss: 0.00739807077 hist_true: [0.00969495624 0.0102106547 0.010738818 ... 0.0220193323 0.0215816814 0.0211187806] hist_pred: [0.0140386913 0.0144223738 0.0148046203 ... 0.0206725448 0.0204050187 0.0201209579]\n",
      "KL loss: 0.0184591264 hist_true: [0.0108795473 0.0114269517 0.011983674 ... 0.0197204258 0.01920099 0.0186637212] hist_pred: [0.0173193254 0.0177306533 0.018129481 ... 0.0161248036 0.0157311372 0.0153344041]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5726 KL loss: 0.00254713511 hist_true: [0.0142846154 0.0147627778 0.0152384955 ... 0.0179179627 0.0174772367 0.0170259159] hist_pred: [0.0173886642 0.0176484659 0.0178997647 ... 0.0191882104 0.0190008972 0.0188058931]\n",
      "KL loss: 0.0053918371 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0180335846 0.0185040608 0.0189603772 ... 0.0137000605 0.0131837511 0.0126698278]\n",
      "KL loss: 0.00864468608 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0143514024 0.0148614794 0.0153684905 ... 0.0172247812 0.016756868 0.0162813626]\n",
      "KL loss: 0.00388273364 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0198474843 0.0200907048 0.0203214325 ... 0.0155445896 0.0151878279 0.0148281828]\n",
      "KL loss: 0.00255393423 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0208083354 0.0210146774 0.0212067403 ... 0.0151138445 0.0147802765 0.0144466572]\n",
      "KL loss: 0.0101017542 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0183437392 0.0187343806 0.0191116929 ... 0.0148422793 0.014395955 0.0139484284]\n",
      "KL loss: 0.00724413851 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0225970931 0.0227262136 0.0228399262 ... 0.0138070974 0.0134355882 0.0130649945]\n",
      "KL loss: 0.00118004926 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0208659135 0.0208826065 0.0208958536 ... 0.0182337333 0.0181145985 0.0179935861]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5762 - val_loss: 0.3591\n",
      "Epoch 29/50\n",
      "KL loss: 0.0303053036 hist_true: [0.0117032137 0.012392303 0.0130930943 ... 0.0146545749 0.0139260143 0.0132028982] hist_pred: [0.0222933423 0.0225480758 0.0227777436 ... 0.0146417655 0.0144355204 0.0142303016]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 2.1518KL loss: 0.00218884274 hist_true: [0.0192072205 0.0197049826 0.0201830491 ... 0.0122397337 0.0117135672 0.0111951046] hist_pred: [0.0214760397 0.0216422342 0.0217972789 ... 0.0143038547 0.0139300749 0.0135581726]\n",
      "KL loss: 0.00182470679 hist_true: [0.0177969858 0.0181434676 0.0184796192 ... 0.0163424313 0.0159594 0.0155711658] hist_pred: [0.0187935177 0.018953627 0.0191074181 ... 0.0188329704 0.0186802596 0.0185229052]\n",
      "KL loss: 0.0281432644 hist_true: [0.0143919662 0.0148347719 0.0152747883 ... 0.0187798291 0.0184083376 0.0180249624] hist_pred: [0.0240957476 0.0241124835 0.0241121314 ... 0.0145081952 0.0142805232 0.0140576409]\n",
      "KL loss: 0.00279122801 hist_true: [0.0168663245 0.0171994083 0.0175251216 ... 0.0179219078 0.0176069513 0.0172838513] hist_pred: [0.0203395579 0.0204673111 0.0205862876 ... 0.017085271 0.0168598276 0.0166313145]\n",
      "KL loss: 0.00175057515 hist_true: [0.0174206588 0.0177186988 0.0180089455 ... 0.0178855509 0.0175922848 0.0172915086] hist_pred: [0.0204480924 0.0205119941 0.0205702577 ... 0.0181901101 0.0180604905 0.0179290101]\n",
      "KL loss: 0.00388066284 hist_true: [0.0161685422 0.0165931154 0.0170102082 ... 0.0168426577 0.0164242703 0.0159989782] hist_pred: [0.0160982255 0.0163557604 0.0166114531 ... 0.0205524117 0.0204024129 0.0202429369]\n",
      "KL loss: 0.00178086944 hist_true: [0.0176018775 0.0180046055 0.0183959305 ... 0.0155231515 0.0150865056 0.0146467136] hist_pred: [0.0205920469 0.0207379088 0.0208735149 ... 0.0164367463 0.016179977 0.0159210749]\n",
      "KL loss: 0.00215831539 hist_true: [0.0131567782 0.0136233876 0.0140907411 ... 0.0197158046 0.0193424392 0.0189540796] hist_pred: [0.0161859374 0.0164459255 0.0167048 ... 0.0200444069 0.0198425073 0.0196296796]\n",
      "KL loss: 0.00977282505 hist_true: [0.0103502935 0.010880799 0.0114226826 ... 0.0205162037 0.020005621 0.0194740351] hist_pred: [0.0161090232 0.0163686536 0.0166251659 ... 0.0201779231 0.0199479237 0.0197019223]\n",
      "KL loss: 0.00130400574 hist_true: [0.0169794187 0.0173816085 0.0177743025 ... 0.0162961185 0.0158781745 0.0154548371] hist_pred: [0.017789958 0.0180473253 0.0182972029 ... 0.0184068438 0.0181852803 0.0179581419]\n",
      "KL loss: 0.0044815056 hist_true: [0.017631188 0.0179797951 0.0183184296 ... 0.0165354516 0.0161583815 0.0157756675] hist_pred: [0.0222029947 0.0222752709 0.0223346446 ... 0.0158441477 0.0156201087 0.0153965531]\n",
      "KL loss: 0.00617987383 hist_true: [0.0187105928 0.0191319901 0.0195378028 ... 0.0139321806 0.0134572461 0.0129840747] hist_pred: [0.0193209238 0.0194376968 0.0195499491 ... 0.0182106849 0.017986238 0.0177534502]\n",
      "KL loss: 0.00109157036 hist_true: [0.0195083283 0.0197668206 0.0200130846 ... 0.0157537796 0.015399727 0.0150424214] hist_pred: [0.0218609348 0.0218667835 0.0218672846 ... 0.0167753641 0.0165747721 0.0163724255]\n",
      "KL loss: 0.00229390385 hist_true: [0.0171820875 0.0175427087 0.0178943649 ... 0.0168750789 0.0165012889 0.0161209963] hist_pred: [0.0166812483 0.0169326663 0.0171815827 ... 0.0195160657 0.0192913916 0.0190558191]\n",
      "KL loss: 0.0335870609 hist_true: [0.0101157185 0.0106443213 0.0111844093 ... 0.0210311599 0.0205445 0.0200350676] hist_pred: [0.0191463046 0.0194436982 0.019726146 ... 0.0164389089 0.0161678102 0.0158953946]\n",
      "KL loss: 0.00167022925 hist_true: [0.0176157355 0.0179301146 0.0182356797 ... 0.0172510743 0.0169209782 0.016584184] hist_pred: [0.0206237193 0.020668583 0.0207088497 ... 0.0179963298 0.0178352073 0.0176697224]\n",
      "KL loss: 0.0014179534 hist_true: [0.0169941466 0.017330762 0.0176595394 ... 0.0176651813 0.0173372589 0.0170015469] hist_pred: [0.0196901262 0.0198328048 0.019967692 ... 0.017683072 0.0174679123 0.017248014]\n",
      "KL loss: 0.00160859525 hist_true: [0.0179228727 0.0181607623 0.0183917079 ... 0.0184360631 0.0182073414 0.0179716907] hist_pred: [0.0172689036 0.0174449291 0.0176186729 ... 0.0207431484 0.0206724145 0.0205950942]\n",
      "KL loss: 0.00236203056 hist_true: [0.0173607562 0.0177101027 0.0180502869 ... 0.016875878 0.0165100768 0.0161379464] hist_pred: [0.0206057113 0.0206423681 0.0206742845 ... 0.0184093732 0.0182954371 0.0181790981]\n",
      "KL loss: 0.00505885296 hist_true: [0.0178039428 0.0181437712 0.0184734352 ... 0.0164819472 0.0161090083 0.0157307182] hist_pred: [0.0229973476 0.0229684114 0.0229328386 ... 0.0155417314 0.015277449 0.0150111895]\n",
      "KL loss: 0.00274632452 hist_true: [0.0194091909 0.0196364596 0.0198532175 ... 0.016445972 0.0161323 0.0158143062] hist_pred: [0.0233430602 0.0232770275 0.0232047308 ... 0.0160332266 0.0158388764 0.015644623]\n",
      "KL loss: 0.00342309149 hist_true: [0.0137498779 0.0142380055 0.0147251626 ... 0.0183757897 0.0179411825 0.0174947847] hist_pred: [0.0174415447 0.0177249219 0.0179996435 ... 0.0185463317 0.0183181204 0.0180832185]\n",
      "KL loss: 0.00402225181 hist_true: [0.0142925987 0.0148577038 0.0154203558 ... 0.0158811808 0.0153298685 0.0147748673] hist_pred: [0.0186231844 0.0188430101 0.0190575011 ... 0.0171157718 0.0168212429 0.0165242199]\n",
      "KL loss: 0.00309105869 hist_true: [0.0181959886 0.018545378 0.0188830514 ... 0.0158037674 0.0154051995 0.0150028281] hist_pred: [0.0173622668 0.0176204052 0.0178727452 ... 0.0188542604 0.0186396018 0.018418014]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6768  KL loss: 0.000221598195 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0155727323 0.0160797145 0.0165799297 ... 0.0158073734 0.0153063294 0.0148013672]\n",
      "KL loss: 0.0011099556 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0122192865 0.0127353743 0.0132548381 ... 0.0196620319 0.0192434564 0.0188101046]\n",
      "KL loss: 0.000169560197 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0176243596 0.0179294515 0.0182259548 ... 0.0174512472 0.0171361547 0.0168142]\n",
      "KL loss: 0.000101141028 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0187611282 0.0190371461 0.0193021297 ... 0.0165867656 0.0162713565 0.0159525424]\n",
      "KL loss: 0.00198018062 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0159332734 0.016372 0.0168035477 ... 0.0169072039 0.0164878424 0.0160617977]\n",
      "KL loss: 0.00161249866 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0203725882 0.0205825418 0.0207799785 ... 0.0154184606 0.0150721027 0.0147233019]\n",
      "KL loss: 0.000151733228 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0197678059 0.0198302642 0.0198894851 ... 0.0191493239 0.0190628264 0.0189737976]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6770 - val_loss: 0.3163\n",
      "Epoch 30/50\n",
      "KL loss: 0.00216697436 hist_true: [0.0170772374 0.017501181 0.0179147813 ... 0.01576728 0.0153248347 0.0148785599] hist_pred: [0.0181938447 0.0184126515 0.0186240133 ... 0.0183867011 0.0181544051 0.0179142505]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9544KL loss: 0.00171714928 hist_true: [0.0184052866 0.0188592765 0.0192978978 ... 0.013681028 0.0131822601 0.0126860924] hist_pred: [0.0210867636 0.0212731864 0.0214460455 ... 0.0150864478 0.0147741493 0.0144639034]\n",
      "KL loss: 0.000726940343 hist_true: [0.0166723989 0.0169830658 0.0172874834 ... 0.0187207628 0.0184565783 0.0181834828] hist_pred: [0.0172391515 0.0174297355 0.0176177397 ... 0.0203515813 0.0202383567 0.0201172]\n",
      "KL loss: 0.00122091081 hist_true: [0.0162309278 0.0166890081 0.0171390735 ... 0.0159935653 0.0155263385 0.0150544494] hist_pred: [0.0184862036 0.0187731907 0.0190493129 ... 0.016857082 0.0165569931 0.0162535682]\n",
      "KL loss: 0.00950590428 hist_true: [0.0104340883 0.0110274879 0.0116340276 ... 0.018443631 0.0178184547 0.0171806607] hist_pred: [0.0155197177 0.0159704909 0.0164148 ... 0.0172174349 0.0168006457 0.0163762774]\n",
      "KL loss: 0.00235531293 hist_true: [0.023369126 0.0237364732 0.0240726676 ... 0.0099511724 0.00945639238 0.00897523947] hist_pred: [0.0248070713 0.0248590093 0.0248943549 ... 0.0121205496 0.0117326574 0.0113505246]\n",
      "KL loss: 0.00108204456 hist_true: [0.0165060665 0.0168499537 0.0171872061 ... 0.0181702878 0.0178552233 0.0175312236] hist_pred: [0.0164271276 0.0166878272 0.0169450603 ... 0.0201649461 0.0200058781 0.0198381804]\n",
      "KL loss: 0.00657861866 hist_true: [0.0161334593 0.0165478978 0.0169550162 ... 0.0171503723 0.0167516433 0.0163454227] hist_pred: [0.0212628879 0.02140023 0.0215261579 ... 0.0155954566 0.0153086726 0.0150216576]\n",
      "KL loss: 0.00342021813 hist_true: [0.0167830791 0.0170930829 0.0173965935 ... 0.0185627025 0.0182912499 0.0180110838] hist_pred: [0.0200742092 0.0202271864 0.0203718562 ... 0.0167624839 0.016492242 0.0162178632]\n",
      "KL loss: 0.0013717179 hist_true: [0.0154749602 0.01597948 0.0164775513 ... 0.0159759372 0.0154802864 0.0149802268] hist_pred: [0.0179086924 0.0182708316 0.0186235383 ... 0.015675826 0.0152647765 0.014851952]\n",
      "KL loss: 0.000981928897 hist_true: [0.0157517251 0.0162201077 0.0166814663 ... 0.0164150931 0.0159518626 0.0154825319] hist_pred: [0.0178247765 0.0181657076 0.0184969828 ... 0.0165010337 0.0161464922 0.0157885309]\n",
      "KL loss: 0.0351876616 hist_true: [0.00772702042 0.00825916789 0.00881329831 ... 0.0223501399 0.0217660125 0.0211527683] hist_pred: [0.0161993112 0.0165635794 0.0169243943 ... 0.0176305696 0.0172914546 0.0169500839]\n",
      "KL loss: 0.0338218212 hist_true: [0.00816255249 0.00865845475 0.00917191058 ... 0.0239581335 0.0235359222 0.0230803695] hist_pred: [0.0160827246 0.0164475795 0.0168071277 ... 0.018417228 0.0181204397 0.0178162977]\n",
      "KL loss: 0.0113694482 hist_true: [0.015739318 0.0161625873 0.0165794734 ... 0.0174893159 0.0170963388 0.0166950561] hist_pred: [0.0226720404 0.0227079317 0.0227320455 ... 0.0156469122 0.0154227363 0.0152000664]\n",
      "KL loss: 0.00558095612 hist_true: [0.0179982912 0.0183158386 0.0186233874 ... 0.016660247 0.0163063947 0.0159469731] hist_pred: [0.0226850379 0.0227339566 0.022773128 ... 0.0146704717 0.0143395942 0.0140073076]\n",
      "KL loss: 0.0357596911 hist_true: [0.0100070201 0.0106407199 0.011291516 ... 0.0173158254 0.0166046061 0.0158865731] hist_pred: [0.0195779745 0.0199764613 0.0203574356 ... 0.0131656611 0.0126793282 0.0121975867]\n",
      "KL loss: 0.00814646296 hist_true: [0.0139826126 0.014435539 0.0148868747 ... 0.0190253071 0.018648563 0.0182590447] hist_pred: [0.0195961613 0.0197587665 0.0199121982 ... 0.0176837984 0.0174712446 0.0172534604]\n",
      "KL loss: 0.00146525668 hist_true: [0.019380644 0.019669883 0.0199459437 ... 0.015383834 0.0150032379 0.014620021] hist_pred: [0.0222953148 0.0223613754 0.0224174093 ... 0.0151082613 0.0148052853 0.0145013696]\n",
      "KL loss: 0.00283010677 hist_true: [0.0140676703 0.0145691242 0.0150690833 ... 0.0175214298 0.0170440711 0.0165571719] hist_pred: [0.0156991724 0.0159920845 0.0162815433 ... 0.0205894895 0.0204235837 0.0202467982]\n",
      "KL loss: 0.00154405949 hist_true: [0.0168299805 0.0172479562 0.0176563375 ... 0.0162289143 0.0158044659 0.0153749464] hist_pred: [0.0189085305 0.0191062987 0.0192958191 ... 0.0179809909 0.017773686 0.0175621286]\n",
      "KL loss: 0.00995281711 hist_true: [0.0186799299 0.0190763175 0.0194579232 ... 0.0144022694 0.0139482496 0.0134944459] hist_pred: [0.0176482834 0.0178066958 0.017964758 ... 0.0197645817 0.0195938367 0.0194133855]\n",
      "KL loss: 0.00031919952 hist_true: [0.018474672 0.0186799727 0.018878283 ... 0.0182627067 0.0180440936 0.0178193264] hist_pred: [0.0197048299 0.0197935663 0.0198775902 ... 0.0187644456 0.0186433233 0.0185189471]\n",
      "KL loss: 0.00280628772 hist_true: [0.0152750416 0.0157471411 0.0162137672 ... 0.0168912504 0.016435856 0.0159730613] hist_pred: [0.0180303399 0.0182597898 0.0184799898 ... 0.019171292 0.019035954 0.0188963767]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5744 KL loss: 0.00328239799 hist_true: [0.0169246402 0.017295016 0.0176569279 ... 0.0170114879 0.0166355893 0.0162527841] hist_pred: [0.020551743 0.0207304079 0.0208966285 ... 0.016042849 0.015763944 0.0154837156]\n",
      "KL loss: 0.00699019525 hist_true: [0.0187190101 0.019118445 0.019503342 ... 0.0141671123 0.0136956116 0.0132246902] hist_pred: [0.0169292614 0.0172223654 0.0175110176 ... 0.0183282401 0.0180408191 0.0177456513]\n",
      "KL loss: 0.000962456921 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0156134786 0.0161647 0.0167090539 ... 0.0147451656 0.014190563 0.0136359325]\n",
      "KL loss: 0.00110477069 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.011924929 0.0124608194 0.013001482 ... 0.0193567313 0.0188990366 0.0184271131]\n",
      "KL loss: 0.00116652739 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.018349098 0.0186513476 0.0189431142 ... 0.0164916907 0.0161412302 0.0157857575]\n",
      "KL loss: 3.44319778e-05 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0184664577 0.018761944 0.0190464873 ... 0.0166184139 0.0162930395 0.0159638673]\n",
      "KL loss: 0.00423337519 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0164289344 0.0168840177 0.0173304416 ... 0.0158394929 0.0153719364 0.0149001591]\n",
      "KL loss: 0.0017759261 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0202313177 0.0204646774 0.0206848942 ... 0.0151890023 0.0148230847 0.0144550037]\n",
      "KL loss: 0.00077506667 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.020440083 0.0204831231 0.0205222908 ... 0.0184242912 0.0183041599 0.0181816891]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5828 - val_loss: 0.2964\n",
      "Epoch 31/50\n",
      "KL loss: 0.0214546397 hist_true: [0.00938045606 0.00996835623 0.0105737289 ... 0.0193262063 0.0186820608 0.0180218536] hist_pred: [0.0168847907 0.0172787011 0.017661145 ... 0.0168988649 0.0165156554 0.016126167]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7214KL loss: 0.0394611284 hist_true: [0.0117136035 0.0123366266 0.0129683623 ... 0.0166038964 0.0159557294 0.0153022362] hist_pred: [0.0201918669 0.0207091812 0.0212052502 ... 0.0105953384 0.0100436788 0.00950791594]\n",
      "KL loss: 0.00155398971 hist_true: [0.0174807142 0.017822586 0.0181550067 ... 0.0169156715 0.0165593438 0.0161968] hist_pred: [0.020342961 0.0204502884 0.0205493681 ... 0.0174899399 0.017290106 0.017086491]\n",
      "KL loss: 0.00622088555 hist_true: [0.0162079949 0.0166848842 0.0171534251 ... 0.01567485 0.015191704 0.0147050023] hist_pred: [0.0217833314 0.0219023433 0.0220081788 ... 0.0151224863 0.0148052918 0.0144869089]\n",
      "KL loss: 0.0216472521 hist_true: [0.00962891709 0.010168721 0.010722423 ... 0.0210242625 0.0205046665 0.019962227] hist_pred: [0.0163598098 0.0167595111 0.0171525553 ... 0.016941648 0.0165525079 0.0161601231]\n",
      "KL loss: 0.00105750933 hist_true: [0.0166478641 0.017104242 0.017551301 ... 0.0155413039 0.0150660155 0.0145874079] hist_pred: [0.0175096486 0.0178235937 0.0181297157 ... 0.0173481572 0.0170272347 0.0167006701]\n",
      "KL loss: 0.000647573965 hist_true: [0.0191574097 0.0194461681 0.0197224952 ... 0.0156733375 0.0153017128 0.0149268229] hist_pred: [0.0211315602 0.0212092 0.0212803986 ... 0.0162515864 0.0159638617 0.01567146]\n",
      "KL loss: 0.001448052 hist_true: [0.0177841131 0.0181095153 0.0184252169 ... 0.0168050677 0.0164524317 0.0160938576] hist_pred: [0.0191783123 0.0193199441 0.0194541682 ... 0.0189096406 0.018790856 0.0186685175]\n",
      "KL loss: 0.00106642745 hist_true: [0.0148508679 0.0151901124 0.0155268461 ... 0.0208163224 0.0206282511 0.0204278957] hist_pred: [0.0170027651 0.0171592813 0.01731495 ... 0.02158284 0.0215677042 0.0215459075]\n",
      "KL loss: 0.0060396581 hist_true: [0.0168325789 0.0173222609 0.0178014282 ... 0.0146931931 0.0141834589 0.0136732683] hist_pred: [0.0220791176 0.0222742148 0.0224504396 ... 0.0139605301 0.0136169083 0.0132767037]\n",
      "KL loss: 0.0188979711 hist_true: [0.010518115 0.0110604847 0.0116133289 ... 0.020241363 0.0197337102 0.0192064419] hist_pred: [0.0178690329 0.0181827173 0.0184822362 ... 0.0181088019 0.0178773031 0.0176378023]\n",
      "KL loss: 0.00193574675 hist_true: [0.0169714522 0.0173495784 0.0177187771 ... 0.0168218575 0.01643732 0.016046349] hist_pred: [0.0201732554 0.0203189943 0.020456655 ... 0.0166280884 0.0163474679 0.0160629712]\n",
      "KL loss: 0.00160646625 hist_true: [0.0173921958 0.0177203603 0.0180398915 ... 0.0172748212 0.0169365294 0.016591277] hist_pred: [0.0182057191 0.0183544978 0.0185002461 ... 0.0196474455 0.0195171796 0.019379966]\n",
      "KL loss: 0.00310933497 hist_true: [0.0142024318 0.0147584723 0.0153126242 ... 0.0160808451 0.015531078 0.0149767613] hist_pred: [0.0169259664 0.0172070395 0.0174821578 ... 0.0185894594 0.0182959791 0.0179917291]\n",
      "KL loss: 0.00249891286 hist_true: [0.0189899113 0.0194758885 0.0199436489 ... 0.0125307208 0.0120031731 0.0114822257] hist_pred: [0.02246245 0.0226446968 0.0228057727 ... 0.0138333803 0.0134775406 0.0131221488]\n",
      "KL loss: 0.00576604204 hist_true: [0.0145673463 0.0150578618 0.0155452499 ... 0.0172092505 0.0167362932 0.016254697] hist_pred: [0.019273011 0.0195267983 0.0197699945 ... 0.0162356514 0.0159285069 0.0156207904]\n",
      "KL loss: 0.000769597944 hist_true: [0.0174592398 0.0178145897 0.0181601774 ... 0.0166444108 0.0162676498 0.015884921] hist_pred: [0.0182115268 0.0184428971 0.0186664257 ... 0.0182252321 0.0179936942 0.0177553445]\n",
      "KL loss: 0.00200610422 hist_true: [0.0171545558 0.0174858663 0.0178090539 ... 0.0175580531 0.0172302928 0.0168950912] hist_pred: [0.0204312503 0.0205186103 0.0205995124 ... 0.0174900703 0.0172831733 0.0170717537]\n",
      "KL loss: 0.00132782292 hist_true: [0.0186488833 0.0190034844 0.0193449166 ... 0.0151117854 0.0146894343 0.0142650325] hist_pred: [0.0214228593 0.0215317234 0.021630317 ... 0.0156678408 0.0153728193 0.0150757441]\n",
      "KL loss: 0.000698597636 hist_true: [0.0190647915 0.0192973092 0.0195200387 ... 0.0168426652 0.0165432263 0.0162388049] hist_pred: [0.0197721142 0.0198711306 0.0199647807 ... 0.018352773 0.0181910414 0.018024547]\n",
      "KL loss: 0.00244633574 hist_true: [0.0188131556 0.0192222446 0.0196155831 ... 0.0140497545 0.0135826059 0.0131166019] hist_pred: [0.0227256138 0.0228181742 0.0228974335 ... 0.0140594523 0.0137037802 0.0133492611]\n",
      "KL loss: 0.00192317739 hist_true: [0.0193658099 0.019585168 0.0197945032 ... 0.0166541208 0.0163528919 0.0160470884] hist_pred: [0.019521717 0.0195928477 0.019661136 ... 0.0192416906 0.0191408154 0.0190355219]\n",
      "KL loss: 0.0027266168 hist_true: [0.0160687082 0.0165113546 0.0169465616 ... 0.0165712461 0.0161325894 0.0156877413] hist_pred: [0.0196681544 0.0198304374 0.0199834071 ... 0.0175372604 0.0173160713 0.0170900207]\n",
      "KL loss: 0.0100731 hist_true: [0.0202758964 0.0205796398 0.0208669025 ... 0.0139832767 0.0135537926 0.0131250573] hist_pred: [0.0192194153 0.019312514 0.0194009654 ... 0.0195395369 0.0194512643 0.0193576086]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4645 KL loss: 0.0158476904 hist_true: [0.0111463582 0.0119215846 0.0127170496 ... 0.0124199055 0.0116159795 0.0108339144] hist_pred: [0.015297588 0.015743766 0.0161772817 ... 0.0185713749 0.0181814916 0.0177728366]\n",
      "KL loss: 0.000835733605 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0162640661 0.0167525373 0.0172322281 ... 0.0154085914 0.0149148982 0.0144185079]\n",
      "KL loss: 0.00315936888 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.013115122 0.0136233494 0.0141321085 ... 0.0188242849 0.0183992535 0.0179621577]\n",
      "KL loss: 0.000257846899 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.017874049 0.0181636717 0.0184445158 ... 0.0174218118 0.0171151236 0.0168018155]\n",
      "KL loss: 0.000300400512 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0191884935 0.0194449909 0.0196900181 ... 0.0163641367 0.0160501897 0.0157334283]\n",
      "KL loss: 0.00354976649 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0166725423 0.0170905832 0.0174995512 ... 0.0164424703 0.0160276312 0.0156075908]\n",
      "KL loss: 0.00273634051 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0210404601 0.0212210864 0.0213885438 ... 0.0150297433 0.0146822538 0.0143332276]\n",
      "KL loss: 0.000173186068 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0198133159 0.0198733 0.0199301038 ... 0.019113414 0.0190251637 0.0189343374]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4642 - val_loss: 0.3126\n",
      "Epoch 32/50\n",
      "KL loss: 0.00128830876 hist_true: [0.0151442345 0.0155363511 0.0159244575 ... 0.0189481173 0.0186234228 0.0182872284] hist_pred: [0.0173861142 0.017572755 0.0177561752 ... 0.0201300643 0.0199941192 0.0198490731]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2433KL loss: 0.00427256338 hist_true: [0.0155229168 0.0159087647 0.0162895396 ... 0.0186278932 0.0183015503 0.0179647841] hist_pred: [0.0194772165 0.019666804 0.0198467039 ... 0.0173382219 0.0171054341 0.0168689284]\n",
      "KL loss: 0.0119811371 hist_true: [0.011023243 0.0117294556 0.0124509763 ... 0.0148659945 0.0141248219 0.0133890621] hist_pred: [0.0166715384 0.0169500746 0.0172192827 ... 0.018953491 0.0185965989 0.0182195753]\n",
      "KL loss: 0.00230912864 hist_true: [0.0177691765 0.0181648489 0.0185488611 ... 0.0154244415 0.0149865355 0.0145455934] hist_pred: [0.0212372299 0.0213991627 0.0215476248 ... 0.0151610728 0.0148265334 0.0144899338]\n",
      "KL loss: 0.00794744119 hist_true: [0.0167572945 0.0171674807 0.0175683983 ... 0.0164873712 0.0160748865 0.0156566035] hist_pred: [0.0162852332 0.0164541584 0.0166256465 ... 0.0216150712 0.0215207301 0.0214132611]\n",
      "KL loss: 0.0174687412 hist_true: [0.00947928894 0.00998756476 0.0105089042 ... 0.022423692 0.0219953433 0.0215400271] hist_pred: [0.0152675603 0.0156534482 0.0160381217 ... 0.0182955507 0.0179352872 0.0175679009]\n",
      "KL loss: 0.00149491825 hist_true: [0.0158984382 0.0163079537 0.016710842 ... 0.0175786279 0.0171968825 0.016806569] hist_pred: [0.0185795967 0.0187651347 0.0189450793 ... 0.0183330644 0.0181172956 0.0178948399]\n",
      "KL loss: 0.00229887106 hist_true: [0.0182833746 0.0184778962 0.0186663754 ... 0.0187949687 0.0186108034 0.0184204299] hist_pred: [0.0210528038 0.0211050026 0.0211510863 ... 0.0172705967 0.0170802921 0.0168873388]\n",
      "KL loss: 0.0304999109 hist_true: [0.00951039232 0.010046781 0.0105977748 ... 0.0210145768 0.0204747673 0.0199114271] hist_pred: [0.0165001415 0.0169856455 0.017462533 ... 0.0154263359 0.014993648 0.0145644834]\n",
      "KL loss: 0.00812312 hist_true: [0.0193804502 0.0196975246 0.0200003106 ... 0.014898967 0.0144908037 0.0140811196] hist_pred: [0.0175242256 0.0177172739 0.0179074928 ... 0.0195189305 0.0193276871 0.0191260446]\n",
      "KL loss: 0.000911172479 hist_true: [0.018330045 0.0186511148 0.018960936 ... 0.0161937047 0.0158249568 0.0154517312] hist_pred: [0.0201180167 0.0202373639 0.0203498676 ... 0.0174471084 0.0172412805 0.0170328151]\n",
      "KL loss: 0.0039991755 hist_true: [0.015733622 0.01610744 0.0164759159 ... 0.0185967591 0.0182772372 0.0179474857] hist_pred: [0.0200750902 0.0201649107 0.020248495 ... 0.0182204284 0.01806763 0.0179108828]\n",
      "KL loss: 0.00867075101 hist_true: [0.0167281646 0.017037401 0.0173403192 ... 0.0186565835 0.0183893181 0.0181131847] hist_pred: [0.0223391335 0.0223617628 0.0223750137 ... 0.0162837077 0.0160950106 0.0159079917]\n",
      "KL loss: 0.00188280421 hist_true: [0.0171834771 0.0174989924 0.0178068541 ... 0.017834546 0.0175266322 0.0172109585] hist_pred: [0.0200543646 0.0201934427 0.0203249045 ... 0.0170483179 0.0167963486 0.0165398382]\n",
      "KL loss: 0.00487247761 hist_true: [0.0144400848 0.0151192807 0.0157972742 ... 0.0131591549 0.0125062838 0.01186259] hist_pred: [0.016279554 0.0166516509 0.0170196928 ... 0.0166804437 0.0162193235 0.0157523248]\n",
      "KL loss: 0.00313330721 hist_true: [0.0181354824 0.0185152534 0.018882595 ... 0.0152978795 0.0148676895 0.0144348955] hist_pred: [0.0188261773 0.0189805645 0.0191300306 ... 0.0184848588 0.0182856079 0.0180799663]\n",
      "KL loss: 0.00452326 hist_true: [0.0169337969 0.017254876 0.0175687484 ... 0.018087754 0.0177875832 0.0174791683] hist_pred: [0.0213300344 0.0213962216 0.0214533843 ... 0.0169566 0.0167711694 0.0165849384]\n",
      "KL loss: 0.00621113181 hist_true: [0.013881865 0.014545694 0.0152104469 ... 0.0139104221 0.0132598029 0.0126153026] hist_pred: [0.0160899311 0.0164307095 0.0167692583 ... 0.0181451049 0.0178192034 0.0174890105]\n",
      "KL loss: 0.003530588 hist_true: [0.0174039844 0.0178136118 0.0182121601 ... 0.0156601258 0.0152242668 0.0147848418] hist_pred: [0.01625151 0.0165874381 0.0169181656 ... 0.0188301709 0.0185771063 0.0183176696]\n",
      "KL loss: 0.00595997274 hist_true: [0.0182014145 0.0185515862 0.0188901722 ... 0.0157371908 0.0153328422 0.0149247209] hist_pred: [0.0164013784 0.0166676939 0.0169315431 ... 0.0196390133 0.0194127597 0.0191755425]\n",
      "KL loss: 0.0108585302 hist_true: [0.0103841582 0.010917766 0.0114621921 ... 0.0205922071 0.0200957358 0.019578265] hist_pred: [0.0158508681 0.0162090603 0.0165603664 ... 0.0187462345 0.0184257478 0.0180944987]\n",
      "KL loss: 0.00454228837 hist_true: [0.0203343052 0.0206128508 0.0208756626 ... 0.0143553428 0.0139483958 0.0135412617] hist_pred: [0.0213250872 0.0213106796 0.021291377 ... 0.0181097966 0.0179672483 0.0178185124]\n",
      "KL loss: 0.00179069024 hist_true: [0.017689487 0.0180095769 0.0183203183 ... 0.0170701053 0.0167322047 0.0163879823] hist_pred: [0.0180542972 0.018238157 0.0184162445 ... 0.0196591131 0.019549 0.0194339715]\n",
      "KL loss: 0.00295887608 hist_true: [0.0181884281 0.018472122 0.0187464524 ... 0.0170799941 0.0167621356 0.0164383035] hist_pred: [0.0216196738 0.0217095315 0.021789521 ... 0.0157712661 0.0154959634 0.0152193885]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4030 KL loss: 0.00609734189 hist_true: [0.0174491033 0.0181966 0.0189306922 ... 0.00973071437 0.00910657551 0.00850560516] hist_pred: [0.020346066 0.0206536558 0.020944735 ... 0.0129040312 0.0123533895 0.0118040843]\n",
      "KL loss: 0.00308819395 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.016828144 0.0173506141 0.0178623777 ... 0.0139965815 0.0134510146 0.0129074892]\n",
      "KL loss: 0.00342722936 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0128861805 0.0134168854 0.0139492406 ... 0.0184021853 0.0179347731 0.0174561255]\n",
      "KL loss: 0.0018275464 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0187846571 0.0190713517 0.019346917 ... 0.0161842722 0.0158296674 0.0154706817]\n",
      "KL loss: 0.000728251471 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0195224434 0.0197831132 0.0200310778 ... 0.0158502851 0.0155159179 0.0151795959]\n",
      "KL loss: 0.00641194 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0171920266 0.0176249426 0.0180472117 ... 0.0153831067 0.0149210049 0.0144560449]\n",
      "KL loss: 0.00384275592 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0212443471 0.0214392524 0.021619698 ... 0.0145024257 0.0141288182 0.0137545653]\n",
      "KL loss: 0.00108942413 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0206939764 0.020726392 0.0207549 ... 0.0182071589 0.0180785786 0.0179477464]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4040 - val_loss: 0.2639\n",
      "Epoch 33/50\n",
      "KL loss: 0.00174558861 hist_true: [0.0151378661 0.0155670298 0.0159914754 ... 0.018103309 0.0177198928 0.0173262656] hist_pred: [0.0169109181 0.0171087589 0.0173050556 ... 0.0202810578 0.0201128386 0.0199323669]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7889KL loss: 0.0022660559 hist_true: [0.0174557287 0.0178443808 0.018222522 ... 0.0159532484 0.0155340023 0.0151103586] hist_pred: [0.0169454291 0.0172308572 0.0175116193 ... 0.0185492542 0.0182776134 0.0179974847]\n",
      "KL loss: 0.00325757894 hist_true: [0.0160277486 0.0164129585 0.0167918615 ... 0.017902296 0.0175463986 0.0171814207] hist_pred: [0.0199529231 0.020072734 0.0201837663 ... 0.018208744 0.0180685204 0.0179257635]\n",
      "KL loss: 0.0255215801 hist_true: [0.0098456135 0.0104503063 0.0110712098 ... 0.0184931401 0.0178364702 0.0171674453] hist_pred: [0.0183411166 0.0187080242 0.0190588776 ... 0.0163549595 0.0160432216 0.0157293696]\n",
      "KL loss: 0.00117434538 hist_true: [0.0191222299 0.0193809122 0.0196285639 ... 0.0162590183 0.0159223732 0.0155814588] hist_pred: [0.0216539782 0.0217266791 0.0217905249 ... 0.0160107575 0.0157539789 0.0154958759]\n",
      "KL loss: 0.00683509186 hist_true: [0.0172152035 0.0175694264 0.0179147348 ... 0.0169835221 0.0166193508 0.0162486304] hist_pred: [0.0228893254 0.0228842907 0.0228704736 ... 0.0155329192 0.0152724413 0.0150101371]\n",
      "KL loss: 0.00322084688 hist_true: [0.0184522383 0.0188952833 0.0193233266 ... 0.0137500595 0.0132523207 0.0127567584] hist_pred: [0.0201942418 0.0203140154 0.0204270016 ... 0.0166085307 0.0162820406 0.0159471873]\n",
      "KL loss: 0.00656960346 hist_true: [0.017754104 0.0181389544 0.0185125154 ... 0.0156499073 0.0152245648 0.0147956535] hist_pred: [0.0238282643 0.0237768479 0.0237155072 ... 0.0150538478 0.0147839254 0.0145116383]\n",
      "KL loss: 0.0143381339 hist_true: [0.00950173475 0.0101420656 0.0108028 ... 0.0171899591 0.0164408386 0.0156865921] hist_pred: [0.0159950536 0.0163732562 0.0167398043 ... 0.0192547739 0.0189852882 0.0187002886]\n",
      "KL loss: 0.0113280825 hist_true: [0.00917881541 0.00975811109 0.0103550758 ... 0.0199085325 0.0192907918 0.0186546855] hist_pred: [0.015165926 0.0154781165 0.0157876648 ... 0.0204473529 0.020211976 0.019962674]\n",
      "KL loss: 0.0133623006 hist_true: [0.0127687622 0.0133112017 0.0138565144 ... 0.0179025978 0.0173805635 0.0168474335] hist_pred: [0.0199315269 0.0201155171 0.0202896707 ... 0.0161030553 0.0157532711 0.0153976586]\n",
      "KL loss: 0.00320987543 hist_true: [0.019429097 0.0198896863 0.0203308966 ... 0.0125595871 0.012050176 0.0115470486] hist_pred: [0.0239453465 0.0240436792 0.0241212 ... 0.0128744524 0.0124911135 0.012109993]\n",
      "KL loss: 0.00792217068 hist_true: [0.019939946 0.0204068869 0.0208529457 ... 0.0118139153 0.0112869637 0.0107688988] hist_pred: [0.0197058637 0.0199160874 0.0201152936 ... 0.0163459238 0.016029926 0.0157090556]\n",
      "KL loss: 0.00355286268 hist_true: [0.0132928472 0.0138466032 0.0144014778 ... 0.0171140507 0.0165774859 0.0160328113] hist_pred: [0.0168094728 0.0171937961 0.0175682921 ... 0.0177337267 0.0174661279 0.0171963]\n",
      "KL loss: 0.00249667512 hist_true: [0.0145098036 0.0149869267 0.0154611412 ... 0.0175965317 0.0171435084 0.0166806635] hist_pred: [0.017092213 0.017331874 0.0175662562 ... 0.0197852403 0.0196318291 0.0194710288]\n",
      "KL loss: 0.00879302248 hist_true: [0.0192154311 0.0196243264 0.0200165175 ... 0.0134864561 0.0130008301 0.012517876] hist_pred: [0.0173413083 0.0176117327 0.0178772844 ... 0.0180824175 0.0177801922 0.0174690448]\n",
      "KL loss: 0.00257746782 hist_true: [0.0155184856 0.0161158089 0.0167066697 ... 0.0138356742 0.0132360933 0.0126404352] hist_pred: [0.0185011271 0.018903695 0.0192905795 ... 0.0152820135 0.0149238128 0.0145669337]\n",
      "KL loss: 0.0010492974 hist_true: [0.0169134978 0.0173388515 0.0177543871 ... 0.0159040205 0.0154602285 0.0150119765] hist_pred: [0.0176365431 0.0179429725 0.0182394963 ... 0.0177694298 0.017492976 0.0172102582]\n",
      "KL loss: 0.00145413913 hist_true: [0.0182901435 0.0185622256 0.0188250989 ... 0.0171705745 0.0168632716 0.0165499952] hist_pred: [0.0183498412 0.0185021069 0.018650623 ... 0.0194247086 0.0192869827 0.0191428065]\n",
      "KL loss: 0.00265784562 hist_true: [0.0159722418 0.0163209978 0.0166642517 ... 0.0188753381 0.0185893867 0.0182933919] hist_pred: [0.0193373654 0.0194849558 0.019626027 ... 0.0181427449 0.0179557707 0.0177644]\n",
      "KL loss: 0.00216850778 hist_true: [0.0166056156 0.0170490555 0.0174834225 ... 0.0158842392 0.0154272318 0.0149659328] hist_pred: [0.0198493339 0.0200678613 0.0202735476 ... 0.0163456816 0.0160554592 0.0157619677]\n",
      "KL loss: 0.00449034618 hist_true: [0.0171994623 0.0176953673 0.0181793869 ... 0.014195933 0.0136776995 0.0131607661] hist_pred: [0.0201558862 0.0202565286 0.0203501899 ... 0.0174316429 0.0171809513 0.0169222429]\n",
      "KL loss: 0.00916649494 hist_true: [0.0110036097 0.0115258452 0.0120563926 ... 0.0203901548 0.0199225415 0.019435158] hist_pred: [0.0159719922 0.0163386613 0.0166986901 ... 0.0186096691 0.0183100197 0.0180014558]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5167 KL loss: 0.00397080369 hist_true: [0.0193148274 0.0195258576 0.0197273362 ... 0.0168998651 0.0166145694 0.0163245294] hist_pred: [0.0235062912 0.0234584175 0.0234027877 ... 0.0154875107 0.0152619705 0.0150371436]\n",
      "KL loss: 0.000525852607 hist_true: [0.0181132387 0.0183292646 0.0185387507 ... 0.0186041631 0.0183970407 0.0181833245] hist_pred: [0.0198537055 0.019908756 0.0199615043 ... 0.0189158078 0.0187991969 0.0186783466]\n",
      "KL loss: 0.00389646366 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0176315587 0.0181013159 0.018558396 ... 0.0141115077 0.0135975163 0.0130844871]\n",
      "KL loss: 0.00572961569 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0136551298 0.0141731324 0.0146902064 ... 0.0178533904 0.017389087 0.0169149917]\n",
      "KL loss: 0.00357662886 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0196856577 0.0199370664 0.0201761462 ... 0.0156084327 0.0152497189 0.014887942]\n",
      "KL loss: 0.00224215165 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0206703469 0.0208801311 0.0210758708 ... 0.0152539909 0.0149255283 0.0145968376]\n",
      "KL loss: 0.00787460618 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0177532211 0.0181610938 0.0185571201 ... 0.0152004259 0.0147499656 0.0142971901]\n",
      "KL loss: 0.00555934571 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0219959635 0.0221528262 0.0222948194 ... 0.0141287325 0.0137563851 0.0133841848]\n",
      "KL loss: 0.00172745041 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0211491138 0.0211593676 0.0211658813 ... 0.0178703554 0.0177308042 0.0175892208]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5131 - val_loss: 0.2496\n",
      "Epoch 34/50\n",
      "KL loss: 0.000240710098 hist_true: [0.0183494296 0.018552402 0.01874879 ... 0.0185146648 0.0183109846 0.0181010794] hist_pred: [0.0189383049 0.0190548431 0.0191674028 ... 0.0193867516 0.0192820504 0.019173136]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1290KL loss: 0.00116676465 hist_true: [0.0173427016 0.0177666396 0.0181795359 ... 0.0154050887 0.0149508724 0.0144937327] hist_pred: [0.0178179573 0.0180771817 0.018332934 ... 0.0172308739 0.0168799069 0.0165211391]\n",
      "KL loss: 0.00241797604 hist_true: [0.0156448688 0.0161469374 0.0166417379 ... 0.0159057584 0.0154150696 0.0149201] hist_pred: [0.0188311748 0.0190250408 0.0192135703 ... 0.0174892265 0.017221272 0.0169484988]\n",
      "KL loss: 0.00139263365 hist_true: [0.0185870975 0.0188443735 0.0190921444 ... 0.0170514919 0.0167483743 0.0164397229] hist_pred: [0.0189330932 0.0190502238 0.0191635769 ... 0.0192707796 0.0191469807 0.0190176144]\n",
      "KL loss: 0.000597059436 hist_true: [0.0175079033 0.0179188251 0.0183185507 ... 0.0154540194 0.015009 0.0145609872] hist_pred: [0.0193740316 0.0196187086 0.0198545139 ... 0.0157407653 0.0153713105 0.0149988085]\n",
      "KL loss: 0.00755695673 hist_true: [0.0172492824 0.01760781 0.0179572012 ... 0.0168491695 0.0164778214 0.016100185] hist_pred: [0.0234306436 0.0233808178 0.0233218931 ... 0.0158765651 0.0156752672 0.0154734589]\n",
      "KL loss: 0.000271794153 hist_true: [0.0173005946 0.0175639819 0.0178210773 ... 0.0188276675 0.0186008681 0.0183661152] hist_pred: [0.0180389974 0.0182096455 0.0183760412 ... 0.0196990445 0.0195809193 0.0194573011]\n",
      "KL loss: 0.00411880203 hist_true: [0.0171772484 0.0177719872 0.0183537584 ... 0.0124841407 0.0119042024 0.0113331014] hist_pred: [0.0189559851 0.0192934666 0.0196135286 ... 0.0157423113 0.01537525 0.015003521]\n",
      "KL loss: 0.00166713027 hist_true: [0.0170987379 0.0174834281 0.0178587548 ... 0.0164910499 0.0160898045 0.015682796] hist_pred: [0.0184795968 0.0186573807 0.0188298281 ... 0.0187547095 0.0185737237 0.0183866769]\n",
      "KL loss: 0.00436508376 hist_true: [0.0168098453 0.0171264671 0.0174363721 ... 0.0183477178 0.0180594586 0.0177624393] hist_pred: [0.0211841557 0.0212327447 0.0212749485 ... 0.0171079542 0.0169064067 0.0167019218]\n",
      "KL loss: 0.0152076343 hist_true: [0.0102353515 0.0108858636 0.0115548465 ... 0.0162081104 0.0154585894 0.0147088422] hist_pred: [0.0168470964 0.0173103828 0.0177652277 ... 0.015297465 0.0148614738 0.0144268135]\n",
      "KL loss: 0.00137808034 hist_true: [0.0141656306 0.0146263447 0.015085143 ... 0.0184943881 0.0180861615 0.0176660344] hist_pred: [0.0156299397 0.0159421749 0.01625067 ... 0.0204986501 0.0203457884 0.0201846194]\n",
      "KL loss: 0.00203104527 hist_true: [0.0143491374 0.014846121 0.0153404158 ... 0.0174046177 0.0169382952 0.0164630618] hist_pred: [0.0170172937 0.0173040405 0.0175836049 ... 0.0188581422 0.0186210871 0.0183754899]\n",
      "KL loss: 0.00267286366 hist_true: [0.0182264317 0.0186681896 0.0190954152 ... 0.0141003896 0.0136140082 0.0131286979] hist_pred: [0.0196164493 0.0198176205 0.0200092588 ... 0.0169525743 0.0167233534 0.0164943691]\n",
      "KL loss: 0.00633553322 hist_true: [0.00890137255 0.00947488286 0.0100673754 ... 0.0200451463 0.0194035303 0.0187424161] hist_pred: [0.0128394095 0.0133112036 0.0137839569 ... 0.0202225745 0.0198631082 0.0194857772]\n",
      "KL loss: 0.00121727295 hist_true: [0.0139854737 0.0143959383 0.0148050683 ... 0.020160513 0.0198680423 0.019561315] hist_pred: [0.0161822289 0.0164606981 0.016735021 ... 0.0202985276 0.0201429427 0.0199784767]\n",
      "KL loss: 0.00374969235 hist_true: [0.0165796075 0.0169443525 0.0173016805 ... 0.0176167376 0.0172666069 0.016908329] hist_pred: [0.0209629945 0.0210160129 0.0210625064 ... 0.0175549518 0.0173906032 0.0172241293]\n",
      "KL loss: 0.000798494206 hist_true: [0.0167955682 0.017109938 0.0174176283 ... 0.0184534695 0.01817495 0.0178878382] hist_pred: [0.018738959 0.0189095456 0.0190732889 ... 0.0187979937 0.01864543 0.0184885226]\n",
      "KL loss: 0.0122602582 hist_true: [0.00932655 0.00986073166 0.0104096979 ... 0.0214493815 0.020932503 0.0203907304] hist_pred: [0.0146185514 0.0150396135 0.0154558988 ... 0.0197644662 0.0195221025 0.0192706194]\n",
      "KL loss: 0.00232229242 hist_true: [0.0163969435 0.0168726221 0.0173394792 ... 0.0154452519 0.0149555551 0.0144629246] hist_pred: [0.0192574691 0.0194014199 0.0195419639 ... 0.0173529331 0.0170492958 0.0167367905]\n",
      "KL loss: 0.00453889 hist_true: [0.0193703175 0.0196611267 0.0199388396 ... 0.0153445713 0.0149603933 0.0145736588] hist_pred: [0.0185177289 0.018681353 0.0188395083 ... 0.0190730728 0.0189195927 0.0187603272]\n",
      "KL loss: 0.0041682478 hist_true: [0.0177284628 0.0180446133 0.0183515102 ... 0.0170736108 0.0167365689 0.0163931567] hist_pred: [0.0216633342 0.0217711106 0.0218679737 ... 0.0154170189 0.0151211293 0.0148243504]\n",
      "KL loss: 0.00335231703 hist_true: [0.0172247142 0.0176723 0.0181086399 ... 0.0151208024 0.0146494219 0.0141761433] hist_pred: [0.0194147937 0.0195441656 0.0196670927 ... 0.0181233175 0.0179065373 0.017682163]\n",
      "KL loss: 0.00501767825 hist_true: [0.0184997246 0.0190037042 0.0194911305 ... 0.0126799596 0.0121417101 0.0116098709] hist_pred: [0.0187839139 0.0190206878 0.0192513596 ... 0.0162535198 0.0158716552 0.0154845063]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5073 KL loss: 0.00420744345 hist_true: [0.0151501456 0.0156732332 0.0161911 ... 0.0158402454 0.0153195672 0.0147948423] hist_pred: [0.019684203 0.019911157 0.0201265011 ... 0.0159111358 0.01555348 0.0151906852]\n",
      "KL loss: 0.00228519319 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0165249538 0.0170517545 0.0175686553 ... 0.0142941978 0.0137539953 0.0132149793]\n",
      "KL loss: 0.00211070152 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0124936197 0.013021687 0.013552513 ... 0.0189638808 0.0185121838 0.0180474501]\n",
      "KL loss: 0.00180443097 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0187735092 0.0190600436 0.0193355177 ... 0.016191721 0.015836522 0.0154768731]\n",
      "KL loss: 0.000767536345 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0195156932 0.0197800044 0.0200315 ... 0.015782591 0.0154426564 0.015100738]\n",
      "KL loss: 0.00482990686 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0167169329 0.0171604659 0.0175945852 ... 0.0157525223 0.0152927795 0.0148291457]\n",
      "KL loss: 0.00316464761 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.021015171 0.0212142803 0.0213994216 ... 0.014741106 0.0143746091 0.014007]\n",
      "KL loss: 0.000672708731 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0203561988 0.0204016194 0.02044327 ... 0.0185070224 0.0183898583 0.0182702504]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5066 - val_loss: 0.2576\n",
      "Epoch 35/50\n",
      "KL loss: 0.00252006715 hist_true: [0.0215731449 0.0219256654 0.022254657 ... 0.0119218361 0.0114463381 0.0109780906] hist_pred: [0.025760131 0.0257460698 0.025711976 ... 0.012272 0.0119160833 0.0115647204]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1.6945KL loss: 0.00534895761 hist_true: [0.0170911029 0.0174558107 0.0178116225 ... 0.0169325117 0.0165591855 0.0161792133] hist_pred: [0.0224588 0.022438379 0.0224109404 ... 0.016544383 0.0163450148 0.0161432624]\n",
      "KL loss: 0.0221819766 hist_true: [0.00819476694 0.00875977054 0.00934661832 ... 0.0207455736 0.0200972874 0.0194268357] hist_pred: [0.014281244 0.0148208812 0.015359153 ... 0.0174876731 0.0171514768 0.0168183576]\n",
      "KL loss: 0.00104696024 hist_true: [0.016385911 0.0167745799 0.0171557702 ... 0.017374238 0.0170006659 0.0166193079] hist_pred: [0.0183804221 0.0186026655 0.0188164171 ... 0.0184098501 0.0182141811 0.0180131607]\n",
      "KL loss: 0.0121550485 hist_true: [0.0187704079 0.0190576576 0.0193337575 ... 0.016198976 0.0158448871 0.0154863736] hist_pred: [0.0160524268 0.0162575059 0.0164615102 ... 0.0221252032 0.0221108496 0.0220881514]\n",
      "KL loss: 0.000932180323 hist_true: [0.0177025273 0.0180494841 0.0183863956 ... 0.0164492335 0.0160683841 0.0156820156] hist_pred: [0.0195552334 0.0196996722 0.0198379699 ... 0.0176555794 0.0174288265 0.0171968136]\n",
      "KL loss: 0.00352003751 hist_true: [0.0159364883 0.016409656 0.0168754216 ... 0.0160363819 0.0155587457 0.0150762089] hist_pred: [0.0163215678 0.0165999308 0.0168758761 ... 0.0194959734 0.0192585699 0.0190103427]\n",
      "KL loss: 0.00144959963 hist_true: [0.0148560954 0.0152391801 0.0156190302 ... 0.0196348056 0.0193492342 0.0190513097] hist_pred: [0.0173952375 0.0176126417 0.0178260021 ... 0.0194597133 0.0192770362 0.0190858617]\n",
      "KL loss: 0.0212054253 hist_true: [0.0147703607 0.0152995242 0.0158248674 ... 0.0160943735 0.015571095 0.0150430892] hist_pred: [0.0234384034 0.0235883854 0.0237161685 ... 0.0128420554 0.012451048 0.0120632267]\n",
      "KL loss: 0.0202256329 hist_true: [0.00967031438 0.0103522846 0.0110562816 ... 0.0158211049 0.0150323501 0.0142463865] hist_pred: [0.017153129 0.0176449828 0.0181269869 ... 0.0137965772 0.0132356957 0.01267784]\n",
      "KL loss: 0.00275494158 hist_true: [0.0179200843 0.0182094332 0.018489955 ... 0.0173488725 0.0170389973 0.0167226624] hist_pred: [0.0177904833 0.0179351773 0.0180777609 ... 0.0204731878 0.0203940812 0.0203079693]\n",
      "KL loss: 0.00540379342 hist_true: [0.0168126822 0.0172264408 0.01763089 ... 0.0163006503 0.0158785973 0.0154513083] hist_pred: [0.0163001977 0.0165489968 0.0167951491 ... 0.0205675568 0.0204271264 0.0202766135]\n",
      "KL loss: 0.00871358253 hist_true: [0.0151270442 0.0157326367 0.0163335446 ... 0.0140184807 0.013414056 0.0128133725] hist_pred: [0.0155179184 0.0158911534 0.0162581652 ... 0.0194403268 0.0192028601 0.0189569332]\n",
      "\u001b[1m13/25\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6543 KL loss: 0.00739275897 hist_true: [0.0171171091 0.0175973829 0.0180663988 ... 0.014546467 0.0140393665 0.0135322148] hist_pred: [0.0234419033 0.0234883688 0.0235210229 ... 0.0141053097 0.0137906102 0.0134781962]\n",
      "KL loss: 0.00724487752 hist_true: [0.0140089272 0.0145087903 0.0150071094 ... 0.0176768545 0.0172063857 0.0167258214] hist_pred: [0.0191933084 0.019446509 0.0196882 ... 0.016478736 0.0161710884 0.0158596]\n",
      "KL loss: 0.00635289401 hist_true: [0.0153785916 0.0158079248 0.016231833 ... 0.0178090986 0.0174197797 0.0170212146] hist_pred: [0.0200584456 0.0202728026 0.0204748362 ... 0.0160164963 0.0157151353 0.0154119199]\n",
      "KL loss: 0.00228432985 hist_true: [0.0198917817 0.0204118751 0.0209095757 ... 0.0111639081 0.0106209237 0.0100897811] hist_pred: [0.0213666204 0.0215875693 0.0217955373 ... 0.0133292647 0.0128834359 0.0124405054]\n",
      "KL loss: 0.00437343353 hist_true: [0.00970769208 0.0102396412 0.0107849278 ... 0.0212282818 0.0207272284 0.020202646] hist_pred: [0.0131209074 0.0135164782 0.0139129953 ... 0.0220944732 0.0219339449 0.0217595883]\n",
      "KL loss: 0.00128980225 hist_true: [0.0166646317 0.0170775708 0.0174816102 ... 0.0165138375 0.0160985384 0.0156774] hist_pred: [0.0193210598 0.0195071921 0.0196857043 ... 0.0170009062 0.0167028587 0.0163987558]\n",
      "KL loss: 0.00152380485 hist_true: [0.0189775527 0.0192921069 0.0195937809 ... 0.0154454671 0.0150541887 0.0146600874] hist_pred: [0.0200128611 0.0201222096 0.0202260092 ... 0.0176073797 0.0173967704 0.0171821378]\n",
      "KL loss: 0.00249892124 hist_true: [0.0156481676 0.0159644373 0.0162768029 ... 0.0201631747 0.0199638791 0.0197538771] hist_pred: [0.0188595112 0.0189838856 0.019104138 ... 0.0193140265 0.0191961601 0.0190733317]\n",
      "KL loss: 0.00129102124 hist_true: [0.0177562032 0.0181118753 0.018457 ... 0.0162360836 0.0158460252 0.0154510504] hist_pred: [0.0200937223 0.0202348977 0.0203670692 ... 0.0173781924 0.0171802063 0.0169805288]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6472KL loss: 0.00191734266 hist_true: [0.0177041907 0.01803758 0.0183612145 ... 0.0167693719 0.0164121352 0.016049074] hist_pred: [0.020858435 0.020959219 0.0210501589 ... 0.0170723591 0.0168770794 0.0166801661]\n",
      "KL loss: 0.00148555241 hist_true: [0.0181375034 0.0184153132 0.0186840538 ... 0.0172902793 0.0169857983 0.0166751407] hist_pred: [0.0206543524 0.0207849219 0.0209056791 ... 0.0165833756 0.0163355321 0.0160853956]\n",
      "KL loss: 0.0364949182 hist_true: [0.010190906 0.0107177226 0.0112557141 ... 0.021099804 0.0206304826 0.020138938] hist_pred: [0.0210664626 0.0211614594 0.0212415401 ... 0.0176889692 0.0175408218 0.0173868891]\n",
      "KL loss: 0.00141921197 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0165480878 0.0170387719 0.017519949 ... 0.0149793196 0.0144722005 0.0139636816]\n",
      "KL loss: 0.00273879012 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0128588239 0.0133761484 0.0138949389 ... 0.0188417435 0.0184010882 0.0179477967]\n",
      "KL loss: 0.000631380244 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0181740709 0.0184634682 0.0187433418 ... 0.0169801675 0.016654253 0.016322406]\n",
      "KL loss: 0.00057370303 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0194992535 0.0197491441 0.0199868 ... 0.0161033 0.0157866944 0.0154680591]\n",
      "KL loss: 0.00380229624 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0166388713 0.017066218 0.0174845308 ... 0.0162497405 0.0158197768 0.0153849125]\n",
      "KL loss: 0.00317590428 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0211363696 0.0213220175 0.0214939639 ... 0.014812774 0.0144549245 0.0140958941]\n",
      "KL loss: 0.00064637023 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0203440655 0.020388322 0.0204289649 ... 0.0185316149 0.0184149221 0.0182956681]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6378 - val_loss: 0.2296\n",
      "Epoch 36/50\n",
      "KL loss: 0.00598167069 hist_true: [0.014426467 0.0149180964 0.0154065341 ... 0.017532764 0.0170810856 0.0166202579] hist_pred: [0.0147293843 0.014983044 0.0152383437 ... 0.0221423768 0.021997381 0.0218347423]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 1.8805KL loss: 0.0102648698 hist_true: [0.0105520245 0.0111896247 0.0118414499 ... 0.0171365049 0.0164601319 0.0157774296] hist_pred: [0.0163264517 0.0167340953 0.0171368979 ... 0.0165687967 0.0161663257 0.0157626774]\n",
      "KL loss: 0.00113032665 hist_true: [0.0147352163 0.0152069693 0.0156749599 ... 0.0175398048 0.0170987863 0.01664849] hist_pred: [0.0168298166 0.017131811 0.0174287055 ... 0.0184938628 0.0182214919 0.0179412365]\n",
      "KL loss: 0.00371497869 hist_true: [0.0198189113 0.0202056076 0.0205742922 ... 0.0131744593 0.0126939956 0.0122170709] hist_pred: [0.0204156227 0.020563893 0.0207022633 ... 0.0164197981 0.0161320176 0.0158395059]\n",
      "KL loss: 0.000258304295 hist_true: [0.0150617519 0.0154984277 0.0159306135 ... 0.0180105269 0.017618 0.0172155164] hist_pred: [0.0158940554 0.0162673593 0.0166343413 ... 0.0186563674 0.0183683801 0.0180723295]\n",
      "KL loss: 0.00341396593 hist_true: [0.0156818237 0.0162045509 0.0167200118 ... 0.0153818121 0.0148667172 0.0143494084] hist_pred: [0.0165831316 0.0168775991 0.0171681158 ... 0.0186785068 0.0183873568 0.0180863831]\n",
      "KL loss: 0.00821760483 hist_true: [0.0161475297 0.0167912971 0.0174263082 ... 0.0124981347 0.0118870698 0.0112861963] hist_pred: [0.0173507314 0.0176421441 0.0179276615 ... 0.0171349142 0.0167202353 0.0162938517]\n",
      "KL loss: 0.0139509477 hist_true: [0.015642792 0.0160556324 0.0164627358 ... 0.0177782439 0.0173958447 0.0170042273] hist_pred: [0.0219747722 0.0221393667 0.0222883802 ... 0.0142302793 0.0138784982 0.0135279847]\n",
      "KL loss: 0.00381593732 hist_true: [0.016408002 0.0168023724 0.0171891749 ... 0.0171912555 0.0168055575 0.0164123736] hist_pred: [0.0207099114 0.0208205413 0.0209234543 ... 0.0164840128 0.0162110832 0.0159343127]\n",
      "KL loss: 0.00207252335 hist_true: [0.0137332547 0.0142525993 0.0147710899 ... 0.0176058374 0.017122779 0.0166300721] hist_pred: [0.0164980274 0.0168332849 0.0171617493 ... 0.0186561346 0.018393768 0.0181233957]\n",
      "KL loss: 0.00221083919 hist_true: [0.0177734159 0.0181645602 0.0185440965 ... 0.0155241452 0.0150931068 0.0146588534] hist_pred: [0.0214499161 0.0215337276 0.0216107145 ... 0.0155720413 0.0152539825 0.0149332238]\n",
      "KL loss: 0.00506174425 hist_true: [0.0110775298 0.0115874214 0.0121048233 ... 0.0208732039 0.0204526559 0.0200117752] hist_pred: [0.0152509138 0.0154678086 0.0156857949 ... 0.0226444546 0.0225977544 0.0225370675]\n",
      "KL loss: 0.00702333869 hist_true: [0.0164323952 0.0168793593 0.0173177812 ... 0.0160151124 0.0155586889 0.0150976218] hist_pred: [0.0217905454 0.0219495334 0.0220942162 ... 0.0144366361 0.0140861468 0.0137364222]\n",
      "KL loss: 0.01279529 hist_true: [0.00990212429 0.0106789926 0.0114837214 ... 0.0130147012 0.0121856499 0.0113776959] hist_pred: [0.0108455746 0.0114100864 0.0119826747 ... 0.0191426333 0.0185446702 0.0179284606]\n",
      "KL loss: 0.00432302942 hist_true: [0.0182787143 0.0187199228 0.0191464517 ... 0.0140620722 0.0135769211 0.0130930552] hist_pred: [0.0186541136 0.0188787356 0.0190946274 ... 0.0177250821 0.017478697 0.0172268674]\n",
      "KL loss: 0.00126736984 hist_true: [0.0178916156 0.0182330813 0.0185640045 ... 0.0163432322 0.0159652624 0.0155822197] hist_pred: [0.0192154497 0.0193578135 0.0194942169 ... 0.018247718 0.0180471316 0.0178403314]\n",
      "KL loss: 0.00246150931 hist_true: [0.0181720573 0.0184823666 0.0187823717 ... 0.0165837966 0.0162324645 0.0158758368] hist_pred: [0.0215474684 0.0216498096 0.0217409413 ... 0.0159540772 0.0157070477 0.0154600963]\n",
      "KL loss: 0.00531695504 hist_true: [0.0176530965 0.0181105901 0.0185555555 ... 0.0143531812 0.0138550829 0.0133573432] hist_pred: [0.0232966188 0.0232654363 0.0232246388 ... 0.015328994 0.0150565114 0.0147819743]\n",
      "KL loss: 0.0317522511 hist_true: [0.0101090288 0.0106966225 0.0112985549 ... 0.0187887661 0.0181564819 0.0175098572] hist_pred: [0.0193165261 0.0196416825 0.0199519508 ... 0.0148632172 0.0144416327 0.0140169039]\n",
      "KL loss: 0.000918973237 hist_true: [0.0161223728 0.0165163893 0.0169035364 ... 0.0176111013 0.0172418449 0.0168642066] hist_pred: [0.0179302078 0.0181612093 0.0183853582 ... 0.0187091101 0.0185115878 0.0183080062]\n",
      "KL loss: 0.00103264907 hist_true: [0.0171216615 0.0174903292 0.0178500284 ... 0.0167801622 0.0163971949 0.0160078425] hist_pred: [0.0188162606 0.0190113802 0.019198278 ... 0.0182202943 0.018029375 0.0178344138]\n",
      "KL loss: 0.00269866735 hist_true: [0.0165701695 0.0169173293 0.0172575135 ... 0.0180349443 0.0177148152 0.0173861049] hist_pred: [0.0203207 0.0203951038 0.0204642285 ... 0.017839415 0.0176527202 0.0174614806]\n",
      "KL loss: 0.000631819479 hist_true: [0.017168019 0.0174844153 0.0177931469 ... 0.0178462472 0.0175387748 0.0172235128] hist_pred: [0.0182697289 0.0184540339 0.0186327491 ... 0.0191689078 0.0190285072 0.0188839193]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5381  KL loss: 0.000914617092 hist_true: [0.0168840624 0.0171871874 0.0174837224 ... 0.0185766481 0.0183112323 0.0180372447] hist_pred: [0.0189282726 0.0190985445 0.0192617234 ... 0.0185187664 0.0183582492 0.018194532]\n",
      "KL loss: 0.00820476934 hist_true: [0.00916715 0.00980683137 0.0104686711 ... 0.0173875708 0.0166323017 0.0158716645] hist_pred: [0.0140194176 0.0144421142 0.014867492 ... 0.0189397223 0.0185479484 0.0181424543]\n",
      "KL loss: 0.00557130482 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0176649038 0.0181734636 0.0186685938 ... 0.0133767473 0.0128337182 0.012294638]\n",
      "KL loss: 0.00639367243 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0136388028 0.0141690848 0.0146986609 ... 0.0175391901 0.0170563962 0.0165650453]\n",
      "KL loss: 0.00277417176 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0192588698 0.0195304956 0.0197902117 ... 0.0158193037 0.0154587924 0.0150947087]\n",
      "KL loss: 0.00159921753 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0201826971 0.0204197951 0.0206431486 ... 0.0154092 0.0150722554 0.0147345141]\n",
      "KL loss: 0.0101309847 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0180918872 0.0185069703 0.0189089626 ... 0.0146583961 0.0141916042 0.0137240626]\n",
      "KL loss: 0.0060683405 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0220152717 0.022183856 0.0223368276 ... 0.0139331929 0.0135511411 0.0131696835]\n",
      "KL loss: 0.0017955224 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0211203117 0.0211377051 0.021150969 ... 0.0177919883 0.0176453795 0.0174966529]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5351 - val_loss: 0.2512\n",
      "Epoch 37/50\n",
      "KL loss: 0.00372995948 hist_true: [0.0187394954 0.01893856 0.0191301648 ... 0.0179984402 0.01777138 0.0175385829] hist_pred: [0.0225114208 0.0224967413 0.0224757455 ... 0.0162842721 0.0160777494 0.0158706903]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6059KL loss: 0.00813580118 hist_true: [0.0138357561 0.0145112397 0.0151880989 ... 0.0136935562 0.013034408 0.0123825977] hist_pred: [0.0191057827 0.0195924304 0.0200611986 ... 0.0127917277 0.0123310145 0.0118799014]\n",
      "KL loss: 0.00330904126 hist_true: [0.0107596423 0.011321188 0.0118937669 ... 0.0190908052 0.0185182281 0.0179300494] hist_pred: [0.0138222473 0.0141973831 0.0145738041 ... 0.0207918957 0.020523902 0.0202401131]\n",
      "KL loss: 0.000726134051 hist_true: [0.0190416556 0.0193662718 0.0196774416 ... 0.015183962 0.0147805167 0.0143749025] hist_pred: [0.0204594117 0.0206063092 0.0207436625 ... 0.0164066534 0.0161308423 0.0158519894]\n",
      "KL loss: 0.00768316 hist_true: [0.0165181216 0.016913848 0.0173015986 ... 0.017031638 0.0166411083 0.0162434876] hist_pred: [0.022451004 0.0224935878 0.0225238279 ... 0.0160588734 0.0158650614 0.0156730488]\n",
      "KL loss: 0.000985831721 hist_true: [0.0176917333 0.0179704931 0.0182413738 ... 0.0178992841 0.0176183023 0.0173300281] hist_pred: [0.0199006386 0.0200236645 0.020140972 ... 0.0174154323 0.0171769243 0.0169329904]\n",
      "KL loss: 0.00719712488 hist_true: [0.0182997789 0.0186127517 0.0189149454 ... 0.0163598265 0.015999157 0.0156336334] hist_pred: [0.0168032013 0.0169866607 0.0171694029 ... 0.0210292 0.0209428165 0.020847315]\n",
      "KL loss: 0.00439831428 hist_true: [0.0183963683 0.0189515688 0.0194899701 ... 0.0118965311 0.0113290194 0.0107716583] hist_pred: [0.0227114577 0.0230506118 0.023363255 ... 0.0108002266 0.0103054652 0.00982089806]\n",
      "KL loss: 0.00217254763 hist_true: [0.0166257136 0.0169530418 0.0172737855 ... 0.0184035 0.0181128811 0.0178134423] hist_pred: [0.0197411869 0.0198759 0.0200032778 ... 0.0178163555 0.0176206063 0.0174209271]\n",
      "KL loss: 0.0016716792 hist_true: [0.0189611893 0.0191618688 0.0193544514 ... 0.0176187959 0.0173714794 0.0171186738] hist_pred: [0.021639226 0.0216777772 0.0217089746 ... 0.016731713 0.0165293422 0.0163256545]\n",
      "KL loss: 0.0143122589 hist_true: [0.0119428122 0.0124785984 0.0130198281 ... 0.0190299433 0.0185348094 0.0180249196] hist_pred: [0.0189219676 0.0191643424 0.0193946902 ... 0.017624341 0.017412167 0.0171970949]\n",
      "KL loss: 0.000962883933 hist_true: [0.0189706981 0.0193271097 0.0196693353 ... 0.0146724246 0.0142372102 0.0138011035] hist_pred: [0.0212133937 0.0213453546 0.0214672629 ... 0.0155003518 0.0151887 0.0148751838]\n",
      "KL loss: 0.000793362735 hist_true: [0.0171741229 0.0175639335 0.017943874 ... 0.016342612 0.0159380306 0.0155282198] hist_pred: [0.0191270392 0.0193324238 0.0195299108 ... 0.0170930866 0.0168086775 0.016519]\n",
      "KL loss: 0.00422947854 hist_true: [0.0167275127 0.0170891676 0.0174431577 ... 0.0174593367 0.0171043985 0.016741652] hist_pred: [0.0211494677 0.021237243 0.0213156454 ... 0.0167254396 0.0165090449 0.0162907895]\n",
      "KL loss: 0.00380542129 hist_true: [0.017168479 0.0176044796 0.0180297438 ... 0.0153791644 0.0149171967 0.0144524332] hist_pred: [0.0217669923 0.0217978861 0.0218209065 ... 0.0164682753 0.0162200443 0.0159668252]\n",
      "KL loss: 0.00752812624 hist_true: [0.0151829571 0.0156915877 0.0161949955 ... 0.0161270779 0.015623671 0.0151152946] hist_pred: [0.0133613432 0.0137644531 0.0141703691 ... 0.020517502 0.0201957226 0.0198573489]\n",
      "KL loss: 0.00179266918 hist_true: [0.0181457531 0.018726429 0.0192903709 ... 0.011892667 0.0113272909 0.010772517] hist_pred: [0.0211912077 0.0215379652 0.0218619704 ... 0.0126455696 0.0122062527 0.0117733805]\n",
      "KL loss: 0.00176606444 hist_true: [0.0166950133 0.0170714501 0.0174398609 ... 0.0172044542 0.0168318413 0.0164518412] hist_pred: [0.0195232704 0.019724749 0.0199170765 ... 0.0166493449 0.0163467973 0.0160390753]\n",
      "KL loss: 0.00942084752 hist_true: [0.0134060169 0.0139362514 0.0144669143 ... 0.0176101737 0.0171064679 0.016592769] hist_pred: [0.019317003 0.0195804909 0.0198293645 ... 0.0166077632 0.0163125284 0.0160111468]\n",
      "KL loss: 0.00523384288 hist_true: [0.00909385178 0.00970824622 0.010342624 ... 0.018471837 0.0177503973 0.0170162208] hist_pred: [0.0124414014 0.012990756 0.0135435406 ... 0.0192944426 0.01892104 0.01853678]\n",
      "KL loss: 0.00175565155 hist_true: [0.0146030812 0.0150595764 0.015512744 ... 0.0181074813 0.0176984929 0.0172789693] hist_pred: [0.0160211045 0.0163007863 0.0165772121 ... 0.0205110628 0.0203725193 0.0202257428]\n",
      "KL loss: 0.000869057141 hist_true: [0.016237339 0.0165459849 0.0168495569 ... 0.0194180682 0.0191870909 0.0189463273] hist_pred: [0.0171979275 0.0173681695 0.0175357573 ... 0.0211642832 0.0211309511 0.0210915878]\n",
      "KL loss: 0.000964014442 hist_true: [0.0170815233 0.0173525624 0.017617587 ... 0.018996913 0.0187736191 0.018542055] hist_pred: [0.0192714892 0.01938379 0.0194911864 ... 0.0190200973 0.0189041123 0.0187846515]\n",
      "KL loss: 0.00419385079 hist_true: [0.0088127451 0.00947187748 0.0101566128 ... 0.0167653747 0.0159623753 0.015158345] hist_pred: [0.0116984872 0.0123022124 0.0129139815 ... 0.0181356203 0.0176715683 0.017205853]\n",
      "KL loss: 0.00129943388 hist_true: [0.0152326375 0.0157383122 0.0162386987 ... 0.0160980355 0.0155931469 0.0150832413] hist_pred: [0.0175447501 0.0178971309 0.0182401072 ... 0.0167303234 0.0163895916 0.0160461217]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4443 KL loss: 0.000398022064 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0157048348 0.0162158329 0.0167198591 ... 0.0155090084 0.0149959773 0.0144800255]\n",
      "KL loss: 0.000588375377 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0118135735 0.0123352641 0.0128617957 ... 0.0198948495 0.0194624607 0.0190136638]\n",
      "KL loss: 0.000236276654 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0176470801 0.0179569777 0.0182581227 ... 0.0173026938 0.0169775225 0.0166456215]\n",
      "KL loss: 6.97022479e-05 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0186616611 0.018937273 0.0192020275 ... 0.016776612 0.0164726321 0.0161651243]\n",
      "KL loss: 0.00146525656 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0155938454 0.0160437543 0.0164873898 ... 0.0170642287 0.0166387744 0.0162060838]\n",
      "KL loss: 0.00157518045 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0202970523 0.0205140803 0.0207184702 ... 0.0154000362 0.0150500955 0.014697725]\n",
      "KL loss: 0.000725650927 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0203879327 0.0204329733 0.0204742346 ... 0.0184468273 0.018324947 0.0182004813]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4428 - val_loss: 0.1848\n",
      "Epoch 38/50\n",
      "KL loss: 0.00445105648 hist_true: [0.015067379 0.0155389206 0.0160057545 ... 0.0171167925 0.0166640878 0.0162032675] hist_pred: [0.0196646731 0.0198371746 0.0200015157 ... 0.0169416219 0.0166672543 0.0163885057]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.6240KL loss: 0.00758177135 hist_true: [0.015955992 0.0163720157 0.0167812854 ... 0.0173060652 0.0169068035 0.0164994057] hist_pred: [0.0214277934 0.0215460248 0.0216538589 ... 0.0154020749 0.0150827924 0.0147608621]\n",
      "KL loss: 0.00344066694 hist_true: [0.0195236504 0.0199817 0.0204203594 ... 0.0124252951 0.0119096888 0.0114007303] hist_pred: [0.0239468 0.0240980834 0.0242262296 ... 0.0124033522 0.0120266834 0.0116551463]\n",
      "KL loss: 0.0112279058 hist_true: [0.00962198619 0.0102568241 0.0109107876 ... 0.0174419042 0.0167142 0.0159796793] hist_pred: [0.0144260908 0.014860156 0.0152809918 ... 0.0212817509 0.0210547708 0.0208000336]\n",
      "KL loss: 0.000922114588 hist_true: [0.0191759542 0.0194956549 0.0198017452 ... 0.0150754908 0.0146686016 0.0142596681] hist_pred: [0.021474693 0.0215896517 0.0216942355 ... 0.015565048 0.0152826635 0.0150008639]\n",
      "KL loss: 0.00337499031 hist_true: [0.0173608158 0.0176428407 0.0179177336 ... 0.0183320213 0.0180700272 0.0178002603] hist_pred: [0.0212227721 0.0212698877 0.0213096905 ... 0.0173631404 0.0171993226 0.0170343]\n",
      "KL loss: 0.00414058939 hist_true: [0.013857631 0.0142821381 0.01470563 ... 0.0199063923 0.0195844527 0.0192480311] hist_pred: [0.0177345779 0.0179629866 0.018185528 ... 0.0189099349 0.0187130924 0.018509753]\n",
      "KL loss: 0.0040187249 hist_true: [0.0144714443 0.015049208 0.0156243257 ... 0.0153084937 0.0147344442 0.014158952] hist_pred: [0.0185517538 0.0189067088 0.0192523766 ... 0.0147428233 0.0143108629 0.0138815735]\n",
      "KL loss: 0.00127451448 hist_true: [0.0188985486 0.0191987343 0.0194868576 ... 0.0157956444 0.0154217221 0.0150441714] hist_pred: [0.0209184 0.0209753476 0.0210263915 ... 0.0173626412 0.0171707645 0.0169754457]\n",
      "KL loss: 0.000979040284 hist_true: [0.0182578228 0.0185768474 0.0188851189 ... 0.0162675474 0.0158979148 0.0155234672] hist_pred: [0.0189879332 0.0191684645 0.0193418134 ... 0.0180844236 0.017886268 0.0176842902]\n",
      "KL loss: 0.00030960096 hist_true: [0.0203244705 0.0204344 0.0205370039 ... 0.0173121803 0.0170965139 0.0168771725] hist_pred: [0.0216700379 0.0216645431 0.0216543712 ... 0.0174674578 0.0173235219 0.0171788298]\n",
      "KL loss: 0.00247862283 hist_true: [0.0188782271 0.0191740505 0.0194579493 ... 0.0159356445 0.0155712478 0.0152031016] hist_pred: [0.019492412 0.0195821095 0.0196679812 ... 0.0187995099 0.0186480172 0.0184900537]\n",
      "KL loss: 0.00165461376 hist_true: [0.0161532592 0.0165706035 0.0169805456 ... 0.0170502272 0.0166454017 0.0162332803] hist_pred: [0.0165319182 0.016802486 0.0170703139 ... 0.0194721986 0.0192594491 0.0190387703]\n",
      "KL loss: 0.0465239361 hist_true: [0.0101959528 0.0108750444 0.011573324 ... 0.015586352 0.0148129696 0.0140427584] hist_pred: [0.0215729717 0.0219501927 0.0223046 ... 0.0114905396 0.0110197421 0.0105594723]\n",
      "KL loss: 0.00445528794 hist_true: [0.00960885268 0.0101999985 0.0108081894 ... 0.0188311469 0.0181644168 0.0174834281] hist_pred: [0.0104449457 0.0109223481 0.0114070559 ... 0.0231719911 0.0228979439 0.0225996021]\n",
      "KL loss: 0.00736879371 hist_true: [0.0178017262 0.0181046128 0.0183985513 ... 0.0172290187 0.0169052705 0.0165750179] hist_pred: [0.0228914022 0.022929607 0.0229573902 ... 0.0147034274 0.0143882064 0.0140721612]\n",
      "KL loss: 0.001568801 hist_true: [0.0180387925 0.0183614288 0.0186738335 ... 0.0164854508 0.0161206014 0.0157504026] hist_pred: [0.020736428 0.0207801145 0.020818837 ... 0.0177585687 0.0175739434 0.0173839685]\n",
      "KL loss: 0.000506449724 hist_true: [0.018353153 0.0186441317 0.0189249329 ... 0.0167245 0.0163900424 0.0160502139] hist_pred: [0.0201193113 0.0202433299 0.0203618 ... 0.0169741102 0.0167139489 0.0164493751]\n",
      "KL loss: 0.00131724332 hist_true: [0.0181384962 0.018451253 0.0187537465 ... 0.0165664665 0.0162119381 0.0158520639] hist_pred: [0.02076081 0.0208226144 0.0208788272 ... 0.0174555592 0.0172641352 0.0170694049]\n",
      "KL loss: 0.00285719894 hist_true: [0.0171180479 0.0174800418 0.0178331602 ... 0.0169420373 0.0165696833 0.0161906127] hist_pred: [0.0195845477 0.0196304154 0.0196739081 ... 0.0196636226 0.0195885189 0.0195074752]\n",
      "KL loss: 0.00624827854 hist_true: [0.0100106448 0.0105360206 0.0110730482 ... 0.0213836 0.0209240243 0.0204413459] hist_pred: [0.0144007429 0.0147289168 0.0150544215 ... 0.0218913946 0.0217501316 0.0215933286]\n",
      "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4811 KL loss: 0.006969098 hist_true: [0.0181406774 0.0184018631 0.0186546575 ... 0.0176081378 0.0173257831 0.017036967] hist_pred: [0.0231229234 0.0231247507 0.0231168196 ... 0.0151873231 0.0149237029 0.0146600483]\n",
      "KL loss: 0.00537242 hist_true: [0.0153045664 0.0158094224 0.0163085423 ... 0.0161101241 0.0156121049 0.0151091591] hist_pred: [0.0203743968 0.0205436405 0.0206982773 ... 0.0167346727 0.0164749566 0.0162095204]\n",
      "KL loss: 0.00527709909 hist_true: [0.0200345032 0.0203078315 0.0205667056 ... 0.014796841 0.0144034503 0.0140087744] hist_pred: [0.0196009167 0.0197033975 0.0197990369 ... 0.0189289283 0.0188161545 0.0186989866]\n",
      "KL loss: 0.00323145604 hist_true: [0.018856233 0.0193689428 0.0198638905 ... 0.0121250777 0.011576538 0.0110365627] hist_pred: [0.0227117315 0.0228650775 0.0230003875 ... 0.0138005139 0.0134753492 0.0131551297]\n",
      "KL loss: 0.000181494077 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0140025532 0.0145664718 0.0151289934 ... 0.0161742549 0.0156227695 0.0150665194]\n",
      "KL loss: 0.000327530317 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0102967387 0.0108224386 0.0113579202 ... 0.0214944277 0.0210828129 0.0206498411]\n",
      "KL loss: 4.07737971e-05 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0166780464 0.0170234535 0.0173616204 ... 0.0179356616 0.0176144261 0.0172849577]\n",
      "KL loss: 0.000551442383 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0171420518 0.0174760725 0.0178016257 ... 0.0176675823 0.0173593 0.0170448795]\n",
      "KL loss: 0.000517748529 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0147030903 0.0151822641 0.0156576168 ... 0.017448796 0.0170032904 0.0165489502]\n",
      "KL loss: 4.75046691e-05 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0184976626 0.0187881868 0.0190683231 ... 0.0164871681 0.0161404014 0.0157885626]\n",
      "KL loss: 0.000331286108 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0198925901 0.0199630037 0.0200294815 ... 0.0187604167 0.0186445396 0.018525606]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4772 - val_loss: 0.2021\n",
      "Epoch 39/50\n",
      "KL loss: 0.000586873386 hist_true: [0.0176154505 0.0180030651 0.0183797125 ... 0.0157713704 0.015347315 0.0149193248] hist_pred: [0.0187916756 0.019026557 0.0192536041 ... 0.0169256497 0.0166183561 0.0163064077]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1240KL loss: 0.000941449543 hist_true: [0.0179823525 0.0183087103 0.0186247751 ... 0.0165206157 0.0161576755 0.0157894213] hist_pred: [0.0200456697 0.020190075 0.0203252304 ... 0.0173723903 0.0171665438 0.0169580914]\n",
      "KL loss: 0.00201608567 hist_true: [0.0116560208 0.0122203752 0.012792551 ... 0.0181567445 0.0175801143 0.0169912633] hist_pred: [0.0133848106 0.0138257 0.0142665254 ... 0.0204339661 0.0201567281 0.0198676679]\n",
      "KL loss: 0.00367196626 hist_true: [0.0163685977 0.0167808514 0.0171853397 ... 0.0168319289 0.0164204556 0.0160021335] hist_pred: [0.0207505133 0.0208393503 0.0209203679 ... 0.0171133429 0.0168980397 0.0166791603]\n",
      "KL loss: 0.00516173197 hist_true: [0.0160629489 0.0168111064 0.0175518114 ... 0.0107708024 0.0101245297 0.00949792098] hist_pred: [0.0191245228 0.0195163563 0.019891385 ... 0.0137579208 0.0132476101 0.0127367666]\n",
      "KL loss: 0.000537538202 hist_true: [0.0182758532 0.0185266212 0.0187690072 ... 0.0176284667 0.0173533075 0.0170718152] hist_pred: [0.0193436258 0.0194657836 0.0195821114 ... 0.0188246574 0.0187043268 0.0185814165]\n",
      "KL loss: 0.00101380423 hist_true: [0.016120052 0.0164957307 0.0168650299 ... 0.017998036 0.0176535733 0.0173000135] hist_pred: [0.017227916 0.0174473524 0.0176631883 ... 0.0198072456 0.0196584035 0.0195023958]\n",
      "KL loss: 0.00130767236 hist_true: [0.0168493725 0.0171799865 0.0175033063 ... 0.0180091839 0.0176998768 0.0173823144] hist_pred: [0.0171983931 0.0173793975 0.0175601151 ... 0.0201403014 0.0199880134 0.0198259186]\n",
      "KL loss: 0.00250220532 hist_true: [0.0151377218 0.0156686772 0.0161944721 ... 0.0156342853 0.0150990039 0.0145602059] hist_pred: [0.018367555 0.0186406951 0.0189053845 ... 0.0169440825 0.0166480057 0.0163504854]\n",
      "KL loss: 0.00238288357 hist_true: [0.0192011911 0.0196288 0.0200391319 ... 0.0132118138 0.0127149206 0.0122217471] hist_pred: [0.0231366847 0.0232136548 0.0232773479 ... 0.0136903487 0.0133197289 0.0129501317]\n",
      "KL loss: 0.000498716254 hist_true: [0.0189220253 0.0191275179 0.0193248019 ... 0.0175846312 0.0173333064 0.0170764774] hist_pred: [0.020509 0.0205552336 0.0205972642 ... 0.0182124544 0.0180745944 0.0179339219]\n",
      "KL loss: 0.000534845749 hist_true: [0.0173445176 0.0176269058 0.0179022625 ... 0.0183302891 0.0180665553 0.0177949648] hist_pred: [0.0178032219 0.0179840848 0.0181610063 ... 0.0197154637 0.0195759404 0.0194289889]\n",
      "KL loss: 0.00098604348 hist_true: [0.0196610652 0.0198888984 0.0201054458 ... 0.0160875041 0.0157595184 0.0154278139] hist_pred: [0.0220775232 0.0221075863 0.0221294072 ... 0.0162251368 0.0159986708 0.0157708935]\n",
      "KL loss: 0.0105176987 hist_true: [0.0136223286 0.0141875567 0.0147526944 ... 0.0165758133 0.0160312597 0.0154807568] hist_pred: [0.020136822 0.0203779303 0.0206037611 ... 0.0154724084 0.0151215149 0.0147673357]\n",
      "KL loss: 0.000445379643 hist_true: [0.0189212635 0.0191508383 0.0193711352 ... 0.0171103477 0.0168243758 0.0165330935] hist_pred: [0.0194195267 0.0195490271 0.0196724962 ... 0.0183329731 0.0181577802 0.0179775767]\n",
      "KL loss: 0.000939909834 hist_true: [0.0186252594 0.0190899801 0.0195384305 ... 0.0132289967 0.0127160391 0.0122071449] hist_pred: [0.0185551476 0.0189269986 0.0192868374 ... 0.0147782154 0.0143406363 0.0139032649]\n",
      "KL loss: 0.00160878804 hist_true: [0.0152116762 0.0155861471 0.0159565769 ... 0.0193405747 0.0190510526 0.0187499374] hist_pred: [0.0177931339 0.0180151016 0.0182315391 ... 0.0188874323 0.0186868757 0.0184793361]\n",
      "KL loss: 0.00819928385 hist_true: [0.0170829073 0.0175005831 0.0179081224 ... 0.015864281 0.015426686 0.0149849616] hist_pred: [0.0156535562 0.0159189589 0.0161840916 ... 0.0208024289 0.0206384901 0.020463299]\n",
      "KL loss: 0.00223288219 hist_true: [0.0127516678 0.013266339 0.0137833226 ... 0.0188200474 0.0183599666 0.0178862642] hist_pred: [0.0142215984 0.0145631395 0.0149039878 ... 0.0215779897 0.0214131735 0.0212346241]\n",
      "KL loss: 0.00171311526 hist_true: [0.0179873332 0.0183767062 0.0187537801 ... 0.0153135993 0.0148794185 0.0144426059] hist_pred: [0.0191257652 0.0193293635 0.0195237752 ... 0.0176300928 0.0174051635 0.0171754882]\n",
      "KL loss: 0.0244911443 hist_true: [0.00872346107 0.00931073725 0.00991885457 ... 0.0195355173 0.0188526195 0.0181529466] hist_pred: [0.0174470488 0.0177164953 0.0179753229 ... 0.0183019713 0.0179809928 0.0176461842]\n",
      "KL loss: 0.0074085528 hist_true: [0.0150131062 0.0154543612 0.0158912651 ... 0.0179496333 0.0175500866 0.0171406344] hist_pred: [0.0206079502 0.0207392946 0.0208594017 ... 0.0169458073 0.0167254955 0.0165018737]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3461 KL loss: 0.000739849522 hist_true: [0.0188624747 0.0191601142 0.0194459185 ... 0.0158919562 0.0155230165 0.0151503347] hist_pred: [0.0209102128 0.0210454203 0.0211701673 ... 0.0160401855 0.0157584 0.0154743576]\n",
      "KL loss: 0.00243136473 hist_true: [0.0143397255 0.0148547692 0.0153671857 ... 0.016968932 0.0164762624 0.015975995] hist_pred: [0.0167833082 0.017035421 0.0172849596 ... 0.0192325376 0.0189815667 0.0187191162]\n",
      "KL loss: 0.00218087179 hist_true: [0.0119572021 0.012580459 0.0132110789 ... 0.0166062284 0.0159823634 0.0153533854] hist_pred: [0.0146273552 0.015038278 0.015449903 ... 0.0180694796 0.0176078752 0.0171325244]\n",
      "KL loss: 0.00728447083 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0183766633 0.0188549981 0.0193179 ... 0.0131850252 0.0126584945 0.0121362051]\n",
      "KL loss: 0.00865212362 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.014275291 0.01479223 0.0153063014 ... 0.017164249 0.0166896079 0.0162074827]\n",
      "KL loss: 0.00358216651 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0196860451 0.0199375711 0.0201767571 ... 0.0156048639 0.0152457152 0.0148834791]\n",
      "KL loss: 0.00296002766 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0209085122 0.0211193413 0.0213153809 ... 0.0149035277 0.0145605095 0.0142178098]\n",
      "KL loss: 0.011305836 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0184549522 0.0188545138 0.0192401521 ... 0.0145379612 0.0140789887 0.0136196436]\n",
      "KL loss: 0.00777876284 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0226628259 0.0227971077 0.0229154415 ... 0.0136518115 0.0132740308 0.0128975166]\n",
      "KL loss: 0.00162495021 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0210423619 0.0210609045 0.0210754797 ... 0.0178920627 0.0177503917 0.0176065713]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3569 - val_loss: 0.2503\n",
      "Epoch 40/50\n",
      "KL loss: 0.00353922555 hist_true: [0.0157584026 0.016196683 0.0166284 ... 0.0170393754 0.0166119412 0.0161766279] hist_pred: [0.0199047402 0.0200718436 0.0202289931 ... 0.0168683194 0.016587168 0.0162995867]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.9333KL loss: 0.00617612479 hist_true: [0.0145785492 0.0150679117 0.0155540211 ... 0.0172808822 0.0168162528 0.0163430441] hist_pred: [0.0195548236 0.0197849553 0.020003777 ... 0.0164409019 0.0161505155 0.0158573464]\n",
      "KL loss: 0.000675939489 hist_true: [0.0177286807 0.018108394 0.0184768308 ... 0.0158320665 0.015418184 0.0150003321] hist_pred: [0.0193760786 0.0195671637 0.0197503623 ... 0.0167887527 0.016471887 0.0161481239]\n",
      "KL loss: 0.00566979498 hist_true: [0.015880134 0.0164862983 0.0170847457 ... 0.0133782038 0.012781 0.0121897832] hist_pred: [0.0212005358 0.0214581396 0.0216938946 ... 0.0141261248 0.013716788 0.0133041283]\n",
      "KL loss: 0.00293928897 hist_true: [0.0157490335 0.0162356887 0.0167154279 ... 0.015976226 0.0154893277 0.0149979079] hist_pred: [0.0195729844 0.0197558887 0.0199300759 ... 0.0168730561 0.0165851749 0.0162922274]\n",
      "KL loss: 0.00400948431 hist_true: [0.0164017025 0.0169106405 0.0174102671 ... 0.0147774471 0.014254896 0.013731732] hist_pred: [0.0207974706 0.0210111234 0.0212080758 ... 0.0154677983 0.0151739661 0.0148801561]\n",
      "KL loss: 0.00152738811 hist_true: [0.016224321 0.0166036319 0.0169761442 ... 0.0177864 0.0174323767 0.0170696657] hist_pred: [0.0165785 0.016812114 0.0170440339 ... 0.0201080572 0.0199266374 0.0197342429]\n",
      "KL loss: 0.000978752505 hist_true: [0.0167398583 0.0170908738 0.0174343642 ... 0.017703468 0.0173668358 0.0170221142] hist_pred: [0.0188079011 0.0189640075 0.0191148315 ... 0.0186572094 0.0184790846 0.0182950217]\n",
      "KL loss: 0.00178281218 hist_true: [0.014223136 0.0146720987 0.0151188476 ... 0.0187904499 0.0184081085 0.0180134848] hist_pred: [0.0142447129 0.0145896 0.0149346367 ... 0.0214596875 0.0213071648 0.0211441889]\n",
      "KL loss: 0.00153720612 hist_true: [0.0176555049 0.0179898646 0.018314654 ... 0.0167907663 0.0164317228 0.0160666909] hist_pred: [0.018777892 0.0189282782 0.0190729517 ... 0.0190503411 0.0189119522 0.018768359]\n",
      "KL loss: 0.00143845333 hist_true: [0.0180804022 0.018422097 0.0187526364 ... 0.0161152445 0.0157320183 0.0153443711] hist_pred: [0.0184212439 0.0186168291 0.0188069027 ... 0.0182710364 0.0180353615 0.0177919269]\n",
      "KL loss: 0.000818405417 hist_true: [0.0177416038 0.0180674344 0.0183836 ... 0.0168858245 0.0165385045 0.0161852557] hist_pred: [0.0199449807 0.020061465 0.0201729536 ... 0.017312767 0.0170602687 0.0168018248]\n",
      "KL loss: 0.0124158133 hist_true: [0.0155356918 0.0162818506 0.0170225035 ... 0.0113471346 0.0107044056 0.0100789703] hist_pred: [0.0232976861 0.0233998559 0.0234782845 ... 0.0139525793 0.013555673 0.0131518729]\n",
      "KL loss: 0.000622013351 hist_true: [0.0184556 0.0187523272 0.0190385189 ... 0.0164383762 0.0160876773 0.0157320332] hist_pred: [0.0192744341 0.0194344968 0.0195882227 ... 0.0178114735 0.017588377 0.0173602048]\n",
      "\u001b[1m14/25\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4489 KL loss: 0.00219637575 hist_true: [0.018143693 0.0185235888 0.0188911706 ... 0.0152506987 0.0148168867 0.0143805565] hist_pred: [0.0195661783 0.0197225306 0.0198706202 ... 0.0178537201 0.0176665187 0.0174762495]\n",
      "KL loss: 0.00188335509 hist_true: [0.0162007436 0.0165422577 0.0168779064 ... 0.0186948813 0.0184056163 0.0181066953] hist_pred: [0.0187864713 0.018996384 0.01919844 ... 0.0176322293 0.0173741393 0.0171098355]\n",
      "KL loss: 0.00471727829 hist_true: [0.00987582933 0.0106008276 0.0113498634 ... 0.0144337276 0.013622201 0.0128222471] hist_pred: [0.012839918 0.0134558911 0.0140758939 ... 0.0169118401 0.0164611731 0.016011849]\n",
      "KL loss: 0.00170888985 hist_true: [0.0168395471 0.0172566809 0.0176645145 ... 0.0161374547 0.0157032926 0.015264051] hist_pred: [0.016795788 0.0170879066 0.0173757952 ... 0.0184348226 0.0181355774 0.0178268012]\n",
      "KL loss: 0.0068152356 hist_true: [0.0103863506 0.010913305 0.0114514949 ... 0.0205532722 0.0200448204 0.0195150673] hist_pred: [0.0148899779 0.015241012 0.0155892633 ... 0.0204035025 0.0201925933 0.0199715551]\n",
      "KL loss: 0.0104092099 hist_true: [0.0129878987 0.0135355154 0.014085249 ... 0.0175717957 0.0170438699 0.0165060777] hist_pred: [0.0127939116 0.013125211 0.0134583255 ... 0.0238870755 0.0238072779 0.0237083677]\n",
      "KL loss: 0.00356727187 hist_true: [0.0167670306 0.0172058959 0.0176352225 ... 0.0158047397 0.0153507199 0.0148926945] hist_pred: [0.0209387764 0.0211084299 0.0212631561 ... 0.0159822833 0.0157153811 0.0154464692]\n",
      "KL loss: 0.0158779081 hist_true: [0.00973827671 0.0103238616 0.010924818 ... 0.0193804782 0.0187701155 0.0181433819] hist_pred: [0.0166428555 0.0169945974 0.0173362959 ... 0.0181250609 0.0177894682 0.0174412299]\n",
      "KL loss: 0.00732795056 hist_true: [0.0195593238 0.0199642889 0.0203515328 ... 0.0131620364 0.0126726227 0.0121868756] hist_pred: [0.0190101061 0.01918591 0.0193556 ... 0.0176339559 0.0173660591 0.0170908645]\n",
      "KL loss: 0.000642499188 hist_true: [0.0190845858 0.0193533991 0.0196109191 ... 0.0161071345 0.0157586131 0.0154059567] hist_pred: [0.0208826568 0.020963192 0.0210370161 ... 0.0168631449 0.0166284796 0.0163902808]\n",
      "KL loss: 0.000749079278 hist_true: [0.0189348646 0.019177828 0.0194109511 ... 0.0168215577 0.0165154859 0.0162043367] hist_pred: [0.020892052 0.0209436677 0.0209895205 ... 0.0175540429 0.0173812136 0.0172058865]\n",
      "KL loss: 0.00676944107 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0190211516 0.0194217842 0.0198065694 ... 0.0138999429 0.0134308431 0.0129632568]\n",
      "KL loss: 0.011008475 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0150194522 0.0155073209 0.0159901176 ... 0.0169203058 0.0164596122 0.015991684]\n",
      "KL loss: 0.00381970452 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0201004557 0.0203129947 0.0205136836 ... 0.0157448 0.0154093662 0.0150708398]\n",
      "KL loss: 0.00320189819 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0213925373 0.0215518028 0.0216973051 ... 0.0151360845 0.0148237487 0.0145115461]\n",
      "KL loss: 0.009609689 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0184358209 0.0188091081 0.0191692188 ... 0.0150899086 0.0146638332 0.0142362099]\n",
      "KL loss: 0.00799385924 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0230918936 0.0231787581 0.0232509766 ... 0.0138271507 0.0134724192 0.0131187318]\n",
      "KL loss: 0.00191820646 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0213756282 0.0213668756 0.0213549156 ... 0.017865723 0.0177349951 0.017602643]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4709 - val_loss: 0.2891\n",
      "Epoch 41/50\n",
      "KL loss: 0.00132229342 hist_true: [0.0154007049 0.0158732701 0.0163401254 ... 0.0166962985 0.0162345 0.0157659389] hist_pred: [0.0174011402 0.0176437218 0.0178833436 ... 0.0182562787 0.0179617256 0.0176586471]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.0631KL loss: 0.000982469879 hist_true: [0.0177766625 0.018151639 0.0185154229 ... 0.0158356279 0.0154223768 0.0150050903] hist_pred: [0.0192815289 0.0194564927 0.0196244754 ... 0.0173366684 0.0170661937 0.0167897418]\n",
      "KL loss: 0.0309140086 hist_true: [0.0150427958 0.0155315017 0.0160154551 ... 0.0167657435 0.0162932202 0.0158137642] hist_pred: [0.0254968684 0.0254956745 0.0254759099 ... 0.012402392 0.012063534 0.0117311087]\n",
      "KL loss: 0.00385019463 hist_true: [0.016359482 0.016947547 0.0175260026 ... 0.013314316 0.0127336364 0.0121588381] hist_pred: [0.0177299883 0.0180307291 0.0183251202 ... 0.0164589789 0.0160332732 0.0155996736]\n",
      "KL loss: 0.0019311267 hist_true: [0.0128074083 0.0132864257 0.0137671735 ... 0.0198193789 0.0194332 0.0190313254] hist_pred: [0.0152878873 0.0155717749 0.0158532672 ... 0.0213255752 0.0211760718 0.0210118666]\n",
      "KL loss: 0.00857796147 hist_true: [0.0197190102 0.0200549029 0.0203747731 ... 0.0141451657 0.0137073556 0.0132699646] hist_pred: [0.0260830969 0.0260198358 0.025941411 ... 0.012313039 0.0119787538 0.0116511211]\n",
      "KL loss: 0.00801212341 hist_true: [0.0136279194 0.0140895378 0.014550576 ... 0.0192318484 0.0188491307 0.0184527263] hist_pred: [0.0185766295 0.018833464 0.0190811362 ... 0.0169362929 0.0166137274 0.0162846204]\n",
      "KL loss: 0.008657258 hist_true: [0.0118008647 0.0125146322 0.0132402619 ... 0.014296351 0.0135815563 0.0128744598] hist_pred: [0.0172114056 0.0177156143 0.0182086546 ... 0.0147515191 0.0143371476 0.0139260758]\n",
      "KL loss: 0.00133128511 hist_true: [0.0173218921 0.0176997297 0.0180677734 ... 0.0163323432 0.015930118 0.0155225815] hist_pred: [0.0200793073 0.0201925095 0.0203010645 ... 0.0170115344 0.0167375561 0.016457824]\n",
      "KL loss: 0.00943767745 hist_true: [0.0136836227 0.0141769722 0.0146697145 ... 0.0182523448 0.017802503 0.017340878] hist_pred: [0.0194979161 0.019729482 0.0199480262 ... 0.0168398954 0.0165850762 0.0163275413]\n",
      "KL loss: 0.0013349629 hist_true: [0.0170410499 0.0173814259 0.0177137144 ... 0.0175238829 0.0171887539 0.0168461073] hist_pred: [0.0185231399 0.0186539497 0.0187821351 ... 0.0194956362 0.0193682425 0.019234404]\n",
      "KL loss: 0.00305309612 hist_true: [0.0177528989 0.018163193 0.018561542 ... 0.0151608754 0.0147081017 0.0142530743] hist_pred: [0.0181918 0.0184065681 0.0186157022 ... 0.0183277167 0.0181043353 0.0178754814]\n",
      "KL loss: 0.00380962389 hist_true: [0.0163496174 0.0169307496 0.0175022874 ... 0.0134233525 0.0128427707 0.0122673744] hist_pred: [0.0179017782 0.0182149783 0.0185177047 ... 0.0166143067 0.0162275396 0.0158338882]\n",
      "KL loss: 0.00482969824 hist_true: [0.010666132 0.0112722414 0.0118908631 ... 0.0179659408 0.0173345115 0.0166927464] hist_pred: [0.0137524521 0.0141272619 0.0145007186 ... 0.0210904386 0.020813141 0.0205162354]\n",
      "KL loss: 0.00189480418 hist_true: [0.0163194612 0.0166797582 0.0170335565 ... 0.0180412382 0.0177069847 0.0173636172] hist_pred: [0.0188210793 0.0189512633 0.0190749653 ... 0.0197692029 0.0197016262 0.019629905]\n",
      "KL loss: 0.00182621647 hist_true: [0.0171743203 0.0175309498 0.0178786404 ... 0.0170016941 0.016637193 0.0162660573] hist_pred: [0.0181066617 0.0182874799 0.018462576 ... 0.019547021 0.0194219146 0.0192910153]\n",
      "KL loss: 0.00211039698 hist_true: [0.0164990537 0.0169247035 0.0173420385 ... 0.0163611788 0.0159264319 0.0154860439] hist_pred: [0.0197438747 0.0199482571 0.0201425925 ... 0.0163496509 0.0160431452 0.0157330483]\n",
      "KL loss: 0.00817372277 hist_true: [0.00911616068 0.00963996351 0.0101789217 ... 0.0220614243 0.0215754751 0.0210628416] hist_pred: [0.0131885726 0.0136567224 0.0141227124 ... 0.0206944346 0.0204292964 0.0201485269]\n",
      "KL loss: 0.00235408871 hist_true: [0.0194854271 0.0197903886 0.0200813152 ... 0.0149501562 0.0145471971 0.0141425543] hist_pred: [0.0191868376 0.019367123 0.0195402093 ... 0.0176192634 0.0173828788 0.0171417017]\n",
      "KL loss: 0.000817751745 hist_true: [0.015871482 0.0162619688 0.0166464243 ... 0.0180121902 0.0176580083 0.0172945447] hist_pred: [0.0178163592 0.0180707648 0.0183184091 ... 0.0182174295 0.0179745052 0.0177257452]\n",
      "KL loss: 0.000437258655 hist_true: [0.0184356123 0.0186311509 0.0188201889 ... 0.0185390916 0.0183412544 0.0181373451] hist_pred: [0.0199639145 0.0200424213 0.0201161411 ... 0.0185297858 0.0183994081 0.0182659831]\n",
      "KL loss: 0.0121401111 hist_true: [0.0164659284 0.0168305282 0.0171880275 ... 0.0177823771 0.0174393393 0.017087888] hist_pred: [0.0235200748 0.0234981831 0.0234645791 ... 0.0154868411 0.0152774509 0.0150695527]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3597 KL loss: 0.0144062117 hist_true: [0.0095672328 0.0103481766 0.0111596743 ... 0.0131493593 0.0123274298 0.011526539] hist_pred: [0.015795216 0.016484756 0.0171649754 ... 0.0119993361 0.011361042 0.0107380906]\n",
      "KL loss: 0.00493761664 hist_true: [0.0167256705 0.0170602929 0.017387934 ... 0.0180694982 0.0177578032 0.0174375735] hist_pred: [0.0213245209 0.0213889778 0.0214452241 ... 0.0168318544 0.0166298524 0.0164264794]\n",
      "KL loss: 0.00472645974 hist_true: [0.0153665431 0.015763076 0.0161547568 ... 0.0185601898 0.0182180144 0.017864937] hist_pred: [0.0201593172 0.0202307515 0.0202974249 ... 0.0180792399 0.0179035626 0.0177237075]\n",
      "KL loss: 0.00715402234 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.018075807 0.0185787231 0.0190669168 ... 0.0130368164 0.0124931047 0.011954423]\n",
      "KL loss: 0.0055220928 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0133985961 0.0139309559 0.0144634377 ... 0.0177072473 0.0172169618 0.0167169087]\n",
      "KL loss: 0.0045829732 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0198919345 0.0201491192 0.0203931555 ... 0.0152169736 0.0148408916 0.0144624831]\n",
      "KL loss: 0.00220045028 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0204970632 0.0207256414 0.0209398754 ... 0.0151349753 0.0147902817 0.0144450553]\n",
      "KL loss: 0.00862265471 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0176811162 0.0181092527 0.0185253397 ... 0.014884471 0.0144137954 0.0139416968]\n",
      "KL loss: 0.00635948498 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0221795756 0.0223366171 0.0224780962 ... 0.0139114521 0.0135335587 0.0131563451]\n",
      "KL loss: 0.00208947202 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0212749038 0.0212866571 0.0212942064 ... 0.0176473185 0.0174947977 0.0173402317]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3696 - val_loss: 0.2080\n",
      "Epoch 42/50\n",
      "KL loss: 0.00200921809 hist_true: [0.0181163121 0.0184095893 0.0186932441 ... 0.017019419 0.0166958217 0.0163663458] hist_pred: [0.0213841554 0.021441197 0.0214911792 ... 0.0166023858 0.0163718294 0.0161389429]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7955KL loss: 0.0357433483 hist_true: [0.0103684925 0.0109570306 0.0115588624 ... 0.0185873676 0.0179622937 0.0173238292] hist_pred: [0.0190660302 0.0194598362 0.0198427513 ... 0.0129828118 0.012449624 0.0119221937]\n",
      "KL loss: 0.00109195895 hist_true: [0.0173356887 0.0177908465 0.0182344895 ... 0.0147677651 0.014278492 0.0137882456] hist_pred: [0.0182569586 0.0185688436 0.0188705642 ... 0.0165669862 0.0162302293 0.0158889424]\n",
      "KL loss: 0.0239201337 hist_true: [0.00977173168 0.0103729703 0.0109904977 ... 0.0186691321 0.0180163085 0.0173502155] hist_pred: [0.017969707 0.0183291454 0.0186762232 ... 0.0164171513 0.0160833802 0.0157473199]\n",
      "KL loss: 0.000762149924 hist_true: [0.016049007 0.0163822416 0.0167101827 ... 0.0191213433 0.0188577473 0.01858408] hist_pred: [0.0176751297 0.0178463608 0.0180141646 ... 0.0202155933 0.0201167464 0.0200111549]\n",
      "KL loss: 0.0131463185 hist_true: [0.0132268 0.0137473615 0.0142686218 ... 0.0181729458 0.0176997725 0.01721517] hist_pred: [0.0201592296 0.0203495156 0.0205283891 ... 0.0161100961 0.0158020165 0.015490545]\n",
      "KL loss: 0.0112570645 hist_true: [0.0177814346 0.0183926802 0.0189890452 ... 0.0115490193 0.0109569533 0.0103776064] hist_pred: [0.0186742712 0.0189020969 0.0191220436 ... 0.0170109849 0.0166733526 0.0163275637]\n",
      "KL loss: 0.00595999 hist_true: [0.0173360687 0.0177397802 0.0181328878 ... 0.0158389397 0.0154107129 0.0149785373] hist_pred: [0.0153718395 0.0157176293 0.0160606094 ... 0.0197504815 0.0195141565 0.0192685351]\n",
      "KL loss: 0.0456865728 hist_true: [0.00981533062 0.010502385 0.0112113506 ... 0.0154520152 0.0146548571 0.0138626937] hist_pred: [0.0203338172 0.0208477117 0.0213374048 ... 0.011522878 0.0110773621 0.0106455339]\n",
      "KL loss: 0.00123605039 hist_true: [0.0166200642 0.0169328488 0.0172394458 ... 0.018745739 0.0184805468 0.0182062946] hist_pred: [0.0173707344 0.0175476745 0.0177206378 ... 0.0209361948 0.0209021438 0.0208632201]\n",
      "KL loss: 0.000967379659 hist_true: [0.0176471658 0.0178948957 0.0181360412 ... 0.0186352637 0.0184091032 0.0181755368] hist_pred: [0.0178800728 0.0180147626 0.0181478355 ... 0.0205418486 0.0204767901 0.0204056352]\n",
      "KL loss: 0.000354582909 hist_true: [0.0189248081 0.0191133339 0.0192944165 ... 0.0179191455 0.0176932607 0.0174618587] hist_pred: [0.0197868198 0.0198591333 0.0199276544 ... 0.0189055763 0.0187983662 0.0186882094]\n",
      "KL loss: 0.000336678 hist_true: [0.0190264732 0.0192208 0.0194071177 ... 0.0176559258 0.017414527 0.0171677675] hist_pred: [0.0202577263 0.0203231126 0.0203837883 ... 0.018280182 0.018139245 0.0179952309]\n",
      "KL loss: 0.0113231903 hist_true: [0.00940160453 0.00993434247 0.0104818512 ... 0.0213417914 0.0208224393 0.020278791] hist_pred: [0.0147364782 0.0151252784 0.015509936 ... 0.0202032235 0.0199766401 0.0197379757]\n",
      "KL loss: 0.00110609224 hist_true: [0.0151174143 0.0155151971 0.0159088206 ... 0.0188797154 0.0185493138 0.0182074644] hist_pred: [0.0171964206 0.0174363386 0.0176703371 ... 0.0197416488 0.0195924211 0.0194359049]\n",
      "KL loss: 0.00259403791 hist_true: [0.0182098113 0.0185235776 0.0188268665 ... 0.0164458416 0.0160863902 0.0157218352] hist_pred: [0.0178018622 0.018009074 0.0182104129 ... 0.01939594 0.0192405339 0.0190782174]\n",
      "KL loss: 0.000680261757 hist_true: [0.0191414207 0.0193445645 0.0195390172 ... 0.0173027497 0.0170394108 0.0167709216] hist_pred: [0.0204664469 0.0204944015 0.020519359 ... 0.0185826216 0.0184668396 0.01834758]\n",
      "KL loss: 0.000590961194 hist_true: [0.0173177663 0.0177790448 0.0182285327 ... 0.0147408443 0.0142533146 0.0137650929] hist_pred: [0.0183840171 0.0187093448 0.0190249123 ... 0.0159284677 0.0155593837 0.0151883746]\n",
      "KL loss: 0.00786734838 hist_true: [0.0141494554 0.0147178024 0.015284366 ... 0.0159169193 0.0153602725 0.0147998855] hist_pred: [0.0201909747 0.0203914922 0.0205821656 ... 0.0154561438 0.0150916344 0.0147238066]\n",
      "KL loss: 0.00197662297 hist_true: [0.0155219063 0.0160003155 0.0164724775 ... 0.0164644942 0.0159972366 0.0155240707] hist_pred: [0.0182297416 0.0184992943 0.0187584087 ... 0.0178163592 0.0175820086 0.0173436645]\n",
      "KL loss: 0.00623889919 hist_true: [0.0184214842 0.0188759938 0.01931528 ... 0.0136013459 0.0130969631 0.0125953658] hist_pred: [0.0243251715 0.0243738219 0.0244035348 ... 0.0133343842 0.0130123533 0.0126939621]\n",
      "KL loss: 0.00384230493 hist_true: [0.01314101 0.0136634447 0.0141868768 ... 0.0181777645 0.0176960621 0.0172024835] hist_pred: [0.0168203153 0.0171709098 0.0175148919 ... 0.0174911134 0.0171504561 0.0168033671]\n",
      "KL loss: 0.00136851752 hist_true: [0.0184693206 0.0188232586 0.0191646181 ... 0.0153410882 0.0149246063 0.0145054022] hist_pred: [0.0201673023 0.0202986281 0.0204216223 ... 0.0171524081 0.0169136133 0.0166701749]\n",
      "KL loss: 0.000956299 hist_true: [0.0179343931 0.0182532053 0.0185621306 ... 0.0167323574 0.0163810458 0.0160240475] hist_pred: [0.0201025289 0.0202108398 0.0203129351 ... 0.017586967 0.017385494 0.0171810947]\n",
      "KL loss: 0.00914036296 hist_true: [0.0135287298 0.0140955206 0.0146628125 ... 0.0165272299 0.0159701202 0.0154070333] hist_pred: [0.0193859097 0.0196738821 0.0199501291 ... 0.0153471362 0.0149907609 0.0146354549]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5962 KL loss: 0.00217415951 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0166886672 0.0171974096 0.0176958535 ... 0.0144807287 0.0139550995 0.0134298187]\n",
      "KL loss: 0.00213902025 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0124743832 0.0130038299 0.0135361636 ... 0.0189057849 0.0184453763 0.0179716405]\n",
      "KL loss: 0.00149514666 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0186238661 0.0189128108 0.0191910341 ... 0.0163519122 0.0160015076 0.0156463385]\n",
      "KL loss: 0.000928878842 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0197477229 0.0199967 0.0202327203 ... 0.0157833099 0.0154541973 0.0151234297]\n",
      "KL loss: 0.00439609401 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0166492369 0.017089719 0.0175209828 ... 0.0159262903 0.0154755311 0.0150205223]\n",
      "KL loss: 0.00309892232 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0209874026 0.0211873408 0.0213733632 ... 0.0147621883 0.0143959736 0.0140285958]\n",
      "KL loss: 0.00124749844 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0207919758 0.0208211616 0.0208464172 ... 0.0180945434 0.0179596562 0.0178224463]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5952 - val_loss: 0.1684\n",
      "Epoch 43/50\n",
      "KL loss: 0.00265846588 hist_true: [0.0164028201 0.016810786 0.0172109324 ... 0.0168709606 0.0164616834 0.016045291] hist_pred: [0.0198687892 0.0200212821 0.0201629791 ... 0.0178506747 0.0176843815 0.0175156444]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7201KL loss: 0.000798301771 hist_true: [0.0183898862 0.0187231768 0.0190446898 ... 0.0158619471 0.0154744452 0.0150831081] hist_pred: [0.0199473817 0.0200858507 0.0202170257 ... 0.0171049386 0.0168422498 0.0165738072]\n",
      "KL loss: 0.00154814299 hist_true: [0.0188133661 0.0190335475 0.0192451645 ... 0.017453542 0.0171880536 0.0169169735] hist_pred: [0.021585254 0.0216181669 0.0216439925 ... 0.0169463288 0.016757967 0.0165681411]\n",
      "KL loss: 0.00644691847 hist_true: [0.0136049613 0.0142343957 0.0148651162 ... 0.0149461199 0.0143226627 0.0137004089] hist_pred: [0.0191007908 0.0193690211 0.0196270682 ... 0.0156228598 0.0152277546 0.0148294205]\n",
      "KL loss: 0.00115332217 hist_true: [0.0183262378 0.0185606666 0.018787235 ... 0.0178939719 0.0176411103 0.0173819233] hist_pred: [0.0207990445 0.0208513476 0.0208980348 ... 0.0177272335 0.0175664257 0.0174032133]\n",
      "KL loss: 0.00342858303 hist_true: [0.0185775049 0.019147275 0.019699052 ... 0.0116086714 0.0110447733 0.0104923015] hist_pred: [0.0197362825 0.0200948957 0.0204334762 ... 0.0146240778 0.0142638879 0.0139070302]\n",
      "KL loss: 0.00383990677 hist_true: [0.014705047 0.0151748275 0.0156409498 ... 0.0176302306 0.0171943642 0.0167490654] hist_pred: [0.0188542306 0.0190246552 0.0191866681 ... 0.0186486989 0.0184702743 0.0182849336]\n",
      "KL loss: 0.00477311201 hist_true: [0.0179386847 0.0183121059 0.0186737254 ... 0.0156930853 0.0152780432 0.014859288] hist_pred: [0.016231617 0.0165322758 0.0168301109 ... 0.019056933 0.0187768601 0.0184859019]\n",
      "KL loss: 0.00192337914 hist_true: [0.0176331028 0.0179524925 0.0182628203 ... 0.0171372723 0.0168008786 0.0164580084] hist_pred: [0.0208699722 0.0209477507 0.0210183654 ... 0.0170184132 0.0167931467 0.0165637843]\n",
      "KL loss: 0.00275390479 hist_true: [0.0167973377 0.0171262436 0.0174480863 ... 0.0181067083 0.0178013779 0.0174875762] hist_pred: [0.0206510574 0.0206899084 0.0207251254 ... 0.0178475659 0.0176640786 0.0174751487]\n",
      "KL loss: 0.00137276202 hist_true: [0.0170747936 0.0175356418 0.0179854073 ... 0.0150477365 0.0145670241 0.0140846409] hist_pred: [0.0180565752 0.0183382947 0.0186112821 ... 0.0170065127 0.0166560449 0.0162979253]\n",
      "KL loss: 0.0206749812 hist_true: [0.0103926258 0.0109296143 0.0114773121 ... 0.0205571167 0.0200622976 0.0195467435] hist_pred: [0.017078083 0.0174732804 0.0178585928 ... 0.0165731087 0.0161968078 0.0158162452]\n",
      "KL loss: 0.00677824114 hist_true: [0.0174676199 0.017755365 0.0180355273 ... 0.0180462115 0.0177674331 0.017481152] hist_pred: [0.0228147637 0.0227916222 0.0227603093 ... 0.0162897985 0.0161055923 0.0159217622]\n",
      "KL loss: 0.00280893617 hist_true: [0.0143077439 0.0146831227 0.0150567191 ... 0.0206499398 0.020415321 0.0201669037] hist_pred: [0.0176690165 0.0178487264 0.0180237312 ... 0.02040549 0.0203457903 0.0202821754]\n",
      "KL loss: 0.00123315118 hist_true: [0.018906258 0.0192248821 0.0195306763 ... 0.0154599166 0.0150663247 0.0146698] hist_pred: [0.0193980988 0.0195697751 0.0197340231 ... 0.0174509827 0.0172098856 0.0169644281]\n",
      "KL loss: 0.00112768321 hist_true: [0.0158033427 0.016140895 0.0164737031 ... 0.0193764251 0.0191200376 0.0188530646] hist_pred: [0.0180473216 0.0182386152 0.0184241161 ... 0.0193930659 0.0192574728 0.0191169623]\n",
      "KL loss: 0.0130084213 hist_true: [0.00947776716 0.0100345537 0.0106071299 ... 0.0202185307 0.019624101 0.0190092083] hist_pred: [0.0156917889 0.015984552 0.0162704512 ... 0.0215819851 0.0215061959 0.021416612]\n",
      "KL loss: 0.00033832225 hist_true: [0.018623827 0.0188060403 0.0189818833 ... 0.0185168535 0.0183252785 0.0181279201] hist_pred: [0.0196387079 0.0197061133 0.0197700467 ... 0.0193652119 0.0192972515 0.0192273669]\n",
      "KL loss: 0.00173145416 hist_true: [0.0134535674 0.0139912795 0.0145294173 ... 0.0173342824 0.0168157555 0.0162881371] hist_pred: [0.0160829276 0.0164708383 0.0168554112 ... 0.0171033293 0.0166901443 0.0162705462]\n",
      "KL loss: 0.0220320746 hist_true: [0.0101914443 0.010796519 0.0114158569 ... 0.0184497964 0.0178195406 0.0171770174] hist_pred: [0.01828463 0.0186298024 0.0189609062 ... 0.0164326727 0.016120309 0.0158076063]\n",
      "KL loss: 0.00385884265 hist_true: [0.0202355441 0.0206916556 0.0211260542 ... 0.0116877044 0.0111647099 0.0106508564] hist_pred: [0.0251800604 0.0252415203 0.0252802595 ... 0.0121223591 0.0117565319 0.0113962097]\n",
      "KL loss: 0.00760926912 hist_true: [0.0171372406 0.01756531 0.017982807 ... 0.0156101445 0.0151616549 0.0147098238] hist_pred: [0.0229888652 0.0230724141 0.0231414549 ... 0.0140360333 0.0136893503 0.0133432494]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5368 KL loss: 0.00407994725 hist_true: [0.0197682027 0.0200323053 0.020283198 ... 0.0152914571 0.0149173308 0.0145407924] hist_pred: [0.0189370755 0.0190712232 0.0192013811 ... 0.0187621396 0.0185905062 0.0184123497]\n",
      "KL loss: 0.0285993312 hist_true: [0.00925695151 0.0098515721 0.0104643768 ... 0.0193270966 0.0186844878 0.0180262607] hist_pred: [0.0182556268 0.0185975619 0.0189223513 ... 0.0173698273 0.0171157941 0.016854791]\n",
      "KL loss: 0.00521568675 hist_true: [0.015784733 0.016381802 0.0169714019 ... 0.0136750331 0.0130867 0.0125031164] hist_pred: [0.0202474203 0.0206417758 0.0210176017 ... 0.0126714772 0.0122075528 0.0117506701]\n",
      "KL loss: 0.00216382905 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0162575524 0.016801713 0.0173368566 ... 0.0142021729 0.0136467963 0.0130931269]\n",
      "KL loss: 0.00115768984 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.011917823 0.0124553777 0.0129977828 ... 0.0192798208 0.0188120455 0.0183295961]\n",
      "KL loss: 0.00156913698 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0185299087 0.0188311562 0.0191215239 ... 0.0162356086 0.0158738289 0.0155073972]\n",
      "KL loss: 0.000499992457 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0192224905 0.0194995943 0.019764211 ... 0.0159517303 0.0156123592 0.0152706066]\n",
      "KL loss: 0.00443294831 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0164815243 0.0169368666 0.0173833594 ... 0.0157806873 0.0153126456 0.0148406075]\n",
      "KL loss: 0.00242641428 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.020538291 0.0207641684 0.0209763125 ... 0.0149091538 0.0145365912 0.0141624548]\n",
      "KL loss: 0.00126937963 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0207550768 0.0207901038 0.0208209418 ... 0.0180472322 0.0179072637 0.0177648868]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5321 - val_loss: 0.1665\n",
      "Epoch 44/50\n",
      "KL loss: 0.00238996232 hist_true: [0.0132497791 0.0137017062 0.0141541772 ... 0.0199564714 0.0196022857 0.019232478] hist_pred: [0.0162086245 0.0165072195 0.0168013126 ... 0.0196819305 0.0194759462 0.0192611702]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3065KL loss: 0.00136635778 hist_true: [0.0183274634 0.0186490659 0.0189595837 ... 0.0161318611 0.01575654 0.0153766824] hist_pred: [0.0188304521 0.0190096516 0.019181706 ... 0.0182809457 0.0180768725 0.0178668536]\n",
      "KL loss: 0.00225759391 hist_true: [0.0221341476 0.022430405 0.0227037761 ... 0.012033741 0.0115718404 0.0111162439] hist_pred: [0.0259818248 0.0259462949 0.0258927327 ... 0.0124618132 0.0121575436 0.0118612312]\n",
      "KL loss: 0.0124103632 hist_true: [0.0085465936 0.00914342143 0.00976275466 ... 0.0191761293 0.0184607022 0.0177305341] hist_pred: [0.0134873688 0.0140467109 0.014604249 ... 0.017607 0.0171471983 0.0166794]\n",
      "KL loss: 0.00140255969 hist_true: [0.0129130119 0.0133913048 0.013871043 ... 0.0197052341 0.0193171948 0.0189138521] hist_pred: [0.0151297906 0.0154749965 0.0158164818 ... 0.0203877315 0.0201909021 0.0199839063]\n",
      "KL loss: 0.000887530856 hist_true: [0.0174930468 0.0178298149 0.0181573555 ... 0.0169765949 0.01662389 0.0162648503] hist_pred: [0.0193191227 0.0194621962 0.0195989478 ... 0.0181270465 0.0179263186 0.0177200511]\n",
      "KL loss: 0.00461708475 hist_true: [0.0158670675 0.0163449161 0.0168154482 ... 0.0160571933 0.0155802853 0.0150985615] hist_pred: [0.0205407869 0.0207121391 0.0208709184 ... 0.0164884403 0.0162529107 0.0160157476]\n",
      "KL loss: 0.00267327903 hist_true: [0.016076494 0.0165065341 0.0169291962 ... 0.0168668311 0.0164471231 0.0160204843] hist_pred: [0.0197330788 0.0199124962 0.020083148 ... 0.0167351458 0.0164448898 0.0161494]\n",
      "KL loss: 0.0012045285 hist_true: [0.0167621989 0.0171422698 0.0175140798 ... 0.0170259811 0.016644178 0.016255334] hist_pred: [0.0192518737 0.0194517262 0.0196439046 ... 0.0169578884 0.0166701116 0.016377883]\n",
      "KL loss: 0.00402552402 hist_true: [0.0173325408 0.0176735129 0.0180056952 ... 0.0170713887 0.0167162288 0.0163543131] hist_pred: [0.0218018424 0.0218470227 0.0218819901 ... 0.0168768857 0.0167121068 0.0165474191]\n",
      "KL loss: 0.000948959496 hist_true: [0.0175766218 0.0179269146 0.0182673465 ... 0.0165782217 0.0162023883 0.0158208758] hist_pred: [0.0194744896 0.019624792 0.0197682884 ... 0.0177511964 0.0175294727 0.0173023418]\n",
      "KL loss: 0.000936483033 hist_true: [0.0180795733 0.0183367766 0.0185858738 ... 0.0177866761 0.0175149869 0.0172366612] hist_pred: [0.0181430243 0.0183158498 0.0184836388 ... 0.0196847711 0.0195844118 0.0194803737]\n",
      "KL loss: 0.0304934159 hist_true: [0.010490723 0.0110191796 0.0115577383 ... 0.0207920019 0.0203238595 0.0198348] hist_pred: [0.0197314918 0.0199680254 0.0201877132 ... 0.0169026125 0.0166502651 0.0163917467]\n",
      "KL loss: 0.00167370867 hist_true: [0.0165892355 0.0169643965 0.0173317902 ... 0.0174017157 0.0170391332 0.0166688748] hist_pred: [0.0183253027 0.0184775144 0.0186254866 ... 0.0195632894 0.019440135 0.0193111449]\n",
      "KL loss: 0.00814501289 hist_true: [0.01049372 0.0111756502 0.0118746636 ... 0.0158112 0.0150842546 0.0143588902] hist_pred: [0.0159641802 0.0163404234 0.0167133342 ... 0.0170894619 0.0166238099 0.0161479171]\n",
      "KL loss: 0.002497965 hist_true: [0.017701393 0.0180999618 0.0184871536 ... 0.0154144615 0.0149722286 0.0145269502] hist_pred: [0.0198458042 0.019988073 0.0201211181 ... 0.0179698355 0.0178146623 0.0176575]\n",
      "KL loss: 0.0134879863 hist_true: [0.00872240681 0.00928633753 0.00987007935 ... 0.020219015 0.0195642561 0.0188889876] hist_pred: [0.0140812704 0.0145755503 0.0150646362 ... 0.019112194 0.0187987406 0.0184746608]\n",
      "KL loss: 0.00229481095 hist_true: [0.0197238009 0.0202106666 0.0206765085 ... 0.011817758 0.0112883849 0.0107680168] hist_pred: [0.023304306 0.0235063303 0.0236843321 ... 0.0125730773 0.0121971164 0.0118271085]\n",
      "KL loss: 0.00510351639 hist_true: [0.0172337499 0.0175769906 0.0179116298 ... 0.0171705987 0.0168187097 0.0164599102] hist_pred: [0.016450299 0.016650876 0.0168502796 ... 0.0213010106 0.021217458 0.0211234763]\n",
      "KL loss: 0.00189288019 hist_true: [0.0183876753 0.0187380612 0.0190760512 ... 0.0155546516 0.0151488381 0.0147398328] hist_pred: [0.0216246899 0.021736674 0.0218373686 ... 0.0154584693 0.015163755 0.0148676923]\n",
      "KL loss: 0.00511625828 hist_true: [0.0139510324 0.0145498365 0.0151481843 ... 0.0153107578 0.0147148874 0.0141180549] hist_pred: [0.0183216091 0.0187124629 0.0190928094 ... 0.0140864234 0.0135670993 0.0130476849]\n",
      "KL loss: 0.00192184839 hist_true: [0.0200359486 0.0203910973 0.0207284968 ... 0.0134540824 0.0129930042 0.0125344181] hist_pred: [0.021171499 0.0212951973 0.0214080475 ... 0.0157103688 0.0153961806 0.0150781032]\n",
      "KL loss: 0.00318454765 hist_true: [0.015602597 0.0159764253 0.016345175 ... 0.0188023932 0.0184917822 0.0181705374] hist_pred: [0.0193886757 0.0195247401 0.0196528286 ... 0.0187130142 0.0185882505 0.0184605904]\n",
      "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3208 KL loss: 0.00287369639 hist_true: [0.0157684833 0.0163062438 0.0168366972 ... 0.014881175 0.0143415742 0.0138015021] hist_pred: [0.0178167354 0.0181495827 0.018468773 ... 0.0176073089 0.0173424408 0.0170712247]\n",
      "KL loss: 0.00154382875 hist_true: [0.0166341905 0.017038526 0.0174342357 ... 0.0167128667 0.0163061861 0.0158929713] hist_pred: [0.0185319204 0.0187092684 0.0188806448 ... 0.018609073 0.0184049439 0.0181930847]\n",
      "KL loss: 0.00935921073 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0181591865 0.0186925679 0.0192105416 ... 0.0124036185 0.0118384948 0.0112810852]\n",
      "KL loss: 0.00586451963 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0133480299 0.0138898185 0.0144320168 ... 0.0175180454 0.0170154572 0.0165039059]\n",
      "KL loss: 0.00592297828 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0202466454 0.0204991046 0.0207375363 ... 0.0148340482 0.0144473761 0.0140592186]\n",
      "KL loss: 0.00211847806 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0203108341 0.0205563419 0.0207874328 ... 0.0150445141 0.0146850394 0.0143248625]\n",
      "KL loss: 0.012202898 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.018279057 0.0187066626 0.0191204455 ... 0.0141515573 0.013662722 0.0131745385]\n",
      "KL loss: 0.00678131077 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0221531875 0.0223234221 0.0224774946 ... 0.0137337958 0.0133449668 0.0129571725]\n",
      "KL loss: 0.00255551329 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0215234086 0.0215248112 0.0215218887 ... 0.0174624622 0.0173059031 0.0171476565]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3178 - val_loss: 0.2406\n",
      "Epoch 45/50\n",
      "KL loss: 0.00375297177 hist_true: [0.0181554202 0.0186468884 0.0191233326 ... 0.0132309925 0.0127025358 0.0121784909] hist_pred: [0.0228641126 0.0229146704 0.0229531415 ... 0.014408173 0.01405151 0.0136923697]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9932KL loss: 0.0033393479 hist_true: [0.0168917738 0.0173234306 0.0177453347 ... 0.0157742575 0.0153216934 0.0148650575] hist_pred: [0.0207634121 0.0209736675 0.0211690422 ... 0.0150646176 0.0147130201 0.0143597573]\n",
      "KL loss: 0.000965929125 hist_true: [0.0185083319 0.0188042857 0.0190895814 ... 0.016376812 0.0160238557 0.0156660415] hist_pred: [0.0207798108 0.0209106356 0.0210319869 ... 0.0162587054 0.0159886796 0.0157164987]\n",
      "KL loss: 0.00464656 hist_true: [0.0185304694 0.0188073479 0.0190742239 ... 0.0167138614 0.0163837131 0.0160482228] hist_pred: [0.0230626874 0.0230582431 0.0230454355 ... 0.0151664903 0.0148897143 0.0146122519]\n",
      "KL loss: 0.0238167346 hist_true: [0.00954788737 0.0100953551 0.0106572611 ... 0.0208869129 0.0203571413 0.0198052526] hist_pred: [0.0167967267 0.0171916187 0.0175765101 ... 0.016824957 0.0164264105 0.0160203781]\n",
      "KL loss: 0.00249079941 hist_true: [0.0137537913 0.0142785618 0.0148029765 ... 0.0172414687 0.0167291351 0.0162079018] hist_pred: [0.0169295482 0.0172619298 0.0175869782 ... 0.0177912191 0.0174667407 0.0171342418]\n",
      "KL loss: 0.00329749193 hist_true: [0.0157527514 0.0161714163 0.0165837873 ... 0.0175476577 0.0171569753 0.0167576857] hist_pred: [0.0148203913 0.0151708405 0.0155178234 ... 0.0208490361 0.0206720121 0.020483179]\n",
      "KL loss: 0.0031899726 hist_true: [0.0175706688 0.018217 0.0188484937 ... 0.0113040516 0.0107056312 0.0101213334] hist_pred: [0.0194271244 0.0198202915 0.0201947223 ... 0.0139552308 0.0135100782 0.0130652459]\n",
      "KL loss: 0.00556609407 hist_true: [0.0186294802 0.0189068746 0.0191739034 ... 0.0165881831 0.0162547044 0.0159162227] hist_pred: [0.0176776592 0.0177923627 0.0179085862 ... 0.0207326151 0.0206440613 0.0205461215]\n",
      "KL loss: 0.000537615037 hist_true: [0.0185666196 0.0188302957 0.0190842692 ... 0.0169479549 0.0166361276 0.0163187515] hist_pred: [0.0202113315 0.020332722 0.0204459988 ... 0.0174401347 0.0172411408 0.0170395654]\n",
      "KL loss: 0.0458051711 hist_true: [0.00991198141 0.0105801243 0.0112677468 ... 0.0163214095 0.0155689586 0.014815649] hist_pred: [0.0225757882 0.0228143856 0.0230107214 ... 0.0163696278 0.0162250027 0.0160724092]\n",
      "KL loss: 0.00356210023 hist_true: [0.0185808446 0.0188572798 0.0191234872 ... 0.0166809987 0.0163519513 0.0160177294] hist_pred: [0.0222970378 0.0223756079 0.0224418323 ... 0.0152757959 0.0150029417 0.0147304842]\n",
      "KL loss: 0.00652233884 hist_true: [0.0100012925 0.0106406175 0.0112973452 ... 0.0172040258 0.0164943 0.0157787781] hist_pred: [0.0140357241 0.0145171201 0.0149972411 ... 0.0191530604 0.0188691709 0.0185788292]\n",
      "KL loss: 0.00159420911 hist_true: [0.0183681585 0.0186390635 0.0189005323 ... 0.0170964357 0.016787922 0.0164736509] hist_pred: [0.0180957951 0.0182740223 0.0184474532 ... 0.0194279253 0.0192869306 0.0191398319]\n",
      "KL loss: 0.00423065759 hist_true: [0.0184463169 0.0188569129 0.0192533061 ... 0.0143461097 0.0138766803 0.0134074148] hist_pred: [0.0189951342 0.0191853 0.0193662252 ... 0.018010173 0.0177879483 0.0175585207]\n",
      "KL loss: 0.00139631145 hist_true: [0.0148395896 0.0152321411 0.0156213241 ... 0.0194232706 0.0191207193 0.0188059453] hist_pred: [0.0164765064 0.0166683607 0.0168596171 ... 0.0214047171 0.0213348474 0.0212556794]\n",
      "KL loss: 0.00193627935 hist_true: [0.0168143269 0.0172542967 0.0176844019 ... 0.0157691166 0.0153170284 0.0148611013] hist_pred: [0.0199081078 0.020142721 0.0203652307 ... 0.0157348234 0.0154018439 0.0150662409]\n",
      "KL loss: 0.00328101544 hist_true: [0.0152997384 0.0157439299 0.0161828473 ... 0.0175057799 0.0170892272 0.0166637059] hist_pred: [0.0190821607 0.0193066038 0.0195198953 ... 0.0173225682 0.0170733109 0.0168204922]\n",
      "KL loss: 0.0107491137 hist_true: [0.0141529 0.0146728959 0.0151906367 ... 0.0171498545 0.0166634656 0.0161691438] hist_pred: [0.0206086561 0.0208218 0.0210173056 ... 0.0165743157 0.0164009761 0.0162301473]\n",
      "KL loss: 0.00373008382 hist_true: [0.0166144073 0.016947804 0.0172744375 ... 0.0182832032 0.0179825835 0.0176731087] hist_pred: [0.0206395425 0.0207262523 0.0208064616 ... 0.0170986652 0.0168682542 0.0166334976]\n",
      "KL loss: 0.00121492799 hist_true: [0.0157608185 0.0161471236 0.0165278129 ... 0.0182412881 0.0178961251 0.0175410639] hist_pred: [0.0180866718 0.0183213111 0.018548036 ... 0.0184525754 0.0182417613 0.0180250276]\n",
      "KL loss: 0.00686704554 hist_true: [0.0176846478 0.0179036297 0.0181170367 ... 0.0192181077 0.0190413781 0.0188576188] hist_pred: [0.022167867 0.0221785344 0.022182595 ... 0.0162834376 0.016059842 0.0158348419]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3909 KL loss: 0.00306266127 hist_true: [0.0185275469 0.0189749673 0.019406775 ... 0.0136395339 0.0131405406 0.0126440423] hist_pred: [0.0221373141 0.0221860036 0.0222240333 ... 0.0155857187 0.0152872121 0.0149849737]\n",
      "KL loss: 0.014752591 hist_true: [0.00835092 0.00893493835 0.00954150595 ... 0.0198186524 0.019127693 0.0184190702] hist_pred: [0.015251372 0.0154962102 0.0157396663 ... 0.0209962856 0.0207370035 0.0204586033]\n",
      "KL loss: 0.000284058624 hist_true: [0.0179479606 0.0182006024 0.0184456985 ... 0.018070925 0.0178145599 0.0175512694] hist_pred: [0.0191775952 0.0193204898 0.0194576364 ... 0.0183680598 0.0181826558 0.0179916956]\n",
      "KL loss: 0.00168230245 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0161973927 0.0167312063 0.0172561966 ... 0.0144952582 0.0139516005 0.0134085184]\n",
      "KL loss: 0.00117840315 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0119845849 0.0125185587 0.0130570875 ... 0.0193139743 0.0188519266 0.0183750894]\n",
      "KL loss: 0.00130695431 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0184363108 0.018735677 0.019024482 ... 0.0164050292 0.0160507988 0.0156916063]\n",
      "KL loss: 0.000382339116 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0191410165 0.0194161162 0.0196790285 ... 0.0161052197 0.0157727972 0.0154377026]\n",
      "KL loss: 0.00370230293 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0163316634 0.0167835206 0.017226981 ... 0.0160589051 0.0156018184 0.0151400166]\n",
      "KL loss: 0.00244960957 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0206066556 0.0208259653 0.0210316237 ... 0.0149355 0.0145670278 0.0141969752]\n",
      "KL loss: 0.00121417921 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0207240824 0.0207596831 0.0207911544 ... 0.0180839915 0.0179456919 0.0178049579]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3805 - val_loss: 0.1477\n",
      "Epoch 46/50\n",
      "KL loss: 0.00179309631 hist_true: [0.0179410819 0.0182563476 0.0185618438 ... 0.0167847872 0.0164365023 0.0160823818] hist_pred: [0.0182306841 0.0183937438 0.0185533948 ... 0.0192866605 0.0191322826 0.0189714897]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4798KL loss: 0.00771644199 hist_true: [0.014330565 0.0148747116 0.015416204 ... 0.0163231529 0.0157957394 0.0152629437] hist_pred: [0.0194974821 0.0198224783 0.0201321784 ... 0.0146950483 0.014292907 0.0138920117]\n",
      "KL loss: 0.00342953438 hist_true: [0.00984501094 0.0104678106 0.0111078704 ... 0.0178018641 0.0171066858 0.0164024979] hist_pred: [0.0107882097 0.0113049792 0.0118301166 ... 0.0214765631 0.0211129449 0.0207288042]\n",
      "KL loss: 0.000405774452 hist_true: [0.0201520585 0.0203443151 0.0205254517 ... 0.0160619896 0.0157508 0.0154362889] hist_pred: [0.0213029105 0.0213570446 0.0214038771 ... 0.0169474874 0.0167456735 0.0165416207]\n",
      "KL loss: 0.00553912483 hist_true: [0.018908862 0.0193626434 0.0197992958 ... 0.0131622301 0.012658936 0.0121599501] hist_pred: [0.0183783788 0.0186498743 0.0189121272 ... 0.0170283932 0.0167115629 0.0163883604]\n",
      "KL loss: 0.00214796886 hist_true: [0.018670788 0.0190380253 0.0193917267 ... 0.014821656 0.0143825421 0.0139420126] hist_pred: [0.0195289236 0.0196949635 0.0198529623 ... 0.0173996836 0.0171497557 0.0168937296]\n",
      "KL loss: 0.000987732084 hist_true: [0.0191443358 0.0194883719 0.0198179614 ... 0.0146932648 0.0142645175 0.0138346739] hist_pred: [0.0199884288 0.0202032421 0.0204047225 ... 0.0164466407 0.0161917247 0.0159363039]\n",
      "KL loss: 0.00385562843 hist_true: [0.0188321415 0.0191204175 0.0193973463 ... 0.0160898976 0.0157310534 0.0153679904] hist_pred: [0.0180409662 0.0181989167 0.0183546413 ... 0.0195004418 0.0193421934 0.019175997]\n",
      "KL loss: 0.000406749255 hist_true: [0.0177609455 0.0181552786 0.0185380336 ... 0.0154695669 0.0150351459 0.0145977121] hist_pred: [0.0192572288 0.0195151288 0.0197625868 ... 0.0158415399 0.0154733807 0.0151013117]\n",
      "KL loss: 0.000966345891 hist_true: [0.0167675726 0.017179165 0.0175815802 ... 0.0164148528 0.0159982312 0.0155760786] hist_pred: [0.0186465941 0.0188909881 0.0191253498 ... 0.0175062325 0.0172504913 0.016989721]\n",
      "KL loss: 0.00532239396 hist_true: [0.0183850098 0.0188276097 0.0192555133 ... 0.013807945 0.013309204 0.0128124012] hist_pred: [0.0235171653 0.0236404222 0.0237454101 ... 0.0127668567 0.012365561 0.0119672716]\n",
      "KL loss: 0.00433005299 hist_true: [0.0100045316 0.010650916 0.0113154976 ... 0.0167534556 0.0160141978 0.0152713424] hist_pred: [0.0136577468 0.0141538931 0.0146498354 ... 0.0174936876 0.0169371329 0.0163670722]\n",
      "KL loss: 0.00670492509 hist_true: [0.0175627507 0.0178809632 0.0181903373 ... 0.0172595456 0.0169285722 0.0165908989] hist_pred: [0.0226291921 0.0226754956 0.0227108989 ... 0.0152262654 0.0149552813 0.0146844164]\n",
      "KL loss: 0.00146563235 hist_true: [0.0142243551 0.0146671198 0.0151076373 ... 0.0189713109 0.0186031852 0.0182225872] hist_pred: [0.0163186248 0.0165781714 0.0168340858 ... 0.0205132607 0.0203892589 0.0202580374]\n",
      "KL loss: 0.00814080331 hist_true: [0.0139793167 0.0144856675 0.0149903484 ... 0.0176451821 0.017176332 0.0166977439] hist_pred: [0.0186286904 0.0189775657 0.0193146393 ... 0.0150965275 0.0146699566 0.0142411683]\n",
      "KL loss: 0.00602245936 hist_true: [0.0136251282 0.0141454712 0.0146655096 ... 0.0176384207 0.017149834 0.0166514311] hist_pred: [0.0186666176 0.0189066753 0.0191353485 ... 0.0175088625 0.0172252338 0.0169329736]\n",
      "KL loss: 0.0012590813 hist_true: [0.0192180574 0.0195154287 0.0197999682 ... 0.0154022826 0.0150146578 0.014624197] hist_pred: [0.0212260652 0.021310959 0.0213855132 ... 0.0169047453 0.0167124383 0.0165185593]\n",
      "KL loss: 0.00590376556 hist_true: [0.0165365208 0.0169352684 0.0173259061 ... 0.016948007 0.0165530089 0.0161511097] hist_pred: [0.021331951 0.0214673448 0.021592088 ... 0.0150898425 0.0147392638 0.014386002]\n",
      "KL loss: 0.00540373847 hist_true: [0.00967909582 0.0101789841 0.0106907403 ... 0.0226824582 0.0222954452 0.0218817592] hist_pred: [0.0132534457 0.0136606582 0.01406716 ... 0.0217641648 0.0215777364 0.0213762634]\n",
      "KL loss: 0.00802333932 hist_true: [0.019456638 0.0199448392 0.0204134174 ... 0.0119776223 0.0114442296 0.0109195411] hist_pred: [0.0208230875 0.0209639352 0.0210916754 ... 0.0168045182 0.0165970158 0.0163867194]\n",
      "KL loss: 0.00918696634 hist_true: [0.0106846495 0.0113938 0.0121209435 ... 0.0146537377 0.0138819776 0.0131180743] hist_pred: [0.0158587694 0.0164125413 0.0169561282 ... 0.0156413447 0.0152070876 0.0147725362]\n",
      "KL loss: 0.00265964633 hist_true: [0.0165151116 0.0169225689 0.0173219591 ... 0.0167383198 0.0163269974 0.0159090925] hist_pred: [0.0200463496 0.0202193782 0.0203807876 ... 0.017122671 0.0169140473 0.0167041365]\n",
      "KL loss: 0.00630394742 hist_true: [0.0160819143 0.016465744 0.016843047 ... 0.0178869348 0.0175338797 0.0171719] hist_pred: [0.0210392922 0.0211675633 0.0212838594 ... 0.0165545885 0.0163550749 0.0161573458]\n",
      "KL loss: 0.00690482929 hist_true: [0.016065944 0.0165018402 0.0169303138 ... 0.0167382192 0.0163093861 0.0158738643] hist_pred: [0.0157780983 0.016026957 0.0162731837 ... 0.0217976328 0.0217445623 0.0216810703]\n",
      "KL loss: 0.000862934161 hist_true: [0.0158977602 0.0162329637 0.0165632069 ... 0.0193035975 0.0190468654 0.0187797863] hist_pred: [0.0177099295 0.017869724 0.0180266108 ... 0.0203586724 0.0202684719 0.0201710425]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2766 KL loss: 3.07400041e-05 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0150775481 0.0155995851 0.016116526 ... 0.0159993861 0.0154871466 0.0149705112]\n",
      "KL loss: 3.94201779e-05 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0112082083 0.0117293848 0.0122571914 ... 0.0206641611 0.0202521011 0.019821506]\n",
      "KL loss: 4.95743e-06 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0170218498 0.017346289 0.0176631641 ... 0.0178960226 0.0175862722 0.0172685776]\n",
      "KL loss: 4.84277261e-05 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0181100983 0.0184077136 0.0186952986 ... 0.0170847569 0.016778063 0.0164668933]\n",
      "KL loss: 0.00064711622 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0150495647 0.0155094415 0.0159644801 ... 0.0175367873 0.0171167646 0.016688142]\n",
      "KL loss: 0.000665853731 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0195990596 0.0198418051 0.0200728476 ... 0.0158888455 0.0155452471 0.0151981516]\n",
      "KL loss: 0.00025273033 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0198344626 0.0199028067 0.0199674983 ... 0.0188941136 0.0187869594 0.0186768137]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2770 - val_loss: 0.1442\n",
      "Epoch 47/50\n",
      "KL loss: 0.000573299942 hist_true: [0.0187141243 0.0189872887 0.0192500409 ... 0.0165372286 0.0162027124 0.0158632137] hist_pred: [0.0203012228 0.0204266198 0.0205434859 ... 0.0172811076 0.0170785096 0.0168738421]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1762KL loss: 0.000781268347 hist_true: [0.0182573516 0.0185459778 0.0188247785 ... 0.0169088263 0.0165831391 0.0162518062] hist_pred: [0.0194640979 0.0195932407 0.0197157227 ... 0.0183591098 0.0181884505 0.0180126783]\n",
      "KL loss: 0.0015261214 hist_true: [0.02062889 0.0208446775 0.0210467987 ... 0.0149962781 0.0146338604 0.014269881] hist_pred: [0.0236963984 0.0236447081 0.0235842504 ... 0.0154171819 0.0152005674 0.014985566]\n",
      "KL loss: 0.000575634069 hist_true: [0.0173922312 0.0176808145 0.017962 ... 0.0181341674 0.0178583171 0.0175747983] hist_pred: [0.0190943498 0.0192381274 0.0193762947 ... 0.018565245 0.0184013676 0.0182331428]\n",
      "KL loss: 0.00588749489 hist_true: [0.0189794078 0.0193962958 0.019797 ... 0.0136242127 0.0131373554 0.0126527948] hist_pred: [0.0185642485 0.0187588036 0.018947782 ... 0.0175329354 0.0172061976 0.0168685932]\n",
      "KL loss: 0.00441477541 hist_true: [0.0105540231 0.0112308972 0.0119264172 ... 0.0151093034 0.0143328644 0.0135622052] hist_pred: [0.014035874 0.0145042296 0.0149717759 ... 0.0171646699 0.0166184437 0.0160661619]\n",
      "KL loss: 0.00235719234 hist_true: [0.0180551913 0.0185493473 0.0190280825 ... 0.0134289069 0.0129079223 0.0123903826] hist_pred: [0.0197136495 0.0199287049 0.0201367848 ... 0.0159483515 0.0156453345 0.0153439129]\n",
      "KL loss: 0.00146890839 hist_true: [0.0183187164 0.0188931525 0.019450644 ... 0.0117031187 0.0111293988 0.0105667915] hist_pred: [0.0212757383 0.0216141716 0.0219348222 ... 0.0119969761 0.0115152765 0.0110417195]\n",
      "KL loss: 0.0133403949 hist_true: [0.0149622401 0.0153783942 0.0157905947 ... 0.0186322089 0.0182766356 0.0179098323] hist_pred: [0.0215556193 0.0216802675 0.0217920188 ... 0.0155820074 0.0153025268 0.0150220022]\n",
      "KL loss: 0.00193643081 hist_true: [0.017489912 0.0178993344 0.018297689 ... 0.0154839456 0.0150384353 0.0145897279] hist_pred: [0.0205587987 0.020683594 0.0207996108 ... 0.0166482665 0.0163878724 0.0161235761]\n",
      "KL loss: 0.00921913236 hist_true: [0.0147327604 0.0153303267 0.0159244239 ... 0.0146310348 0.0140393376 0.0134490347] hist_pred: [0.0212902203 0.0215099864 0.0217136852 ... 0.014033122 0.0136321709 0.0132317711]\n",
      "KL loss: 0.0146135427 hist_true: [0.0137627088 0.0143529028 0.01494308 ... 0.015744403 0.0151622407 0.0145774242] hist_pred: [0.0208752919 0.0211691651 0.0214453079 ... 0.0134335328 0.0130007602 0.0125707444]\n",
      "KL loss: 0.000977417454 hist_true: [0.0173345767 0.0176363569 0.0179304555 ... 0.0179333128 0.0176401343 0.0173393451] hist_pred: [0.0194391627 0.0196060203 0.0197656434 ... 0.0174122956 0.0171614941 0.0169051886]\n",
      "KL loss: 0.00333851203 hist_true: [0.0145298233 0.0149830319 0.0154330982 ... 0.018265985 0.0178612 0.0174451936] hist_pred: [0.018545 0.0186979342 0.0188469868 ... 0.0188125484 0.0186181869 0.0184162445]\n",
      "KL loss: 0.0182639286 hist_true: [0.0164011121 0.0168613624 0.0173128601 ... 0.0158048477 0.0153370332 0.0148652792] hist_pred: [0.0143164322 0.0145442253 0.0147777488 ... 0.0233436916 0.0233083721 0.0232596342]\n",
      "KL loss: 0.0182623193 hist_true: [0.00995755941 0.0105721233 0.0112028653 ... 0.0180930607 0.0174238682 0.0167443175] hist_pred: [0.0168346465 0.0172849856 0.0177242383 ... 0.0159215908 0.0155034568 0.0150831565]\n",
      "KL loss: 0.00273710117 hist_true: [0.00897710398 0.00954871 0.0101387249 ... 0.0201563183 0.0195301324 0.0188840758] hist_pred: [0.0113379369 0.0117799696 0.0122301485 ... 0.0221494474 0.0218553096 0.0215431172]\n",
      "KL loss: 0.00331489462 hist_true: [0.0141894622 0.0146065922 0.0150218466 ... 0.0196665581 0.0193460379 0.0190119371] hist_pred: [0.017584797 0.0178398434 0.018088175 ... 0.018697748 0.0184850916 0.0182661396]\n",
      "KL loss: 0.00106333848 hist_true: [0.0188656058 0.0191768724 0.0194756687 ... 0.0156629849 0.0152814491 0.0148966536] hist_pred: [0.0209542979 0.0210276172 0.0210945867 ... 0.0169015415 0.0166780706 0.0164520238]\n",
      "KL loss: 0.00780810975 hist_true: [0.0191440377 0.0195931196 0.0200241134 ... 0.0130291721 0.0125275608 0.0120304376] hist_pred: [0.0187242776 0.0189285763 0.0191267245 ... 0.0177599397 0.0175310783 0.0172993243]\n",
      "KL loss: 0.000647303881 hist_true: [0.0182287414 0.0185205 0.0188024826 ... 0.0168602355 0.0165289603 0.0161919855] hist_pred: [0.0190638304 0.0192200579 0.0193701778 ... 0.0182715226 0.018072594 0.0178677309]\n",
      "KL loss: 0.00178580405 hist_true: [0.0179567393 0.0182632674 0.0185603015 ... 0.0169331897 0.0165953208 0.0162514187] hist_pred: [0.0186595172 0.0187985394 0.0189323127 ... 0.0194556881 0.0193381775 0.0192147177]\n",
      "KL loss: 0.00275529828 hist_true: [0.0136107169 0.0141509278 0.0146910641 ... 0.017115498 0.0165938307 0.0160639286] hist_pred: [0.0166010652 0.0170249119 0.0174401421 ... 0.0165578481 0.0161649287 0.0157680307]\n",
      "KL loss: 0.00156196067 hist_true: [0.0144491466 0.0149075603 0.0153631009 ... 0.0182515252 0.017844459 0.0174264498] hist_pred: [0.0167220533 0.0169690102 0.0172129571 ... 0.0197574962 0.0195607152 0.0193533655]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2947 KL loss: 0.00657238485 hist_true: [0.0164108332 0.0167718511 0.0171260331 ... 0.0179272629 0.0175909773 0.0172459576] hist_pred: [0.0211185273 0.0212673564 0.0214028545 ... 0.0159050487 0.0156406444 0.0153755685]\n",
      "KL loss: 0.00322697102 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0165622812 0.0171095859 0.0176469907 ... 0.013768347 0.0132030714 0.0126410145]\n",
      "KL loss: 0.00113435346 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0118566453 0.0123961754 0.012940879 ... 0.0192384236 0.0187611263 0.0182689521]\n",
      "KL loss: 0.0019550065 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0186907779 0.0189910308 0.0192799978 ... 0.0160320047 0.0156631432 0.0152900377]\n",
      "KL loss: 0.00034662796 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0190269109 0.0193106551 0.0195823014 ... 0.0160551798 0.0157116205 0.0153649878]\n",
      "KL loss: 0.00444771629 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0164401736 0.0168990511 0.0173491966 ... 0.015742572 0.0152700273 0.0147935534]\n",
      "KL loss: 0.00259468192 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0205993447 0.0208246112 0.0210359991 ... 0.014836099 0.0144610545 0.0140845831]\n",
      "KL loss: 0.00193346664 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0211283583 0.0211512577 0.021169655 ... 0.0176815707 0.0175267626 0.0173698012]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2987 - val_loss: 0.1480\n",
      "Epoch 48/50\n",
      "KL loss: 0.00510779442 hist_true: [0.015692737 0.0162678659 0.0168356393 ... 0.0142575465 0.0136906495 0.0131259989] hist_pred: [0.0207598917 0.0209770855 0.0211790819 ... 0.0150523335 0.0147022447 0.0143500576]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - loss: 1.4651KL loss: 0.000769300328 hist_true: [0.0171603914 0.0175422356 0.0179144256 ... 0.0165281706 0.0161343534 0.0157348886] hist_pred: [0.0190991554 0.0193503369 0.0195918567 ... 0.0162496828 0.0159093607 0.0155652435]\n",
      "KL loss: 0.00196328177 hist_true: [0.0166504029 0.0170697086 0.0174802411 ... 0.0163280647 0.0158977956 0.0154619468] hist_pred: [0.0195717774 0.019707771 0.0198371075 ... 0.0177330244 0.0174997766 0.0172600299]\n",
      "KL loss: 0.00227535516 hist_true: [0.0155873299 0.0160509683 0.0165084451 ... 0.016658105 0.0162016433 0.0157385059] hist_pred: [0.0188277178 0.0190544147 0.0192719679 ... 0.0174053684 0.0171405915 0.0168702286]\n",
      "KL loss: 0.00161982514 hist_true: [0.017410811 0.0177574065 0.0180947408 ... 0.0168860126 0.0165243 0.016156368] hist_pred: [0.0201610569 0.0203360803 0.0205000676 ... 0.0166409668 0.0163878035 0.0161324944]\n",
      "KL loss: 0.00118294032 hist_true: [0.0174716022 0.0178351793 0.0181888863 ... 0.0164381396 0.0160490815 0.0156545974] hist_pred: [0.0192802083 0.0194209144 0.0195563063 ... 0.0180185251 0.0177973267 0.0175695661]\n",
      "KL loss: 0.00885936618 hist_true: [0.0137504265 0.0142947407 0.0148386676 ... 0.0168317594 0.0163008329 0.0157627314] hist_pred: [0.0190815851 0.0194232315 0.0197504796 ... 0.0151436962 0.0147709651 0.0143990144]\n",
      "KL loss: 0.00157908676 hist_true: [0.0176736731 0.0179595985 0.0182375163 ... 0.0177649576 0.0174736753 0.0171752479] hist_pred: [0.0174018722 0.0176034328 0.0178007241 ... 0.0201652739 0.0200638603 0.0199568421]\n",
      "KL loss: 0.000672380906 hist_true: [0.0176181365 0.0178740118 0.0181230176 ... 0.0185161438 0.0182799958 0.018036427] hist_pred: [0.0177863091 0.0179553553 0.018121032 ... 0.0201188829 0.0200235751 0.0199225023]\n",
      "KL loss: 0.00209762272 hist_true: [0.0175255686 0.0178706702 0.0182062816 ... 0.0167299863 0.0163606871 0.0159853306] hist_pred: [0.0205739401 0.0207355823 0.0208866894 ... 0.0159597527 0.0156542901 0.0153456405]\n",
      "KL loss: 0.000466107391 hist_true: [0.0184512436 0.0186913908 0.0189231019 ... 0.0175912231 0.0173211377 0.0170450024] hist_pred: [0.0191746373 0.0193010066 0.0194221903 ... 0.0188153889 0.0186726078 0.0185252391]\n",
      "KL loss: 0.00212312769 hist_true: [0.0184453148 0.0187961552 0.0191346798 ... 0.0154040614 0.0149890678 0.0145711405] hist_pred: [0.019621022 0.0197567698 0.0198850986 ... 0.0179934539 0.0178007148 0.0176029187]\n",
      "KL loss: 0.00572184846 hist_true: [0.0139436508 0.0145308124 0.0151171684 ... 0.015639646 0.0150583694 0.0144745409] hist_pred: [0.0187264159 0.019074196 0.0194089301 ... 0.0154622318 0.0150852259 0.0147061991]\n",
      "KL loss: 0.00589995272 hist_true: [0.0101884259 0.0107893869 0.0114044147 ... 0.0185650382 0.017938083 0.0172981061] hist_pred: [0.0141801536 0.0145589756 0.0149329463 ... 0.0209111776 0.020650791 0.0203717873]\n",
      "KL loss: 0.00607782044 hist_true: [0.0131307477 0.0137212928 0.0143143125 ... 0.0162435602 0.0156503264 0.0150524443] hist_pred: [0.0181318037 0.0184408538 0.0187407825 ... 0.016608743 0.0162643846 0.0159154534]\n",
      "KL loss: 0.0117751621 hist_true: [0.0167555083 0.0171909686 0.0176170748 ... 0.0158409942 0.0153854815 0.0149256224] hist_pred: [0.0143932933 0.0147427507 0.0150896069 ... 0.0218371879 0.0217453092 0.0216439143]\n",
      "KL loss: 0.0177750029 hist_true: [0.0219346527 0.0224197973 0.0228755325 ... 0.00976346899 0.00923512317 0.00872289389] hist_pred: [0.0189106818 0.0192038901 0.0194876511 ... 0.0154626779 0.0150633408 0.01466191]\n",
      "KL loss: 0.0363892466 hist_true: [0.00890582521 0.00952225644 0.0101604555 ... 0.0183595847 0.0176282339 0.0168859735] hist_pred: [0.0180458874 0.0185131077 0.0189628843 ... 0.0145952879 0.0141787734 0.0137662767]\n",
      "KL loss: 0.00161600299 hist_true: [0.0175527297 0.017910542 0.0182583537 ... 0.0164608769 0.0160770398 0.0156877842] hist_pred: [0.0204465743 0.0205458738 0.0206373408 ... 0.0173263792 0.0171069279 0.0168827306]\n",
      "KL loss: 0.000887511764 hist_true: [0.0188173335 0.0190549865 0.0192833412 ... 0.0170985684 0.0168074351 0.0165109057] hist_pred: [0.020917302 0.0209345222 0.0209485572 ... 0.0180080831 0.0178640317 0.0177169703]\n",
      "KL loss: 0.00152107 hist_true: [0.0149890017 0.0154316342 0.0158698708 ... 0.0179752726 0.0175773893 0.0171695948] hist_pred: [0.0175799951 0.0177925322 0.0180015508 ... 0.018996466 0.0187706687 0.0185351931]\n",
      "KL loss: 0.00619818084 hist_true: [0.0102461791 0.0108237797 0.011413997 ... 0.0194300488 0.0188626498 0.0182789657] hist_pred: [0.0143751483 0.0148090981 0.0152442958 ... 0.0184171777 0.0180290788 0.0176319759]\n",
      "KL loss: 0.00924271159 hist_true: [0.0155197959 0.0159205515 0.0163161829 ... 0.0182110742 0.0178520419 0.017482942] hist_pred: [0.0211699 0.0212959778 0.0214118529 ... 0.0157251786 0.0154299578 0.0151331397]\n",
      "KL loss: 0.013893839 hist_true: [0.0110816862 0.0117964819 0.012527057 ... 0.0145330224 0.0137866605 0.0130479932] hist_pred: [0.0174651369 0.0179958399 0.0185167193 ... 0.0133261047 0.0128534138 0.0123909293]\n",
      "KL loss: 0.000412344 hist_true: [0.0189271122 0.0191073194 0.0192804392 ... 0.018090168 0.0178779364 0.0176602509] hist_pred: [0.0195502602 0.0196197368 0.0196863413 ... 0.0192648377 0.0191704985 0.0190722644]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2683  KL loss: 0.00846705679 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.01837782 0.0188761968 0.0193589889 ... 0.012774826 0.0122294 0.0116898334]\n",
      "KL loss: 0.00642386917 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0135308569 0.0140678454 0.0146046393 ... 0.0174065474 0.016903216 0.0163909588]\n",
      "KL loss: 0.00583402626 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0202832799 0.0205297712 0.0207623839 ... 0.0148899052 0.0145077324 0.0141239753]\n",
      "KL loss: 0.00263474742 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0207596887 0.0209745094 0.0211748444 ... 0.0149925882 0.0146445641 0.0142959114]\n",
      "KL loss: 0.010934066 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0181959253 0.0186127629 0.0190162491 ... 0.0144667123 0.0139917061 0.0135164019]\n",
      "KL loss: 0.00673001353 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0222153049 0.0223767236 0.02252228 ... 0.013782952 0.0133981435 0.0130142337]\n",
      "KL loss: 0.00421968196 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0222570188 0.0222262852 0.0221911613 ... 0.0168886 0.0167141128 0.0165385287]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2715 - val_loss: 0.1760\n",
      "Epoch 49/50\n",
      "KL loss: 0.00474439701 hist_true: [0.016412789 0.016989829 0.0175569 ... 0.0134994974 0.0129267359 0.0123587688] hist_pred: [0.0206088815 0.0207424145 0.0208653826 ... 0.016008202 0.0156697799 0.0153261032]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8298KL loss: 0.000726833474 hist_true: [0.0171732195 0.0174980443 0.0178148244 ... 0.0176838394 0.0173661206 0.0170408487] hist_pred: [0.0186001938 0.0187713839 0.0189362019 ... 0.0189142507 0.0187565684 0.0185932405]\n",
      "KL loss: 0.000511065 hist_true: [0.0168969221 0.0172168389 0.0175296683 ... 0.0181722473 0.0178768411 0.0175730959] hist_pred: [0.0184290223 0.0186437909 0.0188505277 ... 0.0183684621 0.0181676615 0.0179616436]\n",
      "KL loss: 0.00117478939 hist_true: [0.018107146 0.0185208824 0.0189214926 ... 0.0146692935 0.0142036136 0.0137371356] hist_pred: [0.0204069745 0.0205939636 0.0207694788 ... 0.0157397855 0.0154156936 0.0150892725]\n",
      "KL loss: 0.00308682886 hist_true: [0.0182556715 0.0184553936 0.0186489113 ... 0.0187279489 0.0185370743 0.0183398984] hist_pred: [0.0218596179 0.0218395311 0.0218151845 ... 0.0174001362 0.0172544718 0.0171077773]\n",
      "KL loss: 0.00550711807 hist_true: [0.0137001341 0.0142439129 0.0147872623 ... 0.0169591773 0.0164346397 0.0159024708] hist_pred: [0.0182899423 0.0185999703 0.0188992694 ... 0.0170567539 0.0168120246 0.0165691487]\n",
      "KL loss: 0.00278861262 hist_true: [0.0199987479 0.0204558093 0.0208918098 ... 0.0119523006 0.0114332428 0.0109224021] hist_pred: [0.0240999032 0.0241253041 0.0241364855 ... 0.0132124275 0.0128382258 0.0124659501]\n",
      "KL loss: 0.000900986372 hist_true: [0.0192478262 0.0194638446 0.0196702834 ... 0.0168984402 0.0166102704 0.0163172688] hist_pred: [0.0215174519 0.0215572771 0.0215904508 ... 0.0167361367 0.0165179 0.0162968412]\n",
      "KL loss: 0.00549182 hist_true: [0.0194785018 0.0196587928 0.0198304914 ... 0.0172526352 0.0169993211 0.0167412665] hist_pred: [0.0170775559 0.0172582548 0.0174368117 ... 0.0209903661 0.020934118 0.0208714679]\n",
      "KL loss: 0.00696994923 hist_true: [0.0153484698 0.015695164 0.016038036 ... 0.0198229551 0.0195775013 0.0193204023] hist_pred: [0.0196782481 0.0198607203 0.020033313 ... 0.0171140973 0.0168694109 0.0166212097]\n",
      "KL loss: 0.00798825361 hist_true: [0.011483605 0.0119883688 0.0124995047 ... 0.0204433482 0.0200111065 0.0195595138] hist_pred: [0.0164553653 0.016767269 0.0170718431 ... 0.0192502961 0.0190120656 0.0187631156]\n",
      "KL loss: 0.00353693869 hist_true: [0.0185843 0.0189056732 0.0192150567 ... 0.0158340558 0.0154513568 0.0150648449] hist_pred: [0.0226629619 0.0227175876 0.022762211 ... 0.0145728849 0.0142341061 0.0138941333]\n",
      "KL loss: 0.00129781058 hist_true: [0.0166117549 0.0169736966 0.0173281096 ... 0.0176676251 0.0173246022 0.0169735588] hist_pred: [0.0186379049 0.0187886432 0.0189347584 ... 0.0192180332 0.0190986469 0.0189760718]\n",
      "KL loss: 0.000766184181 hist_true: [0.0183655117 0.0187476873 0.019116804 ... 0.0149251604 0.0144807184 0.0140345814] hist_pred: [0.0203703754 0.0205552652 0.0207300168 ... 0.0156276356 0.0152893327 0.0149484854]\n",
      "KL loss: 0.0022731903 hist_true: [0.0108612748 0.0114313876 0.0120128011 ... 0.0184158068 0.0177920368 0.0171545018] hist_pred: [0.0133157885 0.0137537206 0.0141921667 ... 0.0198327508 0.019452922 0.0190577526]\n",
      "KL loss: 0.000674754381 hist_true: [0.0186229534 0.0189413186 0.0192478 ... 0.0158169195 0.0154341077 0.0150475614] hist_pred: [0.0198003538 0.0199576505 0.0201068651 ... 0.0171029121 0.0168448 0.0165818427]\n",
      "KL loss: 0.0030888617 hist_true: [0.0153546073 0.0158218164 0.0162835289 ... 0.0168738142 0.0164210238 0.0159610249] hist_pred: [0.0169185735 0.0171455573 0.0173688624 ... 0.0200835131 0.0199287049 0.0197643414]\n",
      "KL loss: 0.00618210668 hist_true: [0.0198908858 0.020333752 0.0207566861 ... 0.0122037511 0.011687384 0.0111782728] hist_pred: [0.0196677689 0.0198715962 0.0200671814 ... 0.0162349939 0.0159231573 0.0156093342]\n",
      "KL loss: 0.00123523548 hist_true: [0.0170797743 0.0174946785 0.0178994592 ... 0.0159381926 0.0155052654 0.0150680207] hist_pred: [0.0191505514 0.0193758644 0.0195898805 ... 0.0172499139 0.0169969872 0.0167396292]\n",
      "KL loss: 0.00149975636 hist_true: [0.0182053447 0.0185696874 0.018921895 ... 0.0154912667 0.0150743723 0.0146544138] hist_pred: [0.0211125501 0.0212549791 0.0213861633 ... 0.0155626014 0.0152510507 0.0149372369]\n",
      "KL loss: 0.000589027302 hist_true: [0.0181574076 0.0184439868 0.0187211055 ... 0.0170879662 0.0167704169 0.0164469406] hist_pred: [0.0193268787 0.0194764938 0.0196188204 ... 0.0182873383 0.0181191191 0.0179473311]\n",
      "KL loss: 0.00553760165 hist_true: [0.0141655765 0.0146733709 0.015179337 ... 0.0172301643 0.0167378485 0.0162367076] hist_pred: [0.0188056882 0.0190876592 0.0193565283 ... 0.0167815611 0.0164850596 0.0161841325]\n",
      "KL loss: 0.00145559199 hist_true: [0.0210792795 0.021275619 0.0214578137 ... 0.0147310514 0.0143676596 0.014003302] hist_pred: [0.0205509141 0.020675689 0.0207917411 ... 0.016765153 0.0165254232 0.0162832979]\n",
      "KL loss: 0.00105396053 hist_true: [0.0166583154 0.017044438 0.0174224358 ... 0.0170430541 0.0166586321 0.0162671451] hist_pred: [0.0185200982 0.0187105555 0.018895328 ... 0.0183908828 0.0181861725 0.0179759953]\n",
      "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3765 KL loss: 0.0192910079 hist_true: [0.0100659104 0.0107737277 0.0115029514 ... 0.0150152538 0.014231394 0.0134546561] hist_pred: [0.017773971 0.0182652418 0.0187403113 ... 0.0144624831 0.0139977438 0.0135313282]\n",
      "KL loss: 0.00471243635 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0176613126 0.0181503147 0.0186262727 ... 0.0137427747 0.0132163009 0.0126924012]\n",
      "KL loss: 0.00390511798 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0130493706 0.0135767143 0.0141052408 ... 0.0182313789 0.0177542418 0.0172655489]\n",
      "KL loss: 0.00251518469 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0192123093 0.0194796231 0.0197353642 ... 0.0159527473 0.0155984014 0.0152402008]\n",
      "KL loss: 0.0013037438 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0200478453 0.020283699 0.0205063317 ... 0.015578419 0.0152434139 0.0149067454]\n",
      "KL loss: 0.00537896529 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0169791672 0.0174113307 0.0178334322 ... 0.0156907663 0.0152397007 0.014785069]\n",
      "KL loss: 0.00473946566 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0217471365 0.0219112858 0.0220608916 ... 0.0143625643 0.0139976218 0.0136324661]\n",
      "KL loss: 0.00165979727 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0210428853 0.021063149 0.0210793335 ... 0.0178609192 0.0177168772 0.017570667]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3746 - val_loss: 0.1606\n",
      "Epoch 50/50\n",
      "KL loss: 0.00385839632 hist_true: [0.0189637393 0.0193759594 0.0197724309 ... 0.0136657041 0.0131784277 0.0126932962] hist_pred: [0.0185491946 0.0187947731 0.0190331973 ... 0.0168724619 0.0165373087 0.0161957443]\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4930KL loss: 0.0026115207 hist_true: [0.020046927 0.0202457123 0.0204333048 ... 0.0161083322 0.0157971047 0.0154824797] hist_pred: [0.0188123267 0.0189658254 0.0191139169 ... 0.0187621955 0.0185944065 0.0184208136]\n",
      "KL loss: 0.0138372369 hist_true: [0.0109635778 0.0114908889 0.0120265931 ... 0.0203483142 0.0198792 0.019390624] hist_pred: [0.0175200384 0.0177966245 0.0180636067 ... 0.018743569 0.0185324363 0.0183135942]\n",
      "KL loss: 0.00670497259 hist_true: [0.0103342542 0.0109676411 0.0116163269 ... 0.0172245093 0.0165314376 0.0158317033] hist_pred: [0.0149036786 0.0153453583 0.0157819837 ... 0.0181838162 0.0178053342 0.0174183976]\n",
      "KL loss: 0.00339262513 hist_true: [0.0191186517 0.0195132401 0.0198915973 ... 0.0139133437 0.0134477476 0.0129835429] hist_pred: [0.0234456733 0.0235406905 0.0236182548 ... 0.0136398217 0.0133078936 0.0129787829]\n",
      "KL loss: 0.00114128191 hist_true: [0.0162831768 0.016647784 0.0170057788 ... 0.0180407204 0.0177074913 0.0173653401] hist_pred: [0.0186542068 0.0188443922 0.0190278664 ... 0.0182740577 0.0180608798 0.0178412907]\n",
      "KL loss: 0.000172657717 hist_true: [0.0180329941 0.018283369 0.0185260586 ... 0.0179894 0.0177305359 0.0174648631] hist_pred: [0.0189080834 0.0190849435 0.0192547366 ... 0.0183237307 0.0181414373 0.0179552864]\n",
      "KL loss: 0.00732733402 hist_true: [0.0126817357 0.0132176634 0.0137563478 ... 0.0183215421 0.0178271718 0.0173206925] hist_pred: [0.0180999413 0.0183353201 0.0185615178 ... 0.0185908899 0.018380871 0.0181625057]\n",
      "KL loss: 0.00736515364 hist_true: [0.0154616153 0.0159071032 0.0163468141 ... 0.0172845591 0.0168626104 0.0164323933] hist_pred: [0.0204761978 0.0206762981 0.0208658185 ... 0.0149759343 0.0145836556 0.0141883623]\n",
      "KL loss: 0.0014181938 hist_true: [0.0185509305 0.0187454298 0.0189331919 ... 0.0183762535 0.018170312 0.017958425] hist_pred: [0.0183546208 0.018453721 0.0185513962 ... 0.0206558835 0.0206306782 0.0206014793]\n",
      "KL loss: 0.0077384687 hist_true: [0.0135226836 0.0140459714 0.0145693598 ... 0.0176066961 0.017105313 0.0165937711] hist_pred: [0.0189455599 0.019206997 0.0194553286 ... 0.0173235536 0.0170992482 0.0168726]\n",
      "KL loss: 0.00110841345 hist_true: [0.00949383527 0.0101206433 0.0107665593 ... 0.0178843737 0.0171725824 0.0164516754] hist_pred: [0.010861245 0.0114869392 0.0121251959 ... 0.0176133197 0.0170253664 0.0164338425]\n",
      "KL loss: 0.000695865601 hist_true: [0.0173479617 0.0176320598 0.0179090537 ... 0.0182923451 0.0180261061 0.0177520532] hist_pred: [0.0172502939 0.0174801182 0.0177042801 ... 0.0199359 0.0198134314 0.019685166]\n",
      "KL loss: 0.00596447894 hist_true: [0.0175391566 0.0178478919 0.0181481559 ... 0.0174916983 0.0171758235 0.0168529525] hist_pred: [0.0226495881 0.0226513594 0.0226445 ... 0.0159127302 0.0156816598 0.0154493488]\n",
      "KL loss: 0.0031227665 hist_true: [0.018073326 0.0184095167 0.0187349264 ... 0.0161800049 0.0157979988 0.0154112931] hist_pred: [0.018907126 0.0190204382 0.0191298816 ... 0.0194975697 0.0193969049 0.0192913152]\n",
      "KL loss: 0.00478333235 hist_true: [0.0171451569 0.017602168 0.0180482697 ... 0.0149309607 0.0144412424 0.0139499493] hist_pred: [0.0222571623 0.0223445222 0.0224172641 ... 0.0152642662 0.0149686607 0.0146703981]\n",
      "KL loss: 0.00249874289 hist_true: [0.0163040292 0.0166801 0.0170490537 ... 0.0178024136 0.017455535 0.0171001758] hist_pred: [0.0195401199 0.0197296124 0.0199100748 ... 0.0170100704 0.0167460218 0.0164779127]\n",
      "KL loss: 0.00304443017 hist_true: [0.018833302 0.0192662757 0.0196831208 ... 0.0135204336 0.0130253043 0.0125329774] hist_pred: [0.0195398685 0.0197537523 0.0199575964 ... 0.0165114515 0.0162144843 0.0159145594]\n",
      "KL loss: 0.00464079436 hist_true: [0.0207811948 0.0213626437 0.0219170544 ... 0.00951633509 0.00896110106 0.008424717] hist_pred: [0.0231992938 0.0234170817 0.0236089434 ... 0.0125199463 0.0121259093 0.0117362952]\n",
      "KL loss: 0.00536531862 hist_true: [0.0195340104 0.0197805893 0.0200153571 ... 0.0159368534 0.0155952973 0.0152501995] hist_pred: [0.0183894839 0.0185202137 0.018647138 ... 0.0200459566 0.0199691225 0.0198869389]\n",
      "KL loss: 0.00839883368 hist_true: [0.0154695204 0.0159094054 0.0163436867 ... 0.0173682142 0.0169505309 0.0165243447] hist_pred: [0.0214647762 0.0215680953 0.0216598101 ... 0.0162067916 0.0159803219 0.0157537535]\n",
      "KL loss: 0.00821861811 hist_true: [0.0145483781 0.01492838 0.0153058954 ... 0.0201955047 0.0199390482 0.0196695626] hist_pred: [0.0200804509 0.0201694686 0.0202521887 ... 0.0182406567 0.0180916227 0.0179391224]\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4438 KL loss: 0.00529922359 hist_true: [0.0165039841 0.0169190932 0.0173259135 ... 0.0166197494 0.0162019227 0.0157778375] hist_pred: [0.0157062784 0.0159681626 0.0162295941 ... 0.0206762739 0.0204860531 0.0202820245]\n",
      "KL loss: 0.00212504808 hist_true: [0.0164933763 0.0169426408 0.0173828062 ... 0.0159864351 0.0155347008 0.0150785558] hist_pred: [0.019387221 0.0196127538 0.0198258422 ... 0.0173042193 0.0170898978 0.0168730859]\n",
      "KL loss: 0.0100901891 hist_true: [0.00903151371 0.00969484355 0.0103837484 ... 0.0161733702 0.0153531898 0.014535673] hist_pred: [0.0145526025 0.0149771906 0.0154033238 ... 0.0175662432 0.0170841385 0.016593473]\n",
      "KL loss: 0.00391919073 hist_true: [0.0148011297 0.0153298378 0.0158544481 ... 0.0161231514 0.0156042324 0.0150805032] hist_pred: [0.0172253586 0.01773623 0.0182350352 ... 0.0138375005 0.0133011667 0.0127673373]\n",
      "KL loss: 0.00384271331 hist_true: [0.011041102 0.0115526225 0.012071819 ... 0.0208649561 0.0204428341 0.0200005043] hist_pred: [0.0130607197 0.0135877961 0.0141158635 ... 0.0183081664 0.0178419035 0.0173643343]\n",
      "KL loss: 0.00221618498 hist_true: [0.017119199 0.0174314547 0.0177362897 ... 0.0180087555 0.0177106038 0.0174044333] hist_pred: [0.0190531556 0.0193268508 0.019589141 ... 0.0160614327 0.01570867 0.0153518235]\n",
      "KL loss: 0.00132101157 hist_true: [0.0181256905 0.0184348281 0.018733887 ... 0.0166555345 0.0163065381 0.0159520842] hist_pred: [0.0199445318 0.0201941058 0.0204301793 ... 0.0154809831 0.0151380347 0.0147938151]\n",
      "KL loss: 0.00633526593 hist_true: [0.0140983807 0.0145633016 0.0150263412 ... 0.0185359456 0.0181304272 0.0177131258] hist_pred: [0.0172209162 0.017650649 0.0180696119 ... 0.0154459104 0.0149903251 0.0145318303]\n",
      "KL loss: 0.00433799252 hist_true: [0.0183912814 0.0186711103 0.0189412218 ... 0.016855 0.0165292248 0.0161978733] hist_pred: [0.0215202663 0.0216990225 0.0218632147 ... 0.0144196367 0.0140507119 0.0136814024]\n",
      "KL loss: 0.000897704158 hist_true: [0.0190674756 0.0191657804 0.0192607399 ... 0.0195587352 0.0194755774 0.0193888973] hist_pred: [0.0205193013 0.0205604266 0.020597646 ... 0.0183103792 0.0181826893 0.0180525072]\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4449 - val_loss: 0.1703\n"
     ]
    }
   ],
   "source": [
    "history_keras = model_keras.fit(X_train_scaled, y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=32,\n",
    "                              validation_data=(X_val_scaled, y_val),\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "keras-evaluate",
   "metadata": {},
   "source": [
    "### Evaluate Keras Model and Save Predictions\n",
    "\n",
    "Predict on the validation set (predictions are on log scale), then exponentiate. Save predictions to `predictions_keras_KL.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "keras-evaluate-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Any NaNs in Keras predictions? False\n",
      "Keras Validation RMSE: 360599.8884997685\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Keras predictions saved to predictions_keras_KL_v2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_val_pred_log = model_keras.predict(X_val_scaled).flatten()\n",
    "print(\"Any NaNs in Keras predictions?\", np.any(np.isnan(y_val_pred_log)))\n",
    "\n",
    "# Convert back to original scale\n",
    "y_val_pred = np.exp(y_val_pred_log)\n",
    "y_val_actual = np.exp(y_val)  \n",
    "rmse_keras = np.sqrt(mean_squared_error(y_val_actual, y_val_pred))\n",
    "print('Keras Validation RMSE:', rmse_keras)\n",
    "\n",
    "# Save test predictions\n",
    "test_df_proc = fill_missing_values(test_df.copy())\n",
    "test_ids = test_df_proc['Id']\n",
    "test_df_proc.drop('Id', axis=1, inplace=True)\n",
    "test_df_proc = pd.get_dummies(test_df_proc, drop_first=True)\n",
    "test_df_proc = test_df_proc.reindex(columns=X.columns, fill_value=0)\n",
    "test_scaled = scaler.transform(test_df_proc)\n",
    "\n",
    "preds_test_log = model_keras.predict(test_scaled).flatten()\n",
    "preds_test = np.exp(preds_test_log)\n",
    "\n",
    "predictions_keras = pd.DataFrame({'ID': test_ids, 'SALEPRICE': preds_test})\n",
    "predictions_keras.to_csv('predictions_keras_KL_v2.csv', index=False)\n",
    "print('Keras predictions saved to predictions_keras_KL_v2.csv')\n",
    "\n",
    "# Plot Keras loss curves and distribution\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_keras.history['loss'], label='Train Loss')\n",
    "plt.plot(history_keras.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Combined Loss')\n",
    "plt.title('Keras Loss Curves')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(y_val_actual, bins=50, color='blue', alpha=0.5, stat='density', label='Actual')\n",
    "sns.histplot(y_val_pred, bins=50, color='red', alpha=0.5, stat='density', label='Predicted')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Keras: Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pytorch-section",
   "metadata": {},
   "source": [
    "## 3. PyTorch Implementation\n",
    "\n",
    "Build and train the PyTorch model. Note: we define the device before creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pytorch-device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pytorch-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HousePriceNetTorch(\n",
      "  (fc1): Linear(in_features=5, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class HousePriceNetTorch(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceNetTorch, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim_pt = X_train_scaled.shape[1]\n",
    "model_torch = HousePriceNetTorch(input_dim_pt).to(device)\n",
    "print(model_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pytorch-kl-loss",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_histogram_torch(x, bin_centers, sigma):\n",
    "    x = x.view(-1, 1)\n",
    "    bin_centers = bin_centers.view(1, -1)\n",
    "    diff = x - bin_centers\n",
    "    soft_counts = torch.exp(- (diff ** 2) / (2 * sigma ** 2))\n",
    "    hist = torch.sum(soft_counts, dim=0)\n",
    "    hist = hist / torch.sum(hist)\n",
    "    return hist\n",
    "\n",
    "def kl_divergence_loss_torch(y_true, y_pred, num_bins=50, sigma=1.0):\n",
    "    min_val = torch.min(y_true)\n",
    "    max_val = torch.max(y_true)\n",
    "    bin_centers = torch.linspace(min_val, max_val, steps=num_bins, device=y_true.device)\n",
    "    hist_true = soft_histogram_torch(y_true, bin_centers, sigma)\n",
    "    hist_pred = soft_histogram_torch(y_pred, bin_centers, sigma)\n",
    "    epsilon = 1e-6\n",
    "    hist_true = torch.clamp(hist_true, min=epsilon, max=1.0)\n",
    "    hist_pred = torch.clamp(hist_pred, min=epsilon, max=1.0)\n",
    "    kl = torch.sum(hist_true * torch.log(hist_true / hist_pred))\n",
    "    return kl\n",
    "\n",
    "def combined_loss_torch(y_true, y_pred, alpha=0.001):\n",
    "    mse = torch.mean((y_true - y_pred) ** 2)\n",
    "    kl = kl_divergence_loss_torch(y_true, y_pred, num_bins=50, sigma=1.0)\n",
    "    return mse + alpha * kl\n",
    "\n",
    "# Print a test KL loss value (optional, for debugging)\n",
    "# print(kl_divergence_loss_torch(y_train_tensor, model_torch(X_train_tensor), num_bins=50, sigma=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pytorch-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 128.4186, Val Loss: 126.0565, Val RMSE: 11.2272\n",
      "Epoch 20/50, Train Loss: 107.6408, Val Loss: 105.7836, Val RMSE: 10.2848\n",
      "Epoch 30/50, Train Loss: 81.3470, Val Loss: 80.3982, Val RMSE: 8.9664\n",
      "Epoch 40/50, Train Loss: 54.2101, Val Loss: 53.1025, Val RMSE: 7.2871\n",
      "Epoch 50/50, Train Loss: 32.2498, Val Loss: 30.4398, Val RMSE: 5.5172\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "optimizer_torch = optim.Adam(model_torch.parameters(), lr=0.001)\n",
    "num_epochs_pt = 50\n",
    "train_losses_pt = []\n",
    "val_losses_pt = []\n",
    "\n",
    "for epoch in range(num_epochs_pt):\n",
    "    model_torch.train()\n",
    "    optimizer_torch.zero_grad()\n",
    "    outputs = model_torch(X_train_tensor)\n",
    "    loss = combined_loss_torch(y_train_tensor, outputs, alpha=0.001)\n",
    "    loss.backward()\n",
    "    optimizer_torch.step()\n",
    "    train_losses_pt.append(loss.item())\n",
    "    \n",
    "    model_torch.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model_torch(X_val_tensor)\n",
    "        val_loss = combined_loss_torch(y_val_tensor, val_outputs, alpha=0.001)\n",
    "        val_losses_pt.append(val_loss.item())\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        rmse_val = np.sqrt(mean_squared_error(y_val_tensor.cpu().numpy(), val_outputs.cpu().numpy()))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs_pt}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val RMSE: {rmse_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pytorch-evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaNs in PyTorch predictions? False\n",
      "PyTorch Validation RMSE: 22776149.699082326\n",
      "PyTorch predictions saved to predictions_pytorch_KL_v2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_torch.eval()\n",
    "with torch.no_grad():\n",
    "    val_preds_pt_log = model_torch(X_val_tensor).cpu().numpy().flatten()\n",
    "\n",
    "print(\"Any NaNs in PyTorch predictions?\", np.any(np.isnan(val_preds_pt_log)))\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "val_preds_pt = np.exp(val_preds_pt_log)\n",
    "y_val_actual_pt = np.exp(y_val_tensor.cpu().numpy().flatten())\n",
    "rmse_torch = np.sqrt(mean_squared_error(y_val_actual_pt, val_preds_pt))\n",
    "print('PyTorch Validation RMSE:', rmse_torch)\n",
    "\n",
    "# Save test predictions\n",
    "test_df_proc = fill_missing_values(test_df.copy())\n",
    "test_ids = test_df_proc['Id']\n",
    "test_df_proc.drop('Id', axis=1, inplace=True)\n",
    "test_df_proc = pd.get_dummies(test_df_proc, drop_first=True)\n",
    "test_df_proc = test_df_proc.reindex(columns=X.columns, fill_value=0)\n",
    "test_scaled = scaler.transform(test_df_proc)\n",
    "test_tensor = torch.tensor(test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "model_torch.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds_pt_log = model_torch(test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "test_preds_pt = np.exp(test_preds_pt_log)\n",
    "predictions_torch = pd.DataFrame({'ID': test_ids, 'SALEPRICE': test_preds_pt})\n",
    "predictions_torch.to_csv('predictions_pytorch_KL_v2.csv', index=False)\n",
    "print('PyTorch predictions saved to predictions_pytorch_KL_v2.csv')\n",
    "\n",
    "# Plot PyTorch distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(y_val_actual_pt, bins=50, color='blue', alpha=0.5, stat='density', label='Actual')\n",
    "sns.histplot(val_preds_pt, bins=50, color='orange', alpha=0.5, stat='density', label='Predicted')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Density')\n",
    "plt.title('PyTorch: Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jax-section",
   "metadata": {},
   "source": [
    "## 4. JAX (Flax & Optax) Implementation\n",
    "\n",
    "Build and train the model using JAX/Flax with a combined loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "jax-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX model parameters initialized.\n"
     ]
    }
   ],
   "source": [
    "class HousePriceNetJAX(nn_flax.Module):\n",
    "    dropout_rate: float = 0.2\n",
    "    \n",
    "    @nn_flax.compact\n",
    "    def __call__(self, x, training):\n",
    "        x = nn_flax.Dense(128)(x)\n",
    "        x = nn_flax.relu(x)\n",
    "        x = nn_flax.Dropout(rate=self.dropout_rate)(x, deterministic=not training)\n",
    "        x = nn_flax.Dense(64)(x)\n",
    "        x = nn_flax.relu(x)\n",
    "        x = nn_flax.Dropout(rate=self.dropout_rate)(x, deterministic=not training)\n",
    "        x = nn_flax.Dense(1)(x)\n",
    "        return x\n",
    "\n",
    "model_jax = HousePriceNetJAX()\n",
    "rng_jax = jax.random.PRNGKey(0)\n",
    "dummy_input = jnp.ones((X_train_scaled.shape[0], X_train_scaled.shape[1]))\n",
    "params_jax = model_jax.init(rng_jax, dummy_input, training=True)['params']\n",
    "print('JAX model parameters initialized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "jax-trainstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX training state created.\n"
     ]
    }
   ],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    pass\n",
    "\n",
    "def soft_histogram_jax(x, bin_centers, sigma):\n",
    "    x = jnp.reshape(x, (-1, 1))\n",
    "    diff = x - bin_centers\n",
    "    soft_counts = jnp.exp(- (diff ** 2) / (2 * sigma ** 2))\n",
    "    hist = jnp.sum(soft_counts, axis=0)\n",
    "    hist = hist / jnp.sum(hist)\n",
    "    return hist\n",
    "\n",
    "def kl_divergence_loss_jax(params, batch, rng, training, num_bins=50, sigma=1.0):\n",
    "    inputs, targets = batch\n",
    "    preds = model_jax.apply({'params': params}, inputs, training=training, rngs={'dropout': rng})\n",
    "    min_val = jnp.min(targets)\n",
    "    max_val = jnp.max(targets)\n",
    "    bin_centers = jnp.linspace(min_val, max_val, num_bins)\n",
    "    hist_true = soft_histogram_jax(jnp.ravel(targets), bin_centers, sigma)\n",
    "    hist_pred = soft_histogram_jax(jnp.ravel(preds), bin_centers, sigma)\n",
    "    epsilon = 1e-6\n",
    "    hist_true = jnp.clip(hist_true, epsilon, 1.0)\n",
    "    hist_pred = jnp.clip(hist_pred, epsilon, 1.0)\n",
    "    kl = jnp.sum(hist_true * jnp.log(hist_true / hist_pred))\n",
    "    return kl\n",
    "\n",
    "def mse_loss_jax(params, batch, rng, training):\n",
    "    inputs, targets = batch\n",
    "    preds = model_jax.apply({'params': params}, inputs, training=training, rngs={'dropout': rng})\n",
    "    return jnp.mean((preds - targets) ** 2)\n",
    "\n",
    "def combined_loss_jax(params, batch, rng, training, alpha=0.001):\n",
    "    mse = mse_loss_jax(params, batch, rng, training)\n",
    "    kl = kl_divergence_loss_jax(params, batch, rng, training, num_bins=50, sigma=1.0)\n",
    "    return mse + alpha * kl\n",
    "\n",
    "learning_rate = 0.001\n",
    "tx = optax.adam(learning_rate)\n",
    "state_jax = TrainState.create(apply_fn=model_jax.apply, params=params_jax, tx=tx)\n",
    "print('JAX training state created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "jax-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 106.6536, Val Loss: 102.8026, Val RMSE: 184558.9375\n",
      "Epoch 20/50 - Train Loss: 72.7857, Val Loss: 70.1797, Val RMSE: 183799.4375\n",
      "Epoch 30/50 - Train Loss: 46.0348, Val Loss: 43.8628, Val RMSE: 18426294.0000\n",
      "Epoch 40/50 - Train Loss: 33.0997, Val Loss: 31.4605, Val RMSE: 5643284480.0000\n",
      "Epoch 50/50 - Train Loss: 30.3144, Val Loss: 27.1049, Val RMSE: 85150531584.0000\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def train_step_jax(state, batch, rng):\n",
    "    grad_fn = jax.value_and_grad(combined_loss_jax)\n",
    "    loss, grads = grad_fn(state.params, batch, rng, True, 0.001)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "@jax.jit\n",
    "def eval_step_jax(params, batch, rng):\n",
    "    return combined_loss_jax(params, batch, rng, False, 0.001)\n",
    "\n",
    "num_epochs_jax = 50\n",
    "train_losses_jax = []\n",
    "val_losses_jax = []\n",
    "\n",
    "for epoch in range(num_epochs_jax):\n",
    "    rng_jax, step_rng = jax.random.split(rng_jax)\n",
    "    batch_train = (jnp.array(X_train_scaled), jnp.array(y_train.values).reshape(-1,1))\n",
    "    state_jax, loss = train_step_jax(state_jax, batch_train, step_rng)\n",
    "    train_losses_jax.append(loss.item())\n",
    "    \n",
    "    batch_val = (jnp.array(X_val_scaled), jnp.array(y_val.values).reshape(-1,1))\n",
    "    val_loss = eval_step_jax(state_jax.params, batch_val, step_rng)\n",
    "    val_losses_jax.append(val_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        preds_val_log = model_jax.apply({'params': state_jax.params}, jnp.array(X_val_scaled), training=False, rngs={'dropout': step_rng})\n",
    "        rmse_jax = jnp.sqrt(jnp.mean((jnp.exp(preds_val_log) - jnp.exp(jnp.array(y_val.values).reshape(-1,1))) ** 2))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs_jax} - Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val RMSE: {rmse_jax.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "jax-evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaNs in JAX predictions? False\n",
      "JAX Validation RMSE: 85150543053.09625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_2507/3179406045.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX predictions saved to predictions_jax_KL_v2.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_val_log = model_jax.apply({'params': state_jax.params}, jnp.array(X_val_scaled), training=False, rngs={'dropout': rng_jax})\n",
    "preds_val_log = np.array(preds_val_log).flatten()\n",
    "print(\"Any NaNs in JAX predictions?\", np.any(np.isnan(preds_val_log)))\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_val_pred_jax = np.exp(preds_val_log)\n",
    "y_val_actual_jax = np.exp(y_val.values.flatten())\n",
    "rmse_jax_final = np.sqrt(mean_squared_error(y_val_actual_jax, y_val_pred_jax))\n",
    "print('JAX Validation RMSE:', rmse_jax_final)\n",
    "\n",
    "# Save JAX test predictions\n",
    "test_df_proc = fill_missing_values(test_df.copy())\n",
    "test_ids = test_df_proc['Id']\n",
    "test_df_proc.drop('Id', axis=1, inplace=True)\n",
    "test_df_proc = pd.get_dummies(test_df_proc, drop_first=True)\n",
    "test_df_proc = test_df_proc.reindex(columns=X.columns, fill_value=0)\n",
    "test_scaled = scaler.transform(test_df_proc)\n",
    "test_jax = jnp.array(test_scaled)\n",
    "\n",
    "preds_test_log = model_jax.apply({'params': state_jax.params}, test_jax, training=False, rngs={'dropout': rng_jax})\n",
    "preds_test_log = np.array(preds_test_log).flatten()\n",
    "preds_test_jax = np.exp(preds_test_log)\n",
    "\n",
    "predictions_jax = pd.DataFrame({'ID': test_ids, 'SALEPRICE': preds_test_jax})\n",
    "predictions_jax.to_csv('predictions_jax_KL_v2.csv', index=False)\n",
    "print('JAX predictions saved to predictions_jax_KL_v2.csv')\n",
    "\n",
    "# Plot JAX distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(y_val_actual_jax, bins=50, color='blue', alpha=0.5, stat='density', label='Actual')\n",
    "sns.histplot(y_val_pred_jax, bins=50, color='pink', alpha=0.5, stat='density', label='Predicted')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Density')\n",
    "plt.title('JAX: Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 5. Combined Summary and Comparison\n",
    "\n",
    "This section prints the RMSE values for each framework and plots combined loss curves and distribution histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "summary-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras RMSE: 360599.8884997685\n",
      "PyTorch RMSE: 22776149.699082326\n",
      "JAX RMSE: 85150543053.09625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print summary RMSE values\n",
    "print(\"Keras RMSE:\", rmse_keras)\n",
    "print(\"PyTorch RMSE:\", rmse_torch)\n",
    "print(\"JAX RMSE:\", rmse_jax_final)\n",
    "\n",
    "# Plot combined loss curves (side-by-side if available)\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history_keras.history['loss'], label='Train')\n",
    "plt.plot(history_keras.history['val_loss'], label='Val')\n",
    "plt.title('Keras Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(train_losses_pt, label='Train')\n",
    "plt.plot(val_losses_pt, label='Val')\n",
    "plt.title('PyTorch Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(train_losses_jax, label='Train')\n",
    "plt.plot(val_losses_jax, label='Val')\n",
    "plt.title('JAX Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combined distribution histogram overlay for validation set (using Keras, PyTorch, and JAX results)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(y_val_actual, bins=50, color='blue', alpha=0.3, stat='density', label='Keras Actual')\n",
    "sns.histplot(np.exp(y_val_pred_log), bins=50, color='red', alpha=0.3, stat='density', label='Keras Predicted')\n",
    "\n",
    "sns.histplot(y_val_actual_pt, bins=50, color='green', alpha=0.3, stat='density', label='PyTorch Actual')\n",
    "sns.histplot(val_preds_pt, bins=50, color='orange', alpha=0.3, stat='density', label='PyTorch Predicted')\n",
    "\n",
    "sns.histplot(y_val_actual_jax, bins=50, color='purple', alpha=0.3, stat='density', label='JAX Actual')\n",
    "sns.histplot(y_val_pred_jax, bins=50, color='pink', alpha=0.3, stat='density', label='JAX Predicted')\n",
    "\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Combined Actual vs Predicted Distributions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
